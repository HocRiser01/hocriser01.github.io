<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="robots" content="noindex, nofollow">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.jpg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/avatar.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/avatar.jpg">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"47.99.133.133","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

<script>
  (function() {
    const images = [
      '/images/homepage_bg/Landscapes 01.jpg',
      '/images/homepage_bg/Landscapes 02.jpg',
      '/images/homepage_bg/Landscapes 03.jpg',
      '/images/homepage_bg/Landscapes 04.jpg',
      '/images/homepage_bg/Landscapes 05.jpg',
      '/images/homepage_bg/Landscapes 06.jpg',
      '/images/homepage_bg/Landscapes 07.jpg',
      '/images/homepage_bg/Sierras 01.jpg',
      '/images/homepage_bg/Sierras 02.jpg',
      '/images/homepage_bg/Sierras 03.jpg',
      '/images/homepage_bg/Sierras 04.jpg',
      '/images/homepage_bg/Sierras 05.jpg',
      '/images/homepage_bg/Sierras 06.jpg',
      '/images/homepage_bg/Sierras 07.jpg',
      '/images/homepage_bg/Sierras 08.jpg'
    ];

    const randomImage = images[Math.floor(Math.random() * images.length)];

    document.addEventListener('DOMContentLoaded', function() {
      document.body.style.backgroundImage = `url('${randomImage}')`;
      document.body.style.backgroundSize = 'cover';
      document.body.style.backgroundPosition = 'center';
      document.body.style.backgroundAttachment = 'fixed';
    });
  })();
</script>
  <meta name="description" content="本文知识截止至 2025.2.20 以下每节标题的标注表示该技术在这个时期趋于成熟。 Transformer 介绍（GPT-3 及之前） Transformer 是这波 AI 热潮的起点，除了它的发明以外，大模型没有魔法。 Transformer 结构的 LLM，本质是一个可并行加速的有损压缩包：它将海量的知识、语法、运算模式、应答模式等等压缩到自己的权重中。 其本体是一个由线性、非线性变换组成的">
<meta property="og:type" content="article">
<meta property="og:title" content="大语言模型（LLM）随笔">
<meta property="og:url" content="http://47.99.133.133/2025/02/20/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E9%9A%8F%E7%AC%94/index.html">
<meta property="og:site_name" content="朝汐">
<meta property="og:description" content="本文知识截止至 2025.2.20 以下每节标题的标注表示该技术在这个时期趋于成熟。 Transformer 介绍（GPT-3 及之前） Transformer 是这波 AI 热潮的起点，除了它的发明以外，大模型没有魔法。 Transformer 结构的 LLM，本质是一个可并行加速的有损压缩包：它将海量的知识、语法、运算模式、应答模式等等压缩到自己的权重中。 其本体是一个由线性、非线性变换组成的">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-02-20T17:43:34.000Z">
<meta property="article:modified_time" content="2025-02-20T17:45:32.351Z">
<meta property="article:author" content="HocRiser">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://47.99.133.133/2025/02/20/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E9%9A%8F%E7%AC%94/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>大语言模型（LLM）随笔 | 朝汐</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">朝汐</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">如星空般深蓝</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-gallery">

    <a href="/gallery/" rel="section"><i class="fa fa-image fa-fw"></i>Gallery</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/HocRiser01" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://47.99.133.133/2025/02/20/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E9%9A%8F%E7%AC%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="HocRiser">
      <meta itemprop="description" content="平凡即是喜乐">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="朝汐">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          大语言模型（LLM）随笔
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-02-20 12:43:34 / Modified: 12:45:32" itemprop="dateCreated datePublished" datetime="2025-02-20T12:43:34-05:00">2025-02-20</time>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>4.3k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>8 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><em>本文知识截止至 2025.2.20</em></p>
<p>以下每节标题的标注表示该技术在这个时期趋于成熟。</p>
<h2 id="transformer-介绍gpt-3-及之前">Transformer 介绍（GPT-3
及之前）</h2>
<p>Transformer 是这波 AI
热潮的起点，除了它的发明以外，大模型没有魔法。</p>
<p>Transformer 结构的
LLM，本质是一个可并行加速的有损压缩包：它将海量的知识、语法、运算模式、应答模式等等压缩到自己的权重中。</p>
<p>其本体是一个由线性、非线性变换组成的复杂函数，这个函数是一个文章续写器：输入是一段（编码后的）文本，输出是对这段文本的续写下一个词。与之前模型不同的是，每个预测词的生成都会考虑之前所有词（包括输入和已经生成的词），综合计算得到下一个预测词，且这个过程可以并行。</p>
<p>每次运行这个函数，会输出一个模型预测的概率最大的续写在输入之后的词（实际上是
token），然后将这个词接在输入之后形成新的输入再次运行函数，一直循环直到模型生成表示停止的
token；（以上为最基础的过程，现在已有 MTP 等优化技术）。</p>
<p>这个函数中的参数（如线性变换的系数）是可训练的，训练过程是将文字资料的一部分输入给函数，然后将函数生成的续写与文字资料原本的后续做比对，根据差异调整函数参数。</p>
<span id="more"></span>
<h2 id="模型训练与推理gpt-3.5">模型训练与推理（GPT-3.5）</h2>
<p>训练：通过调整模型参数（也即上文中的“函数参数”），使这个文章续写器的内容生成质量更高、更符合人类需要，主要包含两类：</p>
<ul>
<li><p>预训练（Pre-train）：输入（筛选后的）互联网上的海量知识，使模型学习知识、语法、运算模式等；这一步使模型成为一个语法（基本）通顺、简单数学运算（大体）正确、知识（部分）正确的文本续写器；这一步结束时，会得到一个能说会道的续写器（成为
Base 模型），但并不能正确理解并回应人类要求；</p></li>
<li><p>后训练（Post-train）：这个训练阶段用于将续写器调整成指令应答器，即让模型学会“回答”人类的指令，而不只是续写；以下为两个常见步骤（由于这一部分的训练数据量远小于
Pretrain，因此常被称为微调 Fine-tuning）：</p>
<ul>
<li>Instruction Tuning：Supervised
Fine-Tuning（SFT）的一种，使用人工标注的任务数据训练模型；训练者人工生成大量
&lt;用户提问, 机器应有的应答&gt; 对。这个过程可以使用 LLM 辅助，由 LLM
生成文本，人只需要将其整理编排成一个合适的回答。如下例，前两行是训练数据。训练完成，开始推理时，会将用户提问包装成后两行的形式，让大模型续写：</li>
</ul>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;|im_start|&gt;user&lt;|im_sep|&gt;What is 2+2?<span class="tag">&lt;<span class="name">im_end</span>&gt;</span></span><br><span class="line">&lt;|im_start|&gt;assistant&lt;|im_sep|&gt;2+2 = 4<span class="tag">&lt;<span class="name">im_end</span>&gt;</span></span><br><span class="line"></span><br><span class="line">&lt;|im_start|&gt;user&lt;|im_sep|&gt;What is 3+4?<span class="tag">&lt;<span class="name">im_end</span>&gt;</span></span><br><span class="line">&lt;|im_start|&gt;assistant&lt;|im_sep|&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>Reinforcement Learning from Human
Feedback（RLHF）：人类标注者对模型的不同输出进行排序，告诉模型什么样的输出相对更优；通过强化学习的奖励机制，使模型做出调整；这将人类从生成指令-应答对的工作中解放出来，而只需要评价，大幅减少工作量。</li>
</ul></li>
</ul>
<p>需要意识到的是，后训练让模型能够应答人类指令，但这并不改变它本质上仍然是一个“续写器”的事实，只是它续写的内容能够构成对输入指令的应答；</p>
<p>推理：训练结束后，参数固定，输入指令（以下称为
prompt），获得应答；</p>
<h2 id="模型能力">模型能力</h2>
<p>之所以后训练能够起效，是因为随着参数量和训练数据的增长，大模型涌现出了以下能力：</p>
<ul>
<li>泛化能力：可以粗略理解为“模仿能力”，它能找出训练文本或输入文本的一定规律，并使得输出也按照此规律；这使得
few-shot 甚至 zero-shot 成为可能；</li>
<li>推理能力：在数学、逻辑等理科层面进行多步逻辑推演的能力；</li>
</ul>
<p>此外，大模型还擅长完全复述，这使得输入中的一串特定文本（如一个名字、一串秘钥）能够被完全一致地输出；</p>
<p>相反，大模型不擅长以下问题：</p>
<ul>
<li>直接作答：大模型确实有推理能力，但由于模型是一个词一个词地输出，因此推理能力也分摊到每个词之上；对于一个逻辑问题，模型需要先分析（输出推理的过程）再得到结果，如果强行使它直接报出答案，正确率会很低；</li>
<li>计数问题：数用户输入中有多少个字母等；这是一个典型的“直接作答”问题，如果不可以拉长推理过程，回答很可能出错；</li>
<li>严格地推理：因为 LLM
是概率模型，每个预测词的输出都是选择概率最高的那一个；</li>
<li>改变知识：由于知识储存在模型参数中，而用户的使用不影响模型参数，因此一旦参数确定，用户无法改变大模型的知识和“信念”；</li>
<li>自我识别（self-recognition）：再次重复，大模型的本质是经过大量人为调整后的“续写器”，它之所以能条理清晰地应答用户指令，很大程度是因为它在
SFT
阶段学习了相似的用户指令，然后凭借模型自身的模仿能力，模仿生成了一段能够应答新用户问题的输出。</li>
</ul>
<h2 id="多模态与工具使用gpt-4o">多模态与工具使用（GPT-4o）</h2>
<p>多模态大模型使用共享 Transformer
结构，通过编码等技术使得文字、图像、音频最终能被嵌入到同一个 Transformer
结构中，从而在统一的框架下进行处理；</p>
<p>此外，大模型可以使用一些外部工具（浏览器搜索、计算器、代码执行器等），其流程是模型经过
SFT
后，学习到在一些情况下，生成需要在浏览器中搜索的关键字、需要计算器辅助计算的算式等，并用特殊特殊
token 包裹，然后暂停输出；系统取出特殊 token
中间的关键字或算式，交给浏览器或计算器执行，并将结果重新输入到模型中；此时模型根据输入继续预测输出，得到结果。</p>
<p>可以认为一个 LLM 应用（如
ChatGPT）是一个操作系统，其中核心是大模型（即续写器），外围是各类可以与
LLM
交互的工具。这些工具提供确定的计算结果、或是最新的网络搜索结果并交给大模型。</p>
<h2 id="模型推理gpt-o1">模型推理（GPT-o1）</h2>
<p>从前文我们已经可以得出，模型推理所需要的一个必要条件：让多个 token
分摊推理任务，而不是期望一个 token
完成全部的推理操作。此外，一个自然的想法是，对于很多问题，人类无法指定思考过程（也并不重视此过程而只重视结果），因此希望大模型自己学习出推理的能力。</p>
<p>这两个想法分别诞生了以下两个 Reasoning 关键技术：</p>
<ol type="1">
<li>慢思考：通过拉长 Chain of
Thought（思维链）长度，输出大段思考过程，从而减轻单个 token
的推理负担。这一技术用输出长度换取推理准确度；</li>
<li>强化学习：对于一些强逻辑性的推理问题，只提供问题和结果，设置合理的奖励函数，让模型自己训练出合理的思考方式；方法有
PPO、GRPO
等，这些方法可以让模型在思考的过程的某几个时刻有“自我纠错”的能力，以及重复验证的能力（类似于人类解答和检查理科试题时“用不同方法各算一次看结果是否一致”的技巧）。</li>
</ol>
<p>从此开始，大模型开始具备“思考”的能力。</p>
<h2 id="未来展望">未来展望</h2>
<p>以下为我个人极其简单粗略的预测。</p>
<h3 id="回答准确度">回答准确度</h3>
<p>这一点可以通过继续扩大基础模型参数量和训练文本量、拉长思维链、使用更优秀的强化学习实现。</p>
<p>但是，这三点的发展都将很快进入瓶颈。模型参数量和训练文本量都已经几乎达到上限（Pre-training
as we know it will unquestionably
end），思维链目前已经很长，而更优秀的强化学习算法则是极难发现的。</p>
<p>个人预测，这一轮大模型的上限将很大程度上取决于强化学习、对比学习、模仿学习等算法的进展。</p>
<h3 id="记忆能力">记忆能力</h3>
<p>大模型的上下文记忆能力仍然不够。目前的典型值为
128K，这个长度对于常规问答来说足够，但对于需要多步处理的复杂问题（如需要多次改进的编程问题、要数百步数千步才能解决的数学难题、各类因素和参数繁杂的工程问题），这个长度远远不够。</p>
<p>目前已有针对此问题提出的一些解决方案（如改用 Sparse
Attention，只计算与当前 token 关联较大的之前 token
的信息），有希望让时空复杂度低于传统 Full Attention
的长度平方复杂度而达到近线性；</p>
<p>个人预测，在不远的未来，大模型上下文能力能有显著增强，以至于可以覆盖
90% 以上的<em>单次</em>复杂任务。</p>
<h3 id="推理成本">推理成本</h3>
<p>目前以 MoE 为首的稀疏模型架构正在快速取代传统 Attention
架构，显卡支持的量化精度也在不断降低，以这个趋势发展，大模型成本将进一步降低。</p>
<p>另一方面，端侧设备往往并不需要存储大量知识，而只需要存储语法和应答模式（均用于人机交互），因此所需的参数量会远低于目前的大模型，个人预测对于端侧
AI 助理或机器人 AI 大脑（语言指令部分），70B 模型即可胜任。目前，核显 PC
或手机可以以相对可以接受的速度运行 14B 左右的模型。14B 与 70B
之间的鸿沟将由硬件与 MLsys 领域的发展来跨越。</p>
<p>个人认为，边缘设备（PC、手机、机器人）将有机会具有运行特化模型的能力，具体可行性取决于是否能跨越
14B 到 70B 的鸿沟；</p>
<h3 id="多模态能力">多模态能力</h3>
<p>目前大模型多模态能力还非常差，将多个模态的数据统一到同一空间下的难度较高，特别是图片、视频、富文本文件。</p>
<p>另一方面，在工厂、户外等场景中，有更多其它形式的富文本格式信息输入，除非有能够泛化处理各个模态信息的技术突破，否则很难胜任各类场景。</p>
<p>个人认为，未来多模态能力将有发展，能够应对更多的多模态场景，但取得突破难度较大。</p>
<h3 id="ai-agent">AI Agent</h3>
<p>在前文提到的工具使用过程中，AI 充当系统大脑的角色，这个系统就是
Agent。在完成多场景、多阶段、多目标任务时，可能需要多个 Agent
相互协调、合作，结合多个外围工具，最终完成任务。</p>
<p>这是最难攻破的领域，上文所有能力均需要突破，才能达到强大 Agent
的基础要求。如果高完成度实现，可以认为摸到 AGI 的门槛（但距离真正的 AGI
还很远，暂时不必要考虑）。</p>
<p>个人认为，这一轮 AI 热潮能诞生强 AI Agent 的概率极低，诞生 AGI
的概率更是几乎为零。但这不代表当前 LLM 路线并不能通往
AGI，只是至少还需要一两个 Transformer
级别的技术突破，短期内还不可能。</p>
<p>顺带一提，取代程序员岗位并不需要这么强的
Agent，因此取代程序员的进程会相对更快，但也要求前文四个方向全面突破，不是一蹴而就的事情。</p>
<h3 id="其余能力">其余能力</h3>
<ul>
<li>Test-time training：短期内不会有太大发展；</li>
<li>可解释性：短期内没有希望；</li>
<li>动态知识更新：将来知识更新成本会降低，频率会上升；</li>
<li>混合专家系统与定制化：每个领域都将会有所进展，能够提高相关领域研究效率，但不会对有太大影响；</li>
<li>创新与设计能力：暂时不会有显著进展；</li>
<li>人类智慧：暂时不需要考虑 AI 能够拥有自我意识的可能性；</li>
<li>自我迭代：会有进展，但难以突破。</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/11/18/%E8%A5%BF%E6%96%B9%E5%8F%A4%E8%BF%91%E4%BB%A3%E5%93%B2%E5%AD%A6%E5%8F%B2%E5%85%A5%E9%97%A8/" rel="prev" title="西方古近代哲学史入门">
      <i class="fa fa-chevron-left"></i> 西方古近代哲学史入门
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/03/04/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0/" rel="next" title="大模型推理优化笔记">
      大模型推理优化笔记 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#transformer-%E4%BB%8B%E7%BB%8Dgpt-3-%E5%8F%8A%E4%B9%8B%E5%89%8D"><span class="nav-number">1.</span> <span class="nav-text">Transformer 介绍（GPT-3
及之前）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%8E%A8%E7%90%86gpt-3.5"><span class="nav-number">2.</span> <span class="nav-text">模型训练与推理（GPT-3.5）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B"><span class="nav-number">3.</span> <span class="nav-text">模型能力</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E4%B8%8E%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8gpt-4o"><span class="nav-number">4.</span> <span class="nav-text">多模态与工具使用（GPT-4o）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86gpt-o1"><span class="nav-number">5.</span> <span class="nav-text">模型推理（GPT-o1）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B"><span class="nav-number">6.</span> <span class="nav-text">未来展望</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9E%E7%AD%94%E5%87%86%E7%A1%AE%E5%BA%A6"><span class="nav-number">6.1.</span> <span class="nav-text">回答准确度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%B0%E5%BF%86%E8%83%BD%E5%8A%9B"><span class="nav-number">6.2.</span> <span class="nav-text">记忆能力</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%A8%E7%90%86%E6%88%90%E6%9C%AC"><span class="nav-number">6.3.</span> <span class="nav-text">推理成本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E8%83%BD%E5%8A%9B"><span class="nav-number">6.4.</span> <span class="nav-text">多模态能力</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ai-agent"><span class="nav-number">6.5.</span> <span class="nav-text">AI Agent</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B6%E4%BD%99%E8%83%BD%E5%8A%9B"><span class="nav-number">6.6.</span> <span class="nav-text">其余能力</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="HocRiser"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">HocRiser</p>
  <div class="site-description" itemprop="description">平凡即是喜乐</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">41</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/HocRiser01" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;HocRiser01" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hocriser@gmail.com" title="E-Mail → mailto:hocriser@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/GGN_2015" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;GGN_2015" rel="noopener" target="_blank">GGN_2015</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://yirannn.com/" title="https:&#x2F;&#x2F;yirannn.com&#x2F;" rel="noopener" target="_blank">Yirannn</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://oceanpresent.art/" title="https:&#x2F;&#x2F;oceanpresent.art&#x2F;" rel="noopener" target="_blank">OceanPresent</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://atoposyz.github.io/" title="https:&#x2F;&#x2F;atoposyz.github.io&#x2F;" rel="noopener" target="_blank">Atoposyz</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">皖ICP备2023012352号-1 </a>
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">HocRiser</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">214k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">6:29</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("03/01/2023 10:00:00"); //此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒.";
    }
setInterval("createtime()",250);
</script>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
