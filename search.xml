<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Acts of an Ordinary Man (3) - Silicon Valley</title>
    <url>/2025/10/26/Acts-of-an-Ordinary-Man-3-Silicon-Valley/</url>
    <content><![CDATA[<blockquote>
<p>Stay hungry. Stay foolish.</p>
</blockquote>
<p>2005 年，Steve Jobs
在斯坦福大学毕业典礼上发表了著名的演讲，并以这一句作为结尾。从此，这句话通过乔布斯的演讲而广为人知，成为硅谷乃至全球创业者的座右铭。</p>
<p>从没有任何一个地方像硅谷这样如此深刻地改变了世界。</p>
<span id="more"></span>
<p>硅谷（Silicon Valley）位于加利福尼亚州旧金山湾区（San Francisco Bay
Area）南部，主要覆盖：圣塔克拉拉县（Santa Clara County） ——
核心区域（包括圣何塞 San Jose、山景城 Mountain View、帕洛阿尔托 Palo
Alto、桑尼维尔 Sunnyvale 等），以及部分圣马特奥县（San Mateo
County）和阿拉米达县（Alameda County）。</p>
<p>1939
年，惠普公司（HP）在帕洛阿尔托的一个车库中诞生，被认为是“硅谷的摇篮”。1940s–1950s，斯坦福大学鼓励教授与学生创业，设立了“斯坦福工业园”（现为斯坦福研究园），吸引高科技公司落户。“硅谷”一词来自20世纪50年代，这里集中了大量半导体（silicon
chip）制造公司。</p>
<p>1950s–1970s，以仙童半导体（Fairchild
Semiconductor）为代表的企业群体崛起。“八叛徒”（Fairchild
Eight）离开仙童创立了英特尔（Intel），奠定了硅谷半导体产业基础。</p>
<p>这里是”产学研结合“最成功的地方，也是最充满科技梦想的地方。</p>
<p>时间仓促，只逛了几个代表性的地点，探索度不到
1%。好在将来有的是机会探索这个硅基科技的圣地。</p>
<h2 id="苹果">苹果</h2>
<p>比较遗憾的是，苹果的保密严得过分。连员工都无法邀请访客进入所谓的苹果环（Apple
Park），只能参观旁边的 Visitor Centor。 <div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3489.jpg"
alt="IMG_3489" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3499.jpg"
alt="IMG_3499" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3508.jpg"
alt="IMG_3508" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3518.jpg"
alt="IMG_3518" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3519.jpg"
alt="IMG_3519" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3527.jpg"
alt="IMG_3527" /></div></div></div></div></p>
<h2 id="谷歌">谷歌</h2>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3544.jpg"
alt="IMG_3544" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3546.jpg"
alt="IMG_3546" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3547.jpg"
alt="IMG_3547" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3550.jpg"
alt="IMG_3550" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3554.jpg"
alt="IMG_3554" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3555.jpg"
alt="IMG_3555" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3557.jpg"
alt="IMG_3557" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3559.jpg"
alt="IMG_3559" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3566.jpg"
alt="IMG_3566" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3568.jpg"
alt="IMG_3568" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3570.jpg"
alt="IMG_3570" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3574.jpg"
alt="IMG_3574" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3580.jpg"
alt="IMG_3580" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3585.jpg"
alt="IMG_3585" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3588.jpg"
alt="IMG_3588" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3600.jpg"
alt="IMG_3600" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3601.jpg"
alt="IMG_3601" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3611.jpg"
alt="IMG_3611" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3617.jpg"
alt="IMG_3617" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3624.jpg"
alt="IMG_3624" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3629.jpg"
alt="IMG_3629" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3630.jpg"
alt="IMG_3630" /></div></div></div></div>
<h2 id="斯坦福">斯坦福</h2>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3648.jpg"
alt="IMG_3648" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3649.jpg"
alt="IMG_3649" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3651.jpg"
alt="IMG_3651" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3655.jpg"
alt="IMG_3655" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3659.jpg"
alt="IMG_3659" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3663.jpg"
alt="IMG_3663" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3667.jpg"
alt="IMG_3667" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3668.jpg"
alt="IMG_3668" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3671.jpg"
alt="IMG_3671" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3675.jpg"
alt="IMG_3675" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3677.jpg"
alt="IMG_3677" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3680.jpg"
alt="IMG_3680" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3681.jpg"
alt="IMG_3681" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3687.jpg"
alt="IMG_3687" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3688.jpg"
alt="IMG_3688" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3690.jpg"
alt="IMG_3690" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3693.jpg"
alt="IMG_3693" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3696.jpg"
alt="IMG_3696" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3697.jpg"
alt="IMG_3697" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3698.jpg"
alt="IMG_3698" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/硅谷/IMG_3701.jpg"
alt="IMG_3701" /></div></div></div></div>
]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
  <entry>
    <title>Acts of an Ordinary Man (2) - San Francisco</title>
    <url>/2025/10/26/Acts-of-an-Ordinary-Man-2-San-Francisco/</url>
    <content><![CDATA[<blockquote>
<p><em>If you’re going to San Francisco, be sure to wear some flowers in
your hair.</em></p>
<p><em>如果你要去旧金山，记得在头上戴朵花。</em></p>
</blockquote>
<p>1967 年夏天被称为“Love Summer”。在《San
Francisco》这首歌的感召下，超过 10
万年轻人涌入这座城市。他们来自全美各地，怀抱音乐、理想与梦想。公园里举行大型免费演唱会、冥想、诗歌朗诵。人们穿着彩色服装、戴花环、互赠和平标志。从此，加州和旧金山便成为嬉皮士文化的象征。</p>
<p>那是一个美好而疯狂的矛盾年代。</p>
<span id="more"></span>
<h2 id="历史">历史</h2>
<p>欧洲人在 1542 年到达旧金山湾区，旧金山区域在 16
世纪属于西班牙的上加利福尼亚省领土，传教士将此地命名为“Yerba
Buena”。1821
年，墨西哥自西班牙独立，上加利福尼亚也成为墨西哥领土。美墨战争爆发后，美国海军准将约翰·斯洛特带领手下来到这里，1846年以美国名义占领此城，改名为
“San Francisco”。</p>
<p>19
世纪这里是美国加州淘金潮的中心地区，早期华工到美国淘金后多居住于此，称之为“金山”，但直到在澳大利亚的墨尔本附近发现金矿后，为了与被称作新金山的墨尔本区别，而改称这个城市为“旧金山”。旧金山逐渐发展成美国西岸的金融中心。在金融商业区的蒙哥马利街有“西部的华尔街”之称，位于这条街上的有联邦储备银行旧金山分行和太平洋证券交易所（Pacific
Stock Exchange）旧址。全美最大银行美国银行也创始于此。</p>
<p>内战后，由于中央太平洋铁路完工，美国东西海岸之间的交通障碍明显缩小，商人可以把货物通过旧金山直接输往亚洲。而当时适逢日本开国以及中国因第二次鸦片战争后通商口岸增多而扩大开放，亚洲市场成为美国商品的新市场，坐拥良港的旧金山成为西海岸的经济中心。到了
19
世纪末，旧金山已经拥有繁荣的工业、商业、贸易、金融行业，成为北美洲西海岸和美国密西西比河以西举足轻重的重要都会。</p>
<p>受 1882 年《排华法案》的影响，许多从 19 世纪中叶到 20
世纪初的华人和其他亚裔移民在美国倍受歧视。旧金山地震引起的大火烧毁了当时市政厅的档案纪录，让许多华人有了机会，利用购买的伪造出生纸，以假造美籍华人儿女的身份进入美国，即是后人所称的纸儿子。纸儿子的出现也造成许多华人后裔无法回归真实的姓氏和家族史，成为特殊的华人移民史。</p>
<p>20 世纪 60
年代中期，美国经济繁荣、科技进步，另一方面整体社会氛围保守传统，且笼罩在冷战的阴云之下。主流文化宣扬“消费、成功、服从”，令年轻人感到精神空虚与社会虚伪。于是，反主流青年文化运动嬉皮士（Hippies）兴起。年轻人们反对战争（越战）、资本主义、社会等级，追求和平、爱、自由、自然和精神觉醒。他们想用“爱与音乐”去对抗“战争与权力”。</p>
<p>然而由于这群年轻人本身娇生惯养，缺乏社会阅历，并没有一套成熟的政治哲学框架，使得该运动最终堕落成毒品、性泛滥的大型狂欢活动，并最终于
1968
年底逐渐消亡，并转向生态主义（绿色运动）、灵性冥想和科技乌托邦主义。其多元包容、瑜伽、自由等理念影响了后续的硅谷理想主义创业精神和整个美国的文艺界，”Peace
&amp; Love“的口号也流传至今。</p>
<p>嬉皮士运动深刻影响了乔布斯，使其坚守极简主义、印度冥想文化，并将自己的理念融入到后续对苹果公司产品的每个方面，最终进一步影响了硅谷乃至整个世界的科技人文方向。</p>
<h2 id="金门大桥">金门大桥</h2>
<p>离开西雅图，我们便启程前往 SF。经过一天的赶路，跨过海湾大桥，便来到了
SF
市区。由于没有订到合适的酒店，我们只能下榻一家相对简陋且安全性较低的汽车旅馆（Motel）。SF
和西雅图一样遍地都是 homeless。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2897.jpg"
alt="IMG_2897" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2908.jpg"
alt="IMG_2908" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2911.jpg"
alt="IMG_2911" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2921.jpg"
alt="IMG_2921" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2924.jpg"
alt="IMG_2924" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2927.jpg"
alt="IMG_2927" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2940.jpg"
alt="IMG_2940" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2946.jpg"
alt="IMG_2946" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2950.jpg"
alt="IMG_2950" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2953.jpg"
alt="IMG_2953" /></div></div></div></div>
<p>金门大桥（Golden Gate Bridge）是连接旧金山半岛与马林县（Marin
County）之间的重要悬索桥，横跨著名的金门海峡（Golden Gate Strait）。在
1930
年代建造时，它是世界上最长、最高的悬索桥，是旧金山最著名的象征之一，经常出现在电影、明信片与旅游宣传中。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2976.jpg"
alt="IMG_2976" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_2994.jpg"
alt="IMG_2994" /></div></div></div></div>
<h2 id="渔人码头">渔人码头</h2>
<p>渔人码头（Fisherman’s
Wharf）最初是意大利移民渔民的工作码头，后转为旅游区。</p>
<p>恶魔岛（Alcatraz
Island）以前是一座高度戒备的联邦最高级别监狱，因岛上地势孤立、海流湍急，被认为是“最难逃脱的地方”，负责关押最危险、最难管理的罪犯。由于维护成本过高，监狱于1963
年关闭，并于 1970s 开放为国家公园。</p>
<p>在这里一家华人开的小餐车买了个很好吃的 mini donuts，喝了蛤蜊汤。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3016.jpg"
alt="IMG_3016" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3018.jpg"
alt="IMG_3018" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3020.jpg"
alt="IMG_3020" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3024.jpg"
alt="IMG_3024" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3029.jpg"
alt="IMG_3029" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3031.jpg"
alt="IMG_3031" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3040.jpg"
alt="IMG_3040" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3059.jpg"
alt="IMG_3059" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3060.jpg"
alt="IMG_3060" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3073.jpg"
alt="IMG_3073" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3075.jpg"
alt="IMG_3075" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3078.jpg"
alt="IMG_3078" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3080.jpg"
alt="IMG_3080" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3083.jpg"
alt="IMG_3083" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3086.jpg"
alt="IMG_3086" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3091.jpg"
alt="IMG_3091" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3093.jpg"
alt="IMG_3093" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3100.jpg"
alt="IMG_3100" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3103.jpg"
alt="IMG_3103" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3107.jpg"
alt="IMG_3107" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3111.jpg"
alt="IMG_3111" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3120.jpg"
alt="IMG_3120" /></div></div></div></div>
<h2 id="唐人街">唐人街</h2>
<p>旧金山唐人街位于美国加利福尼亚州旧金山市中心，是北美最古老、规模最大的华人社区之一，保留了非常多中式牌楼、飞檐屋顶等建筑。其春节游行（Chinese
New Year Parade）是全美规模最大的亚洲节日庆典之一。</p>
<p>其中丁丁车（San Francisco Cable Car）系统建于 19
世纪后期，是这座城市最著名的交通标志之一，也是世界上现存唯一仍在运行的手动缆车系统。不远处的九曲花街（Lombard
Street）以极其蜿蜒的路段和两侧盛开的花卉而闻名，被称为“世界上最弯曲的街道”。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3128.jpg"
alt="IMG_3128" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3136.jpg"
alt="IMG_3136" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3149.jpg"
alt="IMG_3149" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3151.jpg"
alt="IMG_3151" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3155.jpg"
alt="IMG_3155" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3160.jpg"
alt="IMG_3160" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3162.jpg"
alt="IMG_3162" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3166.jpg"
alt="IMG_3166" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3168.jpg"
alt="IMG_3168" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3172.jpg"
alt="IMG_3172" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3181.jpg"
alt="IMG_3181" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3189.jpg"
alt="IMG_3189" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3192.jpg"
alt="IMG_3192" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3196.jpg"
alt="IMG_3196" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3198.jpg"
alt="IMG_3198" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3204.jpg"
alt="IMG_3204" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3205.jpg"
alt="IMG_3205" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3206.jpg"
alt="IMG_3206" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3222.jpg"
alt="IMG_3222" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3231.jpg"
alt="IMG_3231" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3246.jpg"
alt="IMG_3246" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3255.jpg"
alt="IMG_3255" /></div></div></div></div>
<h2 id="一号公路">一号公路</h2>
<p>加利福尼亚州1号公路（California State Route
1），沿着太平洋海岸线蜿蜒伸展，被誉为世界上最美的自驾路线。起点旧金山，途径半月湾（Half
Moon Bay）、蒙特雷（Monterey）、大苏尔（Big Sur）、圣西蒙（San
Simeon），最终抵达圣塔芭芭拉（Santa Barbara）。</p>
<p>在我的强烈要求下，我们选了一条走一号公路最长的路线，并貌似误入了一个富人庄园，见识了一下海边高尔夫球场。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3272.jpg"
alt="IMG_3272" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3278.jpg"
alt="IMG_3278" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3282.jpg"
alt="IMG_3282" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3311.jpg"
alt="IMG_3311" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3314.jpg"
alt="IMG_3314" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3316.jpg"
alt="IMG_3316" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3318.jpg"
alt="IMG_3318" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3324.jpg"
alt="IMG_3324" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3325.jpg"
alt="IMG_3325" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3327.jpg"
alt="IMG_3327" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3333.jpg"
alt="IMG_3333" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3345.jpg"
alt="IMG_3345" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3359.jpg"
alt="IMG_3359" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3363.jpg"
alt="IMG_3363" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3386.jpg"
alt="IMG_3386" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3414.jpg"
alt="IMG_3414" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3423.jpg"
alt="IMG_3423" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3446.jpg"
alt="IMG_3446" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3453.jpg"
alt="IMG_3453" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3463.jpg"
alt="IMG_3463" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3475.jpg"
alt="IMG_3475" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/旧金山/IMG_3478.jpg"
alt="IMG_3478" /></div></div></div></div>
]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
  <entry>
    <title>Acts of an Ordinary Man (1) - Seattle</title>
    <url>/2025/10/26/Acts-of-an-Ordinary-Man-1-Seattle/</url>
    <content><![CDATA[<blockquote>
<p><em>Will the last person leaving Seattle, please turn out the
lights?</em></p>
<p><em>麻烦最后离开西雅图的人，把灯关掉。</em></p>
</blockquote>
<p>1971
年，西雅图最大的雇主波音公司（Boeing）由于航空需求暴跌，一年内解雇了超过
6
万名员工，导致这座城市失业率一度达到两位数。市区空荡、房价暴跌，人们纷纷离开，去别的城市谋生，西雅图成了一座“被波音遗弃的城”。两位本地广告人在西雅图的州际公路
I-5 上租下了一块大广告牌，写下了这句话。</p>
<span id="more"></span>
<p><img src="lights.jpg" /></p>
<p>时过境迁，1970s
末，波音逐渐恢复生产。1980s，微软成立并崛起于西雅图郊区的
Redmond。1990s，亚马逊、星巴克、Nirvana
等陆续登上世界舞台。软件、生物技术和互联网公司的蓬勃发展推动了经济的复兴，使西雅图成为
2010 至 2020 年间美国发展速度最快的主要城市之一。</p>
<p>西雅图重新点亮了自己的灯。</p>
<h2 id="启程">启程</h2>
<p>12 月 17 日早，我们从北卡坐飞机抵达西雅图，开始了我们为期 20
多天的美西之旅。我们落地后租了一辆尼桑
SUV，计划从美国的西北角一路向南走，到西南端的加州后再北上走到中西部的犹他州，最后在黄石公园结束行程。</p>
<p>作为旅途第一站，西雅图用严冬的鹅毛大雪迎接我们。美国规定雪天山路行驶必须装备雪链，但我们没买。后续几天一直活在对警察突击检查的担忧中，但最后也没有被查到。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2140.jpg"
alt="IMG_2140" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2144.jpg"
alt="IMG_2144" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2157.jpg"
alt="IMG_2157" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2158.jpg"
alt="IMG_2158" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2170.jpg"
alt="IMG_2162" /></div></div></div></div>
<p>夜晚抵达市区，又正逢一场大雨。于是在 Pike Place Market
附近来了一场雨夜 Citywalk。</p>
<p>20
世纪初，西雅图的物价被中间商操控，市民买菜昂贵，农民却赚不到钱。1907
年，市议员 Thomas Revelle
提出建立一个让农民直接面对顾客的市场。派克市场就此诞生，并成为“美国公共市场运动的先驱”。</p>
<p>这里的星巴克是全球第一家门店，保留了最初的棕色双尾美人鱼
Logo。口香糖墙（The Gum
Wall）是西雅图最奇特的“非官方景点”之一，游客用五颜六色的口香糖贴满墙壁，形成“另类艺术墙”。2015
年曾被彻底清洗，清理出超过 2 吨口香糖，但几周内又“满血复活”。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2178.jpg"
alt="IMG_2173" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2178.jpg"
alt="IMG_2178" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2181.jpg"
alt="IMG_2181" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2192.jpg"
alt="IMG_2192" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2195.jpg"
alt="IMG_2195" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2197.jpg"
alt="IMG_2197" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2222.jpg"
alt="IMG_2222" /></div></div></div></div>
<h2 id="太空针塔">太空针塔</h2>
<p>太空针塔（Space
Needle）是美国西北太平洋地区的一座主要地标。因1962年世界博览会在西雅图举办而兴建（那届世博会的主题是“人类在太空时代的愿景”），仅花了
400 天建成。高约 184
米，是当时西雅图最高的大楼。从塔顶观景台眺望，不单能看到全西雅图市中心的景观，还可以看到奥林匹克山脉、喀斯喀特山脉等。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2237.jpg"
alt="IMG_2242" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2242.jpg"
alt="IMG_2242" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2257.jpg"
alt="IMG_2257" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2261.jpg"
alt="IMG_2261" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2296.jpg"
alt="IMG_2271" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2307.jpg"
alt="IMG_2273" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2291.jpg"
alt="IMG_2291" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2302.jpg"
alt="IMG_2302" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2311.jpg"
alt="IMG_2311" /></div></div></div></div>
<p>太空针塔脚下是奇胡利玻璃艺术馆（Chihuly Garden and Glass）。Dale
Chihuly（戴尔·奇胡利）是当代最著名的玻璃艺术大师，以“将玻璃变为流动的雕塑”而闻名。其作品以鲜艳的色彩、自然的曲线与巨型装置著称，常常模仿海洋生物、花朵、珊瑚、藤蔓等自然形态。</p>
<p>进艺术馆看到一位华人面貌的街头艺术家在拉小提琴，被声音吸引过去拍照，却被对方喝止“No
tips, no
photos”，意思是不给小费就不让拍照，令我大为震撼，遂悻悻离开。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2329.jpg"
alt="IMG_2329" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2335.jpg"
alt="IMG_2335" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2336.jpg"
alt="IMG_2336" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2339.jpg"
alt="IMG_2339" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2342.jpg"
alt="IMG_2342" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2344.jpg"
alt="IMG_2344" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2345.jpg"
alt="IMG_2345" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 100%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2350.jpg"
alt="IMG_2350" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2356.jpg"
alt="IMG_2356" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2358.jpg"
alt="IMG_2358" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2363.jpg"
alt="IMG_2363" /></div></div></div></div>
<p>出来发现竟然有一个纪念甘地和各国和平的一小片公园。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2380.jpg"
alt="IMG_2380" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2382.jpg"
alt="IMG_2382" /></div></div></div></div>
<h2 id="citywalk">Citywalk</h2>
<p>接下来便是白天份的
Citywalk。途径亚马逊和星巴克总部。在亚马逊著名的免费香蕉餐车拿了根香蕉，剥开里面是烂的，预示着后续求职与它彻底无缘。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2403.jpg"
alt="IMG_2403" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2410.jpg"
alt="IMG_2410" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2420.jpg"
alt="IMG_2420" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2427.jpg"
alt="IMG_2427" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2432.jpg"
alt="IMG_2432" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2436.jpg"
alt="IMG_2436" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2439.jpg"
alt="IMG_2439" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2448.jpg"
alt="IMG_2448" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2450.jpg"
alt="IMG_2450" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2455.jpg"
alt="IMG_2455" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2458.jpg"
alt="IMG_2458" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2461.jpg"
alt="IMG_2461" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2467.jpg"
alt="IMG_2467" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2476.jpg"
alt="IMG_2476" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2480.jpg"
alt="IMG_2480" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2483.jpg"
alt="IMG_2483" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2486.jpg"
alt="IMG_2486" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2490.jpg"
alt="IMG_2490" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2492.jpg"
alt="IMG_2492" /></div></div></div></div>
<h2 id="飞行博物馆">飞行博物馆</h2>
<p>西雅图飞行博物馆（The Museum of Flight）成立于 1965
年，位于美国华盛顿州西雅图南部波音公司机场内，是美国西海岸规模最大的航空航天博物馆
。该馆收藏超过 175
架飞机及航天器、2.8万多件航空文物，涵盖从莱特兄弟早期飞行器到现代波音客机的完整航空发展史，其中包含波音
727、737、747原型机、协和客机等标志性展品。</p>
<p>在这个博物馆，可以看到上世纪整个航空、航天史，以及太空军备竞赛的全过程。但最令人感兴趣的还是，美国官方视角下的朝鲜战争、越南战争和美苏争霸。其中一战、二战历史分管则是用标准的西方视角进行叙述。照片太多，这里仅选取部分。</p>
<p>离博物馆仅 2 mile 便是贝索斯的“蓝色起源”（Blue Origin）总部。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2520.jpg"
alt="IMG_2520" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2529.jpg"
alt="IMG_2529" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2534.jpg"
alt="IMG_2534" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2537.jpg"
alt="IMG_2537" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2539.jpg"
alt="IMG_2539" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2543.jpg"
alt="IMG_2543" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2548.jpg"
alt="IMG_2548" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2550.jpg"
alt="IMG_2550" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2553.jpg"
alt="IMG_2553" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2556.jpg"
alt="IMG_2556" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2558.jpg"
alt="IMG_2558" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2561.jpg"
alt="IMG_2561" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2563.jpg"
alt="IMG_2563" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2567.jpg"
alt="IMG_2567" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2574.jpg"
alt="IMG_2574" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2578.jpg"
alt="IMG_2578" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2579.jpg"
alt="IMG_2579" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2584.jpg"
alt="IMG_2584" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2594.jpg"
alt="IMG_2594" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2603.jpg"
alt="IMG_2603" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2617.jpg"
alt="IMG_2617" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2622.jpg"
alt="IMG_2622" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2656.jpg"
alt="IMG_2656" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2666.jpg"
alt="IMG_2666" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2671.jpg"
alt="IMG_2671" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2677.jpg"
alt="IMG_2677" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2687.jpg"
alt="IMG_2687" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2688.jpg"
alt="IMG_2688" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2689.jpg"
alt="IMG_2689" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2693.jpg"
alt="IMG_2693" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2696.jpg"
alt="IMG_2696" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2697.jpg"
alt="IMG_2697" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2700.jpg"
alt="IMG_2700" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2703.jpg"
alt="IMG_2703" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2710.jpg"
alt="IMG_2710" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2715.jpg"
alt="IMG_2715" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2721.jpg"
alt="IMG_2721" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2729.jpg"
alt="IMG_2729" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2736.jpg"
alt="IMG_2736" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2741.jpg"
alt="IMG_2741" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2746.jpg"
alt="IMG_2746" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2754.jpg"
alt="IMG_2754" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2759.jpg"
alt="IMG_2759" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2761.jpg"
alt="IMG_2761" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2762.jpg"
alt="IMG_2762" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2768.jpg"
alt="IMG_2768" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2772.jpg"
alt="IMG_2772" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2774.jpg"
alt="IMG_2774" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2783.jpg"
alt="IMG_2783" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2785.jpg"
alt="IMG_2785" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2788.jpg"
alt="IMG_2788" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2793.jpg"
alt="IMG_2793" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2796.jpg"
alt="IMG_2796" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2805.jpg"
alt="IMG_2805" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2815.jpg"
alt="IMG_2815" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2817.jpg"
alt="IMG_2817" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2819.jpg"
alt="IMG_2819" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2825.jpg"
alt="IMG_2825" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2830.jpg"
alt="IMG_2830" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2839.jpg"
alt="IMG_2839" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2841.jpg"
alt="IMG_2841" /></div><div class="group-picture-column" style="width: 50%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2848.jpg"
alt="IMG_2848" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 100%;"><img
src="https://cdn.jsdelivr.net/gh/HocRiser01/Gallery@main/5-3/西雅图/IMG_2851.jpg"
alt="IMG_2851" /></div></div></div></div>
]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
  <entry>
    <title>太空人-行前篇</title>
    <url>/2025/10/03/%E5%A4%AA%E7%A9%BA%E4%BA%BA-%E8%A1%8C%E5%89%8D%E7%AF%87/</url>
    <content><![CDATA[<blockquote>
<p><em>必死に　ただ閃雲に空に手を伸ばして</em></p>
<p><em>拼命地，只是向着闪光的云空伸出手去</em></p>
</blockquote>
<p>本系列为个人美国留学生活记录，分为行前篇、校园篇和旅行篇。</p>
<p>标题《太空人》取自新海诚电影《秒速五厘米》人生三部曲第二篇章
<em>コスモナウト</em>，源自俄语
<em>Cosmonaut</em>（宇航员），讲述成长后、毕业前这个阶段的，青春独有的迷茫、期许和无奈。</p>
<p>让我们从 2023 年夏说起。</p>
<span id="more"></span>
<h2 id="第一段实习">第一段实习</h2>
<p>2023
年，在大家都为了各个保研夏令营天南海北奔走的夏天，随着我在杭州阿里总部食堂里远程遥控我的同学帮我签了放弃保研承诺书，我知道自己已经没有回头路了。要等到十月才开始出国申请，次年四月才能知道结果，这意味着无论申请结果如何，我都必须全盘接受并押上家里七位数资产，去追逐自己这个虚无缥缈的太空人的梦。</p>
<p>简单讲一下我的本科四年，总体来看是非常轻松悠闲的四年。由于高中的竞赛经历，大一上选择进校队打
ACM，不到一学期因对竞赛无感、且与教练不合退役；大一下进组做科研，因为完全没有人指导，浑浑噩噩做了两年，几乎没有成果，认定自己不是这块料，因而决定从此不碰科研；除此之外零零散散参加了一些
CTF
竞赛（因为队友网线坏了用了我的而睡了一整场的觉）、混了些社团、办了些编程比赛。长期摆烂导致
GPA 比较难看（靠着刷分勉强刷上 3.8，最后 WES 认证没上
3.9），同时了解到保研大部分情况下最后的去向都是由导师和实验室安排好的，而我极其不适合在导师要求下学习，也希望能给自己将来的研究领域更大的选择权。另一方面，我是疫情三年完整的亲历者（长春是当时全国最严重的区域之一），其间种种也给了我三观不小的震撼。总而言之，由于各个方面的因素，在大三下我最终决定赴美留学。</p>
<p>具体是怎么决定下来的，我一直没有印象。可能是想着想着，某一天就不再考虑保研了。北美硕士申请无非看三个因素：标化（GPA、语言成绩），经历（论文、实习），文书（SoP、CV、推荐信）。语言方面我用两个暑假分别把
Toefl、GRE
考上门槛线（现在来看托福完全应该再多考几次，虽然当时考了一次就完全不想碰了也没办法）。GPA
上我完全不想努力，也没有花什么功夫；文书之类的基本上就是中文写好一份模板，把其中几个关键地方改成目标学校的特色，翻译成英文，再找个软件润色一下就结束了。</p>
<p>最后还能努力的空间只剩实习，于是我把自己听说过的互联网公司列了张表，开始挨个投递。当时并不了解什么日常、暑期实习，更不了解不同岗位的区别和要求，几乎是闭着眼睛乱投。大部分公司都有投递上限（那是正好是阿里拆分前两个月，还是非独立招聘的，整个集团只能投三个志愿），对于没有上限的比如字节，我花了一天时间把所有开放的实习岗位全投了一遍（88
个岗位），最后一个面试也没拿到。</p>
<p>运气非常好，唯一拿到的面试就是阿里淘天集团的 C++
开发岗，意外地很顺利地三轮面试都通过了。工作是为淘宝的 AR/VR 3D
引擎写插件，技术栈非常多样，是个很有挑战性也很有趣的项目。后来进去后才知道，其实我当时排序第三，只有一个
HC，第一名把阿里鸽了，第二名组里小老板非常看好，但大老板一票否决了，最后才很幸运地轮到了我。可惜让老板们失望了，整个实习期间我几乎全部都在背
GRE 单词、学 Modern C++ 和
C#，加上对组里业务和技术栈完全不熟，最后几乎没有多少产出。老板说，产出完全不够留用，不想转正的话就走人，于是我只干了两个月就被迫走人了。</p>
<p>话说回来，这两个月过得还是非常精彩的，头一次进到一线城市的顶级大厂，头一次对计算机这个行业有了一个比较全面的认知，也是头一次了解到业界真实的样貌，眼界大开。只不过当时我不知道，就像《中国太阳》里水娃头一回进京城一样，之后有的是眼界大开的时刻，这才刚刚开始。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="ali-1.jpg" alt="ali-1" /></div><div class="group-picture-column" style="width: 50%;"><img src="ali-2.jpg" alt="ali-2" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="ali-3.jpg" alt="ali-3" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="ali-4.jpg" alt="ali-4" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="ali-5.jpg" alt="ali-5" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="ali-6.jpg" alt="ali-6" /></div><div class="group-picture-column" style="width: 50%;"><img src="ali-7.jpg" alt="ali-7" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="ali-8.jpg" alt="ali-8" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="ali-9.jpg" alt="ali-9" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="ali-10.jpg" alt="ali-10" /></div></div></div></div>
<h2 id="第二段实习">第二段实习</h2>
<p>时间来到 23
年底，此时我已完成所有学校的申请，大四也没有别的事情，毕业论文我直接用之前失败的论文作品稍作修改，总共只花了两天。于是，虽然对申请已无作用，我还是决定用大四的时间再进行一段实习。</p>
<p>这一次，我的目标更明确些，不再关注国内互联网大厂，而是转而关注一些美国公司。当时正值寒假，几乎没有公司开放，我破罐子破摔地在牛客上找到一家叫英伟达的公司正在招
25 届的实习生。23 年底正是 LLM 的爆发期，NVIDIA
毫无疑问是这一波红利的受益者。因为经常看科技新闻的缘故，我对它的印象也从一家游戏芯片公司变成了一家
AI 芯片公司。我完全没报希望地给数月没上线的猎头留了言，问 24
届本科生是否能做一段时间日常实习。完全没想到的是，这一无心之举完全改变了我今后的人生。经过三轮不痛不痒的面试（问的几乎都是游戏显卡的问题，我从来不玩主机游戏，但凭着平时看科技新闻的见识竟然基本都应付了下来），和多次邮件催促，我竟然拿到了这次不可思议的实习的机会。</p>
<p>现在回头看，24
年春在上海张江的这三个月的实习经历，可以说是几乎毫无收获。岗位是最水的测试开发（JD
并没有写，我也没在意），每天的工作就是将实验室里的各种 GPU
插到测试机上，用现成的脚本测试各种视频软件、游戏、AI
应用的显卡性能。脚本挂了的时候就手动测试，或者修一修代码的 bug，调一调
OCR 等插件的参数。大部分时间就是在内部平台的 GUI 上部署
task，然后监控每台机子，再不然就是组装测试机、修电脑、重装显卡驱动等等杂活。</p>
<p>但是，实习之外对我的影响就太大了。首先是上海这座城市，虽然我以前来过很多次，但这是第一次我单独从一个打工人而不是一个单纯的游客的世界去感受它。我感受到它的繁华、多元和激情，也被它所震撼。在这里定居成了年少的我心中的第一个真实的梦想，虽然它是那么的遥不可及。这三个月，我几乎玩遍了上海的所有大小景点，感受着它的每一次呼吸，也第一次如此想清楚自己究竟想要什么，为了什么而前进。</p>
<p>另一方面，我在公司楼下一条人工河的对面租了个单间，不行上班只需 5
分钟。一个合租人也是 NV
的正式员工，从华为跳槽的，能力非常强。有一天晚上我门敞开着，他便到我的房间来闲聊几句。发现我们都看日本动漫作品、都打过计算机竞赛，便有了一些共同话题。然后我抓住机会问了他的工作，他便向我介绍了国内负责的
NV
高性能计算库和编译器部分。那个晚上总共聊了不到一个小时，我也完全没意识到这次对话有什么价值，但它将在一年后彻底改变我的人生轨迹。</p>
<p><em>题外话，在我入职前一个月的 NV
年会上黄仁勋来上海给所有员工都拍了合照、签了 to
签，当时老板邀请我，但我因为不在上海，且以为只是普通的饭局，于是痛失这个与老黄零距离接触的机会，懊悔至今
:)</em></p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="nv-1.jpg" alt="nv-1" /></div><div class="group-picture-column" style="width: 50%;"><img src="nv-2.jpg" alt="nv-2" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-3.jpg" alt="nv-3" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-4.jpg" alt="nv-4" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-5.jpg" alt="nv-5" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-6.jpg" alt="nv-6" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-7.jpg" alt="nv-7" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-8.jpg" alt="nv-8" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="nv-9.jpg" alt="nv-9" /></div><div class="group-picture-column" style="width: 50%;"><img src="nv-10.jpg" alt="nv-10" /></div></div></div></div>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-11.jpg" alt="nv-11" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-12.jpg" alt="nv-12" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-13.jpg" alt="nv-13" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="nv-14.jpg" alt="nv-14" /></div><div class="group-picture-column" style="width: 50%;"><img src="nv-15.jpg" alt="nv-15" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="nv-16.jpg" alt="nv-16" /></div><div class="group-picture-column" style="width: 50%;"><img src="nv-17.jpg" alt="nv-17" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-18.jpg" alt="nv-18" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-19.jpg" alt="nv-19" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="nv-20.jpg" alt="nv-20" /></div></div></div></div>
<h2 id="行前准备">行前准备</h2>
<p>随着第二段实习结束，我的申请季也宣告结束。总结下来，我的申请策略总体没有什么问题，总共是拿了
6 个 offer。根据专排、总排、OpenCS 评级等指标最后综合选择了 Duke MS
ECE（小插曲：由于漏看了邮件，起初我一直不知道自己拿了 Duke MS ECE 的
offer，直到决定回复 Duke ECE MEng 的时候才在 Portal 上看到 MS ECE
也录取了）。</p>
<p><img src="app-result.png" /></p>
<p>整个申请过程不可谓不繁琐，需要找到每个院校项目的官方网站并仔细阅读，了解院系的偏好、主要的教授与他们研究的方向。每个学院都要专门准备一份
SoP，很多像 CMU
这种学校还需要专门为它设置的繁多问答题分别写回复，还有的项目需要录一个
video interview
甚至需要远程面试。二十多个项目全部申下来工作量巨大，更不用提语言考试（GRE
第一次考试没上门槛线）、成绩认证的各种麻烦，以及为了防止敏感行业签证问题而额外做的各类书面工作。为了省钱和锻炼克服对英文网页的恐惧，我坚持
DIY
而不找中介，只是打电话给几个中介咨询了一下选项方案。事实证明，中介给的目标院校档次会明显虚高，现在
AI 工具的成熟也让中介的定位愈发尴尬，唯一所谓的优势“信息差”也被 OpenCS
和一亩三分地等网站所替代。站在现在这个时间点，我不建议任何人找中介。</p>
<p>我的文书策略是，将自己包装成对人工智能和人机交互相关的研究者。一方面是因为我之前的科研项目都与此有关，另一方面是这些方向适合引导至美国最爱的政治正确、人文关怀、理想抱负等等方面的表达（当时正值民主党执政，且院校内意识形态明显比平均水平更左）。</p>
<p>签证最后还是毫无悬念地 check
了，我护照是在上海办的，签证在沈阳，抽到了一个态度一般的黑女，见面的第一眼我就猜到会先
refuse
了，好在后续让我邮件提交了一系列本科导师材料和证明，又等了一个多月成功下签，虽然只有一年（正常学签是五年）。</p>
<p>万事俱备，剩下的就是抓紧享受国内的大学生活了。大四这一年，我玩了杭州、上海、苏州、无锡、合肥、南京、哈尔滨、延吉，毕业旅行去的是大连和北京。到北卡罗莱纳州最便宜的机票是从厦门出发，临走前，全家人为我送行，顺便把厦门玩了一圈。从学校到家再到厦门，跨越了黄河，跨越了长江，该跨越太平洋了。</p>
<p>好。那么，走罢！</p>
<p>去美国。</p>
]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
  <entry>
    <title>Per-block 量化混合精度卷积实现与 GEMM、GEMV 优化</title>
    <url>/2025/07/04/Per-block-%E9%87%8F%E5%8C%96%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B0%E4%B8%8E-GEMM%E3%80%81GEMV-%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="问题定义">问题定义</h2>
<p>输入两个 Tensor：<span class="math inline">\(input[Batch, Ci, Ih,
Iw]\)</span> （经典 NCHW 布局）、<span class="math inline">\(kernel[Co,
Ci, Kh, Kw]\)</span>（为适应 Coalesced Access 可重排为 <span
class="math inline">\([Co, Kh, Kw, Ci]\)</span>），其中前者为 FP32/FP16
类型，后者为 INT4/INT8 类型。输出卷积结果。</p>
<p>可以发现，对于 <span class="math inline">\(Iw = Ih = Ow = Oh = Kw =
Kh = Dw = Dh = Sw = Sh = 1\)</span>（输入、输出、卷积核尺寸、扩张率
Dilute、步长 Stride 均为 1x1），<span class="math inline">\(Pw = Ph =
0\)</span>（不填充）的情况，卷积退化为标准卷积乘法 <span
class="math inline">\([Batch, Ci] \times [Ci, Co]\)</span>，以下简记为
<span class="math inline">\(A[N, K] \times B[K,
M]\)</span>。（当然，即使不是如此，也可以通过 Im2Col 或 Implicit Conv
等方式将其转换成可直接使用加速库的矩阵乘法）。</p>
<p>对于 <span class="math inline">\(B\)</span>（在 LLM
推理中通常为量化后权重矩阵），采用 Per-block 量化，即在 <span
class="math inline">\(K\)</span> 维度上，每 <span
class="math inline">\(block\_size\)</span> 个元素共享一套量化参数（<span
class="math inline">\(scale\)</span> 和 <span
class="math inline">\(zero\_point\)</span>），<span
class="math inline">\(M\)</span> 维度不共享。因此可以理解为，将 <span
class="math inline">\(B\)</span> 的每列按 <span
class="math inline">\(block\_size\)</span> 划分为多个竖条，总块数为
<span class="math inline">\(K / block\_size \times M\)</span>。</p>
<span id="more"></span>
<h2 id="初探">初探</h2>
<h3 id="conv_fpaint4b">CONV_FpAInt4B</h3>
<p>首先，卷积可以按照原始定义实现，我们对 <span
class="math inline">\(B\)</span>
在线反量化（离线反量化就失去量化本身的意义了），并要求一个量化块在同一个线程内处理从而共享量化参数。因此，我们让每个线程负责一个输出点，实现它的计算过程即可。</p>
<p>理论上有较大优化空间，但并非本文重点。INT4
需要加一个简单的解包，不再赘述。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">CONV_FpAInt4B</span><span class="params">(<span class="type">const</span> T* input,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">uint8_t</span>* kernel,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> T* scale, <span class="type">const</span> T* offset, <span class="type">const</span> T* bias,</span></span></span><br><span class="line"><span class="params"><span class="function">    T *output,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">float</span> maxV, <span class="type">const</span> <span class="type">float</span> minV,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> ic, <span class="type">const</span> <span class="type">int</span> ic_p, <span class="type">const</span> <span class="type">int</span> iw, <span class="type">const</span> <span class="type">int</span> ih,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> c, <span class="type">const</span> <span class="type">int</span> c_p, <span class="type">const</span> <span class="type">int</span> ow, <span class="type">const</span> <span class="type">int</span> oh,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> kw, <span class="type">const</span> <span class="type">int</span> kh, <span class="type">const</span> <span class="type">int</span> dw, <span class="type">const</span> <span class="type">int</span> dh,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> sw, <span class="type">const</span> <span class="type">int</span> sh, <span class="type">const</span> <span class="type">int</span> pw, <span class="type">const</span> <span class="type">int</span> ph,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> total, <span class="type">const</span> <span class="type">int</span> quanC,</span></span></span><br><span class="line"><span class="params"><span class="function">    DivModFast d_oc, DivModFast d_ow, DivModFast d_oh</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> index = blockIdx.x * blockDim.x + threadIdx.x; index &lt; total; index += blockDim.x * gridDim.x) &#123;</span><br><span class="line">        <span class="type">int</span> oz_2, tmp2, oy, ox, tmp1, ob;</span><br><span class="line">        d_oc.<span class="built_in">divmod</span>(index, tmp1, oz_2);</span><br><span class="line">        d_ow.<span class="built_in">divmod</span>(tmp1, tmp2, ox);</span><br><span class="line">        d_oh.<span class="built_in">divmod</span>(tmp2, ob, oy);</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> oz = oz_2;</span><br><span class="line">        <span class="type">int</span> ix = ox * sw - pw;</span><br><span class="line">        <span class="type">int</span> iy = oy * sh - ph;</span><br><span class="line">        <span class="type">float</span> color0 = bias[oz];</span><br><span class="line"></span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> num_quan_groups_per_channel = (c &gt; <span class="number">0</span> &amp;&amp; quanC &gt; <span class="number">0</span>) ? (quanC / c) : <span class="number">1</span>;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> ic_per_group = (num_quan_groups_per_channel &gt; <span class="number">0</span>) ? (ic / num_quan_groups_per_channel) : ic;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> quan_param_index_base = oz * num_quan_groups_per_channel;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> fxSta = <span class="built_in">max</span>(<span class="number">0</span>, (<span class="built_in">UP_DIV</span>(-ix, dw)));</span><br><span class="line">        <span class="type">int</span> fySta = <span class="built_in">max</span>(<span class="number">0</span>, (<span class="built_in">UP_DIV</span>(-iy, dh)));</span><br><span class="line">        <span class="type">int</span> fxEnd = <span class="built_in">min</span>(kw, <span class="built_in">UP_DIV</span>(iw - ix, dw));</span><br><span class="line">        <span class="type">int</span> fyEnd = <span class="built_in">min</span>(kh, <span class="built_in">UP_DIV</span>(ih - iy, dh));</span><br><span class="line">        <span class="type">int</span> fx, fy, fz;</span><br><span class="line">        <span class="keyword">for</span> (fy=fySta; fy&lt;fyEnd; ++fy) &#123;</span><br><span class="line">            <span class="type">int</span> sy = fy*dh + iy;</span><br><span class="line">            <span class="keyword">for</span> (fx=fxSta; fx&lt;fxEnd; ++fx) &#123;</span><br><span class="line">                <span class="type">int</span> sx = fx*dw + ix;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> group_idx = <span class="number">0</span>; group_idx &lt; num_quan_groups_per_channel; ++group_idx) &#123;</span><br><span class="line">                    <span class="type">const</span> <span class="type">int</span> quan_param_index = quan_param_index_base + group_idx;</span><br><span class="line">                    <span class="type">const</span> <span class="type">float</span> x_scale = scale[quan_param_index];</span><br><span class="line">                    <span class="type">const</span> <span class="type">float</span> x_offset = offset[quan_param_index];</span><br><span class="line"></span><br><span class="line">                    <span class="type">const</span> <span class="type">int</span> sz_start = group_idx * ic_per_group / <span class="number">2</span>;</span><br><span class="line">                    <span class="type">const</span> <span class="type">int</span> sz_end = sz_start + ic_per_group / <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">for</span> (<span class="type">int</span> sz = sz_start; sz &lt; sz_end &amp;&amp; sz * <span class="number">2</span> &lt; ic_p; ++ sz) &#123;</span><br><span class="line">                        <span class="type">int</span> src_offset = ((ob * ih + sy) * iw + sx) * ic_p + <span class="number">2</span> * sz;</span><br><span class="line">                        <span class="type">float</span> inp0 = input[src_offset];</span><br><span class="line">                        <span class="type">float</span> inp1 = input[src_offset+<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">                        <span class="comment">//[Cop, KhKw, Cip]</span></span><br><span class="line">                        <span class="type">uint8_t</span> ker = kernel[((oz * kh + fy) * kw + fx) * ic_p / <span class="number">2</span> + sz];</span><br><span class="line">                        <span class="type">int8_t</span> ker0 = (ker &gt;&gt; <span class="number">4</span>) - <span class="number">8</span>;</span><br><span class="line">                        <span class="type">int8_t</span> ker1 = (ker &amp; <span class="number">15</span>) - <span class="number">8</span>;</span><br><span class="line">                        color0 = color0 + inp0 * ((<span class="type">float</span>)ker0 * x_scale + x_offset);</span><br><span class="line">                        color0 = color0 + inp1 * ((<span class="type">float</span>)ker1 * x_scale + x_offset);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        color0 = <span class="built_in">max</span>(color0, minV);</span><br><span class="line">        color0 = <span class="built_in">min</span>(color0, maxV);</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> dst_offset = ((ob * oh + oy) * ow + ox) * c_p + oz;</span><br><span class="line"></span><br><span class="line">        output[dst_offset] = color0;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="convint8cutlassexecution">ConvInt8CutlassExecution</h3>
<p>接下来考察 GEMM 特殊情况，考虑先对 <span
class="math inline">\(A\)</span> 做量化，再对两个矩阵进行 INT*INT
的矩阵乘法，最后再将得到的 INT32 用一套新的量化参数量化。</p>
<p>先思考 <span class="math inline">\(A\)</span> 和 <span
class="math inline">\(B\)</span> 均为 Per-tensor
量化的特殊情况，即两个输入矩阵分别只有一套量化参数，输出有一套。此外还有一个
<span class="math inline">\(Bias\)</span> 参数需要加上。</p>
<p>将量化参数记为 <span class="math inline">\(s\)</span> 和 <span
class="math inline">\(z\)</span>，简单推导得：</p>
<p><span class="math inline">\(c_{fp, ij} = s_A s_B \left[
\sum_{k=1}^{K} a_{q, ik} b_{q, kj} - z_B \sum_{k=1}^{K} a_{q, ik} - z_A
\sum_{k=1}^{K} b_{q, kj} + K z_A z_B \right]\)</span></p>
<p>因此，以上算法是完全可行的，问题只有如何做好反量化和最终结果的量化。</p>
<p>考虑一个更简单的情况，假设 <span class="math inline">\(B\)</span>
为对称量化（即 <span class="math inline">\(Z_B =
0\)</span>）。下面将两个矩阵分别记为 <span
class="math inline">\(I\)</span> 和 <span
class="math inline">\(W\)</span>（Input 和
Weight）。本质上我们的操作流程如下：</p>
<ol type="1">
<li>首先反量化，将 INT8 的输入和权重变回浮点数：<span
class="math inline">\(I_{fp} = S_I \cdot (I_q - Z_I)\)</span>，<span
class="math inline">\(W_{fp} = S_W \cdot W_q\)</span>；</li>
<li>执行标准的浮点卷积和偏置加法：<span class="math inline">\(O_{fp} =
\text{GEMM}(I_{fp}, W_{fp}) + B_{fp}\)</span>；</li>
<li>重新量化，将浮点结果，变回 INT8 输出：<span
class="math inline">\(O_q = O_{fp} / S_O + Z_O\)</span>；</li>
</ol>
<p>我们的目标是跳过中间的浮点步骤。整合以上三个步骤得到：</p>
<p><span class="math inline">\(O_q = \frac{ \left( \sum S_I(I_q-Z_I)
\cdot S_W W_q \right) + B_{fp} }{S_O} + Z_O\)</span></p>
<p>分离出纯整数部分 <span class="math inline">\(\text{Accum}_{32} = \sum
I_q \cdot W_q\)</span>（32位整数累加器)： <span
class="math inline">\(O_q = \frac{S_I S_W \left( \sum I_q W_q - Z_I \sum
W_q \right) + B_{fp}}{S_O} + Z_O\)</span></p>
<p>提出总缩放因子 <span
class="math inline">\(M\)</span>，合并所有偏移项为 <span
class="math inline">\(\text{FusedBias}\)</span>：</p>
<p><span class="math inline">\(M = \frac{S_I \cdot S_W}{S_O}, \quad
\text{FusedBias} = -Z_I \cdot \sum W_q + \frac{B_{fp}}{S_I S_W} +
\frac{Z_O}{M}\)</span></p>
<p>得到最后结果：<span class="math inline">\(O_q = M \cdot
(\text{Accum}_{32} + \text{FusedBias})\)</span></p>
<p>代码实现：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> ConvInt8CutlassExecution::Resource::<span class="built_in">updateInputOutputScale</span>(std::vector&lt;<span class="type">float</span>&gt; inputQuantInfo, std::vector&lt;<span class="type">float</span>&gt; outputQuantInfo) &#123;</span><br><span class="line">    <span class="keyword">if</span>(mUseConvQuan) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// new scales and zero points</span></span><br><span class="line">    <span class="type">float</span> inputScale = inputQuantInfo[<span class="number">0</span>];</span><br><span class="line">    <span class="type">float</span> outputScale = outputQuantInfo[<span class="number">0</span>];</span><br><span class="line">    <span class="type">float</span> inputZeroPoint = inputQuantInfo[<span class="number">1</span>];</span><br><span class="line">    <span class="type">float</span> outputZeroPoint = outputQuantInfo[<span class="number">1</span>];</span><br><span class="line">    mClampMin = <span class="built_in">int8_t</span>(outputQuantInfo[<span class="number">2</span>]);</span><br><span class="line">    mClampMax = <span class="built_in">int8_t</span>(outputQuantInfo[<span class="number">3</span>]);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (inputScale == <span class="number">0.f</span> || outputScale == <span class="number">0.f</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    mInputScale = inputScale;</span><br><span class="line">    mOutputScale = outputScale;</span><br><span class="line">    mInputZeroPoint = <span class="built_in">int8_t</span>(inputZeroPoint);</span><br><span class="line">    mOutputZeroPoint = <span class="built_in">int8_t</span>(outputZeroPoint);</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> kernelNum = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(mInt8WeightKernelSum.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> alphaScale  = inputScale / outputScale;</span><br><span class="line">    <span class="keyword">auto</span> alphaData = mScaleFloatVec;</span><br><span class="line">    <span class="keyword">auto</span> biasData = (<span class="type">float</span> *)mBiasInt32Vec;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; kernelNum; i++) &#123;</span><br><span class="line">        <span class="keyword">auto</span> alphaValue = alphaData[i];</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">fabs</span>(alphaValue) &lt; <span class="number">1e-6</span>) alphaValue = <span class="number">1e-6</span>;</span><br><span class="line">        mScaleFloatVec[i] = alphaValue * alphaScale;</span><br><span class="line">        <span class="comment">// compute outputZeroPointFused in asymmetric quant</span></span><br><span class="line">        <span class="type">int</span> outputZeroPointFused = <span class="built_in">static_cast</span>&lt;<span class="type">int32_t</span>&gt;(outputZeroPoint / mScaleFloatVec[i]);</span><br><span class="line">        mBiasInt32Vec[i] = <span class="built_in">static_cast</span>&lt;<span class="type">int32_t</span>&gt;(biasData[i] / (alphaScale * alphaValue)) - mInt8WeightKernelSum[i] * inputZeroPoint + outputZeroPointFused;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><span class="math inline">\(M = \frac{S_I \cdot S_W}{S_O}\)</span>：
<code>mScaleFloatVec[i] = alphaValue * alphaScale</code>；</p>
<p><code>alphaValue</code> 对应权重尺度 <span
class="math inline">\(S_W\)</span>， <code>alphaScale</code> 对应<span
class="math inline">\(S_I / S_O\)</span>。</p>
<p><span class="math inline">\(\text{FusedBias} = -Z_I \sum W_q +
\frac{B_{fp}}{S_I S_W} +
\frac{Z_O}{M}\)</span>：<code>mBiasInt32Vec[i] = term1 + term2 + term3</code>;</p>
<p><code>term1 = biasData[i] / (alphaScale * alphaValue)</code> 对应
<span class="math inline">\(B_{fp} / M\)</span>。为了让它和公式中的
<span class="math inline">\(\frac{B_{fp}}{S_I S_W}\)</span>
匹配，biasData 必须是预先处理过的 <span
class="math inline">\(B_{fp}/S_O\)</span>。这是一个常见的实现技巧。</p>
<p><code>term2 = - mInt8WeightKernelSum[i] * inputZeroPoint</code> 对应
<span class="math inline">\(-Z_I \sum W_q\)</span>。</p>
<p><code>term3 = outputZeroPointFused</code> （即 outputZeroPoint /
mScaleFloatVec[i]） 对应公式中的 <span class="math inline">\(Z_O /
M\)</span>。</p>
<h3 id="llama.cpp-实现">llama.cpp 实现</h3>
<p>混合精度 GEMM 与 GEMV 代码重点在 ggml/src/ggml-cuda/ 下的
ggml-cuda.cu、mmq.cu、mmq.cuh、mmvq.cu。</p>
<p>量化相关代码重点在 quantize.cu 中；底层向量矩阵乘法实现在 vecdotq.cu
中。</p>
<p>Ilama.cpp 对于 FP16/FP32* INT 混合精度矩阵乘法：</p>
<ol type="1">
<li>cuBLAS 路径：全反量化成 FP16/FP32（代码在 ggml-cuda.cu 中的
<code>ggml_cuda_mul_mat_batched_cublas</code>、
<code>ggml_cuda_op_mul_mat_cublas</code>）；</li>
<li>手写内核（<a
href="https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md#cuda">MMQ</a>）路径：
<ol type="1">
<li>对 FP16<em>INT，使用cuBLAS 路径，执行 FP16</em> FP16，再将 FP16
结果反量化成 FP32；</li>
<li>对 FP32 * INT，全矩阵量化成 INT，执行 INT *INT，再将 INT32
结果反量化为 FP32；
<ol type="1">
<li>分muL_mat_q 和 mul_mat_vec_q 两个版本；还有对 MoE 特化版本；</li>
<li>没有能够直接调用的在线反量化并做矩阵乘的 cuBLAS 接口；没用
Cutlass；</li>
<li>大量模板元实现的编译期分支，用于确定核函数常数和调用的函数指针；</li>
</ol></li>
</ol></li>
</ol>
<p>以下是几个与 MMQ 路径相关的关键函数：</p>
<ul>
<li><strong><code>ggml_cuda_op_mul_mat</code></strong>:
一个通用的矩阵乘法执行引擎，它负责处理多GPU数据切分与同步，并能通过函数指针调用任何具体计算实现（cuBLAS或自定义量化核函数）。</li>
<li><strong><code>ggml_cuda_mul_mat</code></strong>:
矩阵乘法操作的顶层“决策者”，它通过分析输入张量的类型、形状和硬件特性，智能地分发任务给最优的后端实现（如自定义量化内核或多种cuBLAS路径）。
在需要 GPU 切分等时调用 ggml_cuda_op_mul_mat，否则直接调用
ggml_cuda_mul_mat_q 等；</li>
<li><strong><code>ggml_cuda_mul_mat_q</code></strong>:
通用“矩阵-矩阵”量化乘法（MMQ）的逻辑主入口，负责动态量化FP32输入并处理标准及混合专家（MoE）两种计算模式。
针对 MoE 的整体解决方案。</li>
<li><strong><code>ggml_cuda_op_mul_mat_q</code></strong>:
作为通用执行引擎调用的底层计算接口，它接收已准备好的量化输入，将其打包为内核参数并启动实际的“矩阵-矩阵”量化计算核函数。
直接得到上层 ggml_cuda_op_mul_mat 量化处理之后的参数。</li>
</ul>
<p><code>mul_mat_q_case</code> 是真正的执行函数。</p>
<h2 id="方案一在线反量化">方案一：在线反量化</h2>
<p>现在，我们考虑上一节的在线反量化卷积的矩阵乘法与向量-矩阵乘法特化版本。</p>
<p>根据 CUDA 编程加速技巧，我们对 GEMM 做如下优化：</p>
<ol type="1">
<li>将矩阵分割为 16x16 的 Tile，每个 thread-block 负责结果的一块（涉及 A
的一”块行“ 与 B 的一”块列“）；每个线程负责其中 A 的一行与 B 的一列，
<code>k_tile</code> 负责枚举 K 维度上的块；</li>
<li>代码中矩阵乘法的过程访问的是 <code>B_tile_fp[k][tx]</code> 和
<code>A_tile[ty][k]</code> 。相邻线程 ty 相等， tx 相邻。因此同一个 warp
内，B 访问的是同一行数据（合并访问），而 A
访问的是同一个数（直接触发广播）。均不会发生 32-way bank
conflict，因此对 B_tile 列维度 +1 的 Padding 是没有必要的；</li>
<li>GEMM 循环内第一阶段，通过合并访存将 A 和 B 载入到 Shared Memory
中；第二阶段并行进行反量化与转置；第三阶段做矩阵乘法；</li>
</ol>
<p>代码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> TILE_DIM = <span class="number">16</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">GEMM_FpAInt8B</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> T* input,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int8_t</span>* kernel,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> T* scale, <span class="type">const</span> T* offset, <span class="type">const</span> T* bias,</span></span></span><br><span class="line"><span class="params"><span class="function">    T* output,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">float</span> maxV, <span class="type">const</span> <span class="type">float</span> minV,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> ic, <span class="type">const</span> <span class="type">int</span> ic_p, <span class="type">const</span> <span class="type">int</span> oc, <span class="type">const</span> <span class="type">int</span> oc_p,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> batch, <span class="type">const</span> <span class="type">int</span> quanC</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>&#123;</span><br><span class="line">    __shared__ T A_tile[TILE_DIM][TILE_DIM]; <span class="comment">// [batch, ic]</span></span><br><span class="line">    __shared__ <span class="type">int8_t</span> B_tile_s8[TILE_DIM][TILE_DIM]; <span class="comment">// [ic, oc] kernel 本身是 B^T [oc, ic]</span></span><br><span class="line">    __shared__ T B_tile_fp[TILE_DIM][TILE_DIM];</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tx = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ty = threadIdx.y;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> block_row = blockIdx.y; <span class="comment">// batch</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> block_col = blockIdx.x; <span class="comment">// output channel</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 每个线程负责计算输出Tile中的一个元素</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> out_row = block_row * TILE_DIM + ty; <span class="comment">// M</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> out_col = block_col * TILE_DIM + tx; <span class="comment">// N</span></span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> acc = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="comment">// 沿K维度（输入通道ic）分块循环</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> num_k_tiles = <span class="built_in">UP_DIV</span>(ic, TILE_DIM);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k_tile = <span class="number">0</span>; k_tile &lt; num_k_tiles; ++k_tile) &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> k_tile_base = k_tile * TILE_DIM;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 合并访问加载 A_tile (input)，线程 (ty, tx) 加载 A_tile[ty][tx]</span></span><br><span class="line">        <span class="type">int</span> a_col_idx = k_tile_base + tx;</span><br><span class="line">        A_tile[ty][tx] = (out_row &lt; batch &amp;&amp; a_col_idx &lt; ic) ? input[out_row * ic_p + a_col_idx] : (T)<span class="number">0.0f</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 合并访问加载 B_tile (kernel)，线程 (ty, tx) 加载 B_tile[ty][tx]</span></span><br><span class="line">        <span class="comment">// kernel 布局为 [oc, ic]，需要 B(k,n)，即 kernel(n,k)</span></span><br><span class="line">        <span class="type">int</span> b_load_row = block_col * TILE_DIM + ty;</span><br><span class="line">        <span class="type">int</span> b_col_idx = k_tile_base + tx;</span><br><span class="line">        B_tile_s8[ty][tx] = (b_load_row &lt; oc &amp;&amp; b_col_idx &lt; ic) ? kernel[b_load_row * ic_p + b_col_idx] : <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        __syncthreads();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 反量化 + 转置</span></span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> K = ty;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> N = tx;</span><br><span class="line"></span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> global_k = k_tile_base + K;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> global_n = block_col * TILE_DIM + N;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (global_n &lt; oc &amp;&amp; global_k &lt; ic) &#123;</span><br><span class="line">            <span class="type">const</span> <span class="type">int</span> num_quan_groups_per_channel = (quanC &gt; <span class="number">0</span>) ? (quanC / oc) : <span class="number">1</span>;</span><br><span class="line">            <span class="type">const</span> <span class="type">int</span> ic_per_group = (num_quan_groups_per_channel &gt; <span class="number">0</span>) ? (ic / num_quan_groups_per_channel) : ic;</span><br><span class="line">            <span class="type">const</span> <span class="type">int</span> group_idx = global_k / ic_per_group;</span><br><span class="line">            <span class="type">const</span> <span class="type">int</span> quan_param_index = global_n * num_quan_groups_per_channel + group_idx;</span><br><span class="line"></span><br><span class="line">            <span class="type">const</span> <span class="type">float</span> x_scale  = (<span class="type">float</span>)scale[quan_param_index];</span><br><span class="line">            <span class="type">const</span> <span class="type">float</span> x_offset = (<span class="type">float</span>)offset[quan_param_index];</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// B_tile_s8(n,k), thread(n,k) -&gt; (tx, ty)</span></span><br><span class="line">            <span class="comment">// So we need to read from B_tile_s8[n_dim_in_tile][k_dim_in_tile] -&gt; B_tile_s8[tx][ty]</span></span><br><span class="line">            <span class="type">const</span> <span class="type">float</span> b_quant = (<span class="type">float</span>)B_tile_s8[N][K];</span><br><span class="line"></span><br><span class="line">            <span class="comment">// B_tile_fp[k][n] -&gt; B_tile_fp[ty][tx]</span></span><br><span class="line">            B_tile_fp[K][N] = (T)(b_quant * x_scale + x_offset);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        __syncthreads();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 在 SMEM 中进行子矩阵乘法</span></span><br><span class="line">        <span class="keyword">if</span> (out_col &lt; oc) &#123;</span><br><span class="line">            <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; TILE_DIM; ++k) &#123;</span><br><span class="line">                acc += (<span class="type">float</span>)A_tile[ty][k] * (<span class="type">float</span>)B_tile_fp[k][tx];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 写回全局内存</span></span><br><span class="line">    <span class="keyword">if</span> (out_row &lt; batch &amp;&amp; out_col &lt; oc) &#123;</span><br><span class="line">        acc += (<span class="type">float</span>)bias[out_col];</span><br><span class="line">        acc = <span class="built_in">max</span>(acc, minV);</span><br><span class="line">        acc = <span class="built_in">min</span>(acc, maxV);</span><br><span class="line">        output[out_row * oc_p + out_col] = (T)acc;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用</span></span><br><span class="line"><span class="function">dim3 <span class="title">threads</span><span class="params">(TILE_DIM, TILE_DIM)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">blocks</span><span class="params">(UP_DIV(ocp, TILE_DIM), UP_DIV(batch, TILE_DIM))</span></span>;</span><br></pre></td></tr></table></figure>
<p>对 GEMV 做如下优化：</p>
<ol type="1">
<li>每个线程块负责计算一个输出位置，每个线程负责一个 %64
剩余系的位置（合并访存+计算）；</li>
<li>由于向量-矩阵乘的结果是一个向量，因此直接做并行规约（蝶式交换）即可，最终只需要
thread0 写回 Global Memory；</li>
<li>使用动态 Shared Memory，直接在第一阶段通过合并访存从 Global Memory
中加载；</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">GEMV_FpAInt4B</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> T* input,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">uint8_t</span>* kernel, <span class="comment">// kernel 是打包的 int4</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> T* scale, <span class="type">const</span> T* offset, <span class="type">const</span> T* bias,</span></span></span><br><span class="line"><span class="params"><span class="function">    T* output,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">float</span> maxV, <span class="type">const</span> <span class="type">float</span> minV,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> ic, <span class="type">const</span> <span class="type">int</span> ic_p,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> oc, <span class="type">const</span> <span class="type">int</span> quanC</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">uint8_t</span> smem_buffer[];</span><br><span class="line">    T* smem_input = <span class="built_in">reinterpret_cast</span>&lt;T*&gt;(smem_buffer);</span><br><span class="line">    <span class="type">float</span>* partial_sums = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">float</span>*&gt;(smem_buffer + ic_p * <span class="built_in">sizeof</span>(T));</span><br><span class="line">    </span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> oz = blockIdx.x; <span class="comment">// 当前线程块负责计算的输出通道索引</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 加载 input 到共享内存</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = tid; i &lt; ic; i += blockDim.x) smem_input[i] = input[i];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = ic + tid; i &lt; ic_p; i += blockDim.x) smem_input[i] = (T)<span class="number">0.0f</span>;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> num_quan_groups_per_channel = (quanC &gt; <span class="number">0</span>) ? (quanC / oc) : <span class="number">1</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ic_per_group = (num_quan_groups_per_channel &gt; <span class="number">0</span>) ? (ic / num_quan_groups_per_channel) : ic;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> quan_param_index_base = oz * num_quan_groups_per_channel;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> my_sum = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = tid * <span class="number">2</span>; k &lt; ic; k += blockDim.x * <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="comment">// 加载打包的权重并解包</span></span><br><span class="line">        <span class="type">const</span> <span class="type">uint8_t</span> ker_packed = kernel[oz * (ic_p / <span class="number">2</span>) + k / <span class="number">2</span>];</span><br><span class="line">        <span class="type">const</span> <span class="type">int8_t</span> ker0_s8 = (ker_packed &gt;&gt; <span class="number">4</span>) - <span class="number">8</span>;</span><br><span class="line">        <span class="type">const</span> <span class="type">int8_t</span> ker1_s8 = (ker_packed &amp; <span class="number">0x0F</span>) - <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> group_idx0 = k / ic_per_group;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> quan_param_index0 = quan_param_index_base + group_idx0;</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> x_scale0  = scale[quan_param_index0];</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> x_offset0 = offset[quan_param_index0];</span><br><span class="line">        my_sum += (<span class="type">float</span>)smem_input[k] * ((<span class="type">float</span>)ker0_s8 * x_scale0 + x_offset0);</span><br><span class="line">        my_sum += (<span class="type">float</span>)smem_input[k + <span class="number">1</span>] * ((<span class="type">float</span>)ker1_s8 * x_scale0 + x_offset0);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    partial_sums[tid] = my_sum;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 并行规约</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">unsigned</span> <span class="type">int</span> s = blockDim.x / <span class="number">2</span>; s &gt; <span class="number">0</span>; s &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; s) partial_sums[tid] += partial_sums[tid + s];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="type">float</span> final_val = partial_sums[<span class="number">0</span>] + (<span class="type">float</span>)bias[oz];</span><br><span class="line">        final_val = <span class="built_in">max</span>(final_val, minV);</span><br><span class="line">        final_val = <span class="built_in">min</span>(final_val, maxV);</span><br><span class="line">        output[oz] = (T)final_val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用</span></span><br><span class="line"><span class="function">dim3 <span class="title">threads</span><span class="params">(GEMV_TILE)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">blocks</span><span class="params">(oc)</span></span>;</span><br><span class="line"><span class="type">size_t</span> input_smem_size = icp * (mFp16Infer ? <span class="built_in">sizeof</span>(half) : <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"><span class="type">size_t</span> reduction_smem_size = GEMV_TILE * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"><span class="type">size_t</span> smem_size = input_smem_size + reduction_smem_size;</span><br><span class="line">GEMV_FpAInt4B&lt;&lt;&lt;blocks, threads, smem_size&gt;&gt;&gt;(...);</span><br></pre></td></tr></table></figure>
<h2 id="方案二在线量化">方案二：在线量化</h2>
<h3 id="方案推导">方案推导</h3>
<p>最后，我们考虑对 <span class="math inline">\(A\)</span> 做与 <span
class="math inline">\(B\)</span> 相同 <span
class="math inline">\(block\_size\)</span> 的 Per-block 量化（均在 <span
class="math inline">\(K\)</span> 维度切割），再调用 INT*INT
矩阵乘法，最后反量化得到浮点结果。现在，<span
class="math inline">\(A\)</span> 的每行被分割，<span
class="math inline">\(B\)</span> 的每列被分割，其余维度不共享参数。</p>
<p>问题在于，不同 block 中的元素使用的是不同的
量化参数，因此显然无法只通过一次完整的整数矩阵乘法就得到答案。另一方面，逐个
block 地相乘效率又太低，无法享受到 Cutlass 的加速（一个 block 往往只有
64 个元素）。</p>
<p>因此，我们考虑每次拿出 <span class="math inline">\(A\)</span>
的一”块列“，与 <span class="math inline">\(B\)</span>
的一”块行“做矩阵乘法，得到一个 <span class="math inline">\(N \times
M\)</span> 的矩阵，然后暴力将矩阵中的每个数（对应一对 block
的乘积）用对应那对 block 的量化参数做反量化，加到答案矩阵上。重复 <span
class="math inline">\(\frac{K}{block\_size}\)</span> 次即可。</p>
<p>更形式化地：</p>
<p>我们将求和维度 <span class="math inline">\(K\)</span> 分为 <span
class="math inline">\(P\)</span> 个连续的块（block）：<span
class="math inline">\(K = G_1 \cup G_2 \cup \dots \cup
G_P\)</span>。</p>
<p>量化参数 <span class="math inline">\(s\)</span> 和 <span
class="math inline">\(z\)</span> 不仅依赖于矩阵和行列，更依赖于 <span
class="math inline">\(k\)</span> 所在的块 <span
class="math inline">\(G_i\)</span>。</p>
<p>因此，反量化公式应该写成（下标 <span class="math inline">\(i\)</span>
代表第 <span class="math inline">\(i\)</span> 个 <span
class="math inline">\(K\)</span> 维度块）：</p>
<p><span class="math inline">\(A_{fp, mk} = s_{A,m,i} \cdot (A_{q, mk} -
z_{A,m,i}) \quad k \in G_i\)</span></p>
<p><span class="math inline">\(B_{fp, kn} = s_{B,n,i} \cdot (B_{q, kn} -
z_{B,n,i}) \quad k \in G_i\)</span></p>
<p>代入矩阵乘法公式（ <span class="math inline">\(g(k)\)</span> 为索引
<span class="math inline">\(k\)</span> 所属的块的编号）：</p>
<p><span class="math inline">\(C_{fp, mn} = \sum_{k=1}^{K} \left[
s_{A,m,g(k)} \cdot (A_{q, mk} - z_{A,m,g(k)}) \right] \cdot \left[
s_{B,n,g(k)} \cdot (B_{q, kn} - z_{B,n,g(k)}) \right]\)</span></p>
<p>由于缩放因子 <span class="math inline">\(s_A, s_B\)</span> 和零点
<span class="math inline">\(z_A, z_B\)</span> 的值会随着 <span
class="math inline">\(k\)</span>
的变化而改变。因此不能将它们作为常数从整个求和 <span
class="math inline">\(\sum_{k=1}^{K}\)</span> 中提出来。
改变求和结构，将对 <span class="math inline">\(k\)</span>
的总求和分解为“对所有块的求和”，内部嵌套“对块内元素的求和”： <span
class="math inline">\(C_{fp, mn} = \sum_{i=1}^{P} \left( \sum_{k \in
G_i} \left[ s_{A,m,i} \cdot (A_{q, mk} - z_{A,m,i}) \right] \cdot \left[
s_{B,n,i} \cdot (B_{q, kn} - z_{B,n,i}) \right] \right)\)</span></p>
<p>对于求和范围 <span class="math inline">\(\sum_{k \in G_i}\)</span>
内的所有 <span class="math inline">\(k\)</span>，它们都属于同一个块
<span
class="math inline">\(G_i\)</span>，因此它们的量化参数不变，可以将这些参数提到内部求和的外面：
<span class="math inline">\(C_{fp, mn} = \sum_{i=1}^{P} s_{A,m,i} \cdot
s_{B,n,i} \left( \sum_{k \in G_i} (A_{q, mk} - z_{A,m,i}) \cdot (B_{q,
kn} - z_{B,n,i}) \right)\)</span></p>
<p>以上即逐 block 乘法的数学基础，接下来推导”块行块列“乘法：
我们定义一个<strong>第 <span class="math inline">\(i\)</span>
块的浮点结果矩阵</strong>：</p>
<p><span class="math inline">\(C_{fp, mn}^{(i)} := s_{A,m,i} \cdot
s_{B,n,i} \left( \sum_{k \in G_i} (A_{q, mk} - z_{A,m,i}) \cdot (B_{q,
kn} - z_{B,n,i}) \right)\)</span></p>
<p>那么，最终的输出矩阵 <span class="math inline">\(C_{fp}\)</span>
就是所有这些局部结果矩阵的简单叠加： <span class="math inline">\(C_{fp,
mn} = \sum_{i=1}^{P} C_{fp, mn}^{(i)}\)</span></p>
<p>定义与块 <span class="math inline">\(i\)</span> 相关的子矩阵：</p>
<p><span class="math inline">\(A_q^{(i)}\)</span>：由矩阵 <span
class="math inline">\(A_q\)</span> 的所有行，以及 <strong>只属于块 <span
class="math inline">\(G_i\)</span> 的列</strong> 构成的子矩阵。维度为
<span class="math inline">\(M \times block\_size\)</span>；</p>
<p><span class="math inline">\(B_q^{(i)}\)</span>：由矩阵 <span
class="math inline">\(B_q\)</span> 的所有列，以及 <strong>只属于块 <span
class="math inline">\(G_i\)</span> 的行</strong> 构成的子矩阵。其维度为
<span class="math inline">\(block\_size \times N\)</span>；</p>
<p>这两个矩阵的乘积结果定义为 <strong>第 <span
class="math inline">\(i\)</span> 块的整数结果矩阵</strong> <span
class="math inline">\(C_{q}^{(i)}\)</span>： <span
class="math inline">\(C_{q, mn}^{(i)} := \sum_{k \in G_i} A_{q, mk}
B_{q, kn}\)</span></p>
<p>这个运算是一个维度为 <span class="math inline">\((M \times
block\_size) \times (block\_size \times N) \rightarrow (M \times
N)\)</span> 的通用矩阵乘法 (GEMM)。其结果 <span
class="math inline">\(C_{q}^{(i)}\)</span> 是一个完整的 <span
class="math inline">\(M \times N\)</span> 的 INT32 矩阵。</p>
<p>再次展开 <span class="math inline">\(C_{fp, mn}^{(i)}\)</span>
的定义并将 <span class="math inline">\(C_{q, mn}^{(i)}\)</span>
代入，我们得到了最终的反量化公式，它描述了如何将一个完整的中间整数矩阵逐元素地转换为浮点矩阵：</p>
<p><span class="math inline">\(C_{fp, mn}^{(i)} = s_{A,m,i} s_{B,n,i}
\cdot \\ \left( \underbrace{\sum_{k \in G_i} A_{q, mk}B_{q, kn}}_{C_{q,
mn}^{(i)}} - z_{B,n,i}\sum_{k \in G_i} A_{q, mk} - z_{A,m,i}\sum_{k \in
G_i} B_{q, kn} + block\_size \cdot z_{A,m,i}z_{B,n,i}
\right)\)</span></p>
<p>算法流程如下：</p>
<p>for i = 1 to P（遍历所有 <span class="math inline">\(K\)</span>
维度的块）：</p>
<ol type="1">
<li>整数子矩阵乘法
<ol type="1">
<li>提取子矩阵 <span class="math inline">\(A_q^{(i)}\)</span> 和 <span
class="math inline">\(B_q^{(i)}\)</span>。</li>
<li>调用高效 int8*int8 -&gt; int32 GEMM 库函数，计算出中间结果矩阵 <span
class="math inline">\(C_{q_i} = \text{matmul}(A_{q_i},
B_{q_i})\)</span>。</li>
</ol></li>
<li>逐元素反量化与累加
<ol type="1">
<li>启动一个 CUDA Kernel，每个线程处理 <span
class="math inline">\(C_{q_i}\)</span> 的一个或多个元素。</li>
<li>在 Kernel 内部，对于每个元素 <span class="math inline">\((m,
n)\)</span>：
<ol type="1">
<li>读取 <span class="math inline">\(C_{q_i,mn}\)</span>，根据块 <span
class="math inline">\(i\)</span> 的量化参数 <span
class="math inline">\(s_{A,m,i}, z_{A,m,i}, s_{B,n,i},
z_{B,n,i}\)</span>，计算出局部浮点值 <span
class="math inline">\(c_{fp_i}\)</span>。</li>
<li>以原子方式或直接（如果输出空间不冲突）将 <span
class="math inline">\(c_{fp_i}\)</span>
加到最终结果矩阵的对应位置。</li>
</ol></li>
</ol></li>
</ol>
<p>以下代码采用 offset 而非 zero-point 形式：</p>
<p><span class="math inline">\(C_{fp, mn}^{(i)} = \sum_{k \in G_i}
\left[ \text{scale}_{A,m,i} A_{q,mk} + \text{offset}_{A,m,i} \right]
\cdot \left[ \text{scale}_{B,n,i} B_{q,kn} + \text{offset}_{B,n,i}
\right] \\ = \left(\text{scale}_{A,m,i}\text{scale}_{B,n,i}\right)
C_{q,mn}^{(i)} + \left(\text{scale}_{A,m,i}\text{offset}_{B,n,i}\right)
A_{q,m,i} \\ + \left(\text{offset}_{A,m,i}\text{scale}_{B,n,i}\right)
B_{q,n,i} + K_i \cdot
\text{offset}_{A,m,i}\text{offset}_{B,n,i}\)</span></p>
<h3 id="代码">代码</h3>
<p>对于核函数部分，做了以下优化：</p>
<ol type="1">
<li>使用 union 复用共享内存，减少总占用量；</li>
<li>对于并行规约，先试用 <code>__shfl_down_sync</code> 做 Warp
内规约（原子操作），再在 Warp 0 做一次 Warp 间规约（实际上仍是
<code>__shfl_down_sync</code> 做 Warp 内规约）；</li>
<li>查看 cuda_fp16.hpp（CUDA Toolkit
12.4）可知，<code>__half atomicAdd(__half *const address, const __half val)</code>
需要在 SM_70
及以后才支持，因此使用预编译期条件（这种方式同样可以应对胖二进制（Fat
Binary）编译方式的情况）
<code>#if (defined(__CUDACC__) &amp;&amp; (!defined(__CUDA_ARCH__) || (__CUDA_ARCH__ &gt;= 700))) || defined(_NVHPC_CUDA)</code>
和编译期条件 <code>if constexpr (std::is_same_v&lt;T, half&gt;)</code>
进行分支判断；</li>
<li>Cutlass 可以直接调用，也可以分成准备+执行两阶段（在下文 Cutlass
相关代码中）；</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 动态量化 A、计算 sum_A</span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">QuantA</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> T* A_sub_fp, <span class="type">int8_t</span>* A_sub_q,</span></span></span><br><span class="line"><span class="params"><span class="function">    T* scale_A_out, T* offset_A_out, <span class="type">int32_t</span>* sum_A_q_out,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> M, <span class="type">const</span> <span class="type">int</span> K_i, <span class="type">const</span> <span class="type">int</span> lda</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 使用 union 复用共享内存，减少总占用量</span></span><br><span class="line">    __shared__ <span class="keyword">union</span> &#123;</span><br><span class="line">        <span class="type">float</span> min_max_vals[<span class="number">2</span>][BLOCK_SIZE / WARP_SIZE]; <span class="comment">// 用于 min/max 的 warp 间规约</span></span><br><span class="line">        <span class="type">int32_t</span> sum_vals[BLOCK_SIZE / WARP_SIZE];      <span class="comment">// 用于 sum 的 warp 间规约</span></span><br><span class="line">        <span class="type">float</span> scale_offset[<span class="number">2</span>];                        <span class="comment">// 用于向块内所有线程广播 scale 和 offset</span></span><br><span class="line">    &#125; smem;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> m = blockIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (m &gt;= M) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> warp_id = tid / WARP_SIZE;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> lane_id = tid % WARP_SIZE;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> my_min = FLT_MAX;</span><br><span class="line">    <span class="type">float</span> my_max = -FLT_MAX;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = tid; k &lt; K_i; k += BLOCK_SIZE) &#123;</span><br><span class="line">        <span class="type">float</span> val = (<span class="type">float</span>)A_sub_fp[m * lda + k];</span><br><span class="line">        my_min = <span class="built_in">min</span>(my_min, val);</span><br><span class="line">        my_max = <span class="built_in">max</span>(my_max, val);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Warp 内规约：使用 __shfl_down_sync 在 warp 内无锁计算 min/max</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = WARP_SIZE / <span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">        my_min = <span class="built_in">min</span>(my_min, __shfl_down_sync(<span class="number">0xFFFFFFFF</span>, my_min, offset));</span><br><span class="line">        my_max = <span class="built_in">max</span>(my_max, __shfl_down_sync(<span class="number">0xFFFFFFFF</span>, my_max, offset));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Warp 间规约：每个 warp 的 0 号线程将 warp 结果写入共享内存</span></span><br><span class="line">    <span class="keyword">if</span> (lane_id == <span class="number">0</span>) &#123;</span><br><span class="line">        smem.min_max_vals[<span class="number">0</span>][warp_id] = my_min;</span><br><span class="line">        smem.min_max_vals[<span class="number">1</span>][warp_id] = my_max;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (warp_id == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 从共享内存加载各 warp 的结果</span></span><br><span class="line">        <span class="keyword">if</span> (lane_id &lt; (BLOCK_SIZE / WARP_SIZE)) &#123;</span><br><span class="line">            my_min = smem.min_max_vals[<span class="number">0</span>][lane_id];</span><br><span class="line">            my_max = smem.min_max_vals[<span class="number">1</span>][lane_id];</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            my_min = FLT_MAX;</span><br><span class="line">            my_max = -FLT_MAX;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 在第一个 warp 内部完成最终规约</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> offset = (BLOCK_SIZE / WARP_SIZE) / <span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">            my_min = <span class="built_in">min</span>(my_min, __shfl_down_sync(<span class="number">0xFFFFFFFF</span>, my_min, offset));</span><br><span class="line">            my_max = <span class="built_in">max</span>(my_max, __shfl_down_sync(<span class="number">0xFFFFFFFF</span>, my_max, offset));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 线程 0 计算 scale/offset 并写入共享内存进行广播</span></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="type">float</span> scale = (my_max - my_min) / <span class="number">255.0f</span>;</span><br><span class="line">        <span class="type">float</span> offset;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">abs</span>(scale) &gt; <span class="number">1e-5</span>) &#123;</span><br><span class="line">            offset = my_max - scale * <span class="number">127.0f</span>; <span class="comment">// my_max 映射到 127, my_min 映射到 -128</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            scale = <span class="number">1.0f</span>;</span><br><span class="line">            offset = my_max;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        scale_A_out[m] = (T)scale;</span><br><span class="line">        offset_A_out[m] = (T)offset;</span><br><span class="line">        </span><br><span class="line">        smem.scale_offset[<span class="number">0</span>] = scale;</span><br><span class="line">        smem.scale_offset[<span class="number">1</span>] = offset;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 所有线程从共享内存读取 scale/offset, 并进行量化和求和</span></span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> s_scale_A = smem.scale_offset[<span class="number">0</span>];</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> s_offset_A = smem.scale_offset[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">    <span class="type">int32_t</span> my_sum_q = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = tid; k &lt; K_i; k += BLOCK_SIZE) &#123;</span><br><span class="line">        <span class="type">float</span> val_fp = (<span class="type">float</span>)A_sub_fp[m * lda + k];</span><br><span class="line">        <span class="type">int32_t</span> val_q = <span class="built_in">roundf</span>((val_fp - s_offset_A) / s_scale_A);</span><br><span class="line">        <span class="type">int8_t</span> a_q = (<span class="type">int8_t</span>)<span class="built_in">max</span>(<span class="number">-128</span>, <span class="built_in">min</span>(<span class="number">127</span>, val_q));</span><br><span class="line">        A_sub_q[m * K_i + k] = a_q;</span><br><span class="line">        my_sum_q += a_q;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = WARP_SIZE / <span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">        my_sum_q += __shfl_down_sync(<span class="number">0xFFFFFFFF</span>, my_sum_q, offset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lane_id == <span class="number">0</span>) smem.sum_vals[warp_id] = my_sum_q;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (warp_id == <span class="number">0</span>) &#123;</span><br><span class="line">        my_sum_q = (lane_id &lt; (BLOCK_SIZE / WARP_SIZE)) ? smem.sum_vals[lane_id] : <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> offset = (BLOCK_SIZE / WARP_SIZE) / <span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">             my_sum_q += __shfl_down_sync(<span class="number">0xFFFFFFFF</span>, my_sum_q, offset);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 线程 0 将最终的和写入全局内存</span></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) sum_A_q_out[m] = my_sum_q;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">GEMM_Int8</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int8_t</span>* A_q, <span class="type">const</span> <span class="type">int8_t</span>* B_q, <span class="type">int32_t</span>* C_q,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> M, <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> K_i,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> lda_q, <span class="type">const</span> <span class="type">int</span> ldb, <span class="type">const</span> <span class="type">int</span> ldc</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int8_t</span> A_tile_s8[SUB_GEMM_TILE_DIM][SUB_GEMM_TILE_DIM];</span><br><span class="line">    __shared__ <span class="type">int8_t</span> B_tile_s8[SUB_GEMM_TILE_DIM][SUB_GEMM_TILE_DIM];</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> block_row = blockIdx.y;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> block_col = blockIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ty = threadIdx.y;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tx = threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> row = block_row * SUB_GEMM_TILE_DIM + ty;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> col = block_col * SUB_GEMM_TILE_DIM + tx;</span><br><span class="line"></span><br><span class="line">    <span class="type">int32_t</span> acc = <span class="number">0</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> num_k_tiles = <span class="built_in">UP_DIV</span>(K_i, SUB_GEMM_TILE_DIM);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k_tile = <span class="number">0</span>; k_tile &lt; num_k_tiles; ++k_tile) &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> k_tile_base = k_tile * SUB_GEMM_TILE_DIM;</span><br><span class="line"></span><br><span class="line">        A_tile_s8[ty][tx] = (row &lt; M &amp;&amp; (k_tile_base + tx) &lt; K_i) ? A_q[row * lda_q + k_tile_base + tx] : <span class="number">0</span>;</span><br><span class="line">        B_tile_s8[ty][tx] = (col &lt; N &amp;&amp; (k_tile_base + ty) &lt; K_i) ? B_q[col * ldb + k_tile_base + ty] : <span class="number">0</span>;</span><br><span class="line">        __syncthreads();</span><br><span class="line"></span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; SUB_GEMM_TILE_DIM; ++k) &#123;</span><br><span class="line">            acc += (<span class="type">int32_t</span>)A_tile_s8[ty][k] * (<span class="type">int32_t</span>)B_tile_s8[k][tx];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (row &lt; M &amp;&amp; col &lt; N) C_q[row * ldc + col] = acc;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">DequantAndAcc</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int32_t</span>* C_q, T* C_fp_final,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> T* scale_A_in, <span class="type">const</span> T* offset_A_in,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> T* base_scale_B, <span class="type">const</span> T* base_offset_B,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int32_t</span>* base_sum_B_q,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> group_idx, <span class="type">const</span> <span class="type">int</span> num_oc_groups,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int32_t</span>* sum_A_q_in,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> M, <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> K_i, <span class="type">const</span> <span class="type">int</span> ldc</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 使用共享内存缓存行和列的量化参数</span></span><br><span class="line">    __shared__ <span class="type">float</span> smem_scale_A[DEQUANT_TILE_DIM];</span><br><span class="line">    __shared__ <span class="type">float</span> smem_offset_A[DEQUANT_TILE_DIM];</span><br><span class="line">    __shared__ <span class="type">int32_t</span> smem_sum_A_q[DEQUANT_TILE_DIM];</span><br><span class="line"></span><br><span class="line">    __shared__ <span class="type">float</span> smem_scale_B[DEQUANT_TILE_DIM];</span><br><span class="line">    __shared__ <span class="type">float</span> smem_offset_B[DEQUANT_TILE_DIM];</span><br><span class="line">    __shared__ <span class="type">int32_t</span> smem_sum_B_q[DEQUANT_TILE_DIM];</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tx = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ty = threadIdx.y;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> block_row_start = blockIdx.y * DEQUANT_TILE_DIM;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> block_col_start = blockIdx.x * DEQUANT_TILE_DIM;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 每个线程加载一个 A 的参数</span></span><br><span class="line">    <span class="type">int</span> m_load_idx = block_row_start + ty;</span><br><span class="line">    <span class="keyword">if</span> (tx == <span class="number">0</span> &amp;&amp; m_load_idx &lt; M) &#123;</span><br><span class="line">        smem_scale_A[ty]   = (<span class="type">float</span>)scale_A_in[m_load_idx];</span><br><span class="line">        smem_offset_A[ty]  = (<span class="type">float</span>)offset_A_in[m_load_idx];</span><br><span class="line">        smem_sum_A_q[ty]   = sum_A_q_in[m_load_idx];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 每个线程加载一个 B 的参数</span></span><br><span class="line">    <span class="type">int</span> n_load_idx = block_col_start + tx;</span><br><span class="line">    <span class="keyword">if</span> (ty == <span class="number">0</span> &amp;&amp; n_load_idx &lt; N) &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">size_t</span> b_param_idx = n_load_idx * num_oc_groups + group_idx;</span><br><span class="line">        smem_scale_B[tx]  = (<span class="type">float</span>)base_scale_B[b_param_idx];</span><br><span class="line">        smem_offset_B[tx] = (<span class="type">float</span>)base_offset_B[b_param_idx];</span><br><span class="line">        smem_sum_B_q[tx]  = base_sum_B_q[b_param_idx];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算每个线程负责的输出点</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> m = block_row_start + ty;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = block_col_start + tx;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (m &lt; M &amp;&amp; n &lt; N) &#123;</span><br><span class="line">        <span class="comment">// 从共享内存中读取参数</span></span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> scale_A = smem_scale_A[ty];</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> offset_A = smem_offset_A[ty];</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> sum_A_q = (<span class="type">float</span>)smem_sum_A_q[ty];</span><br><span class="line"></span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> scale_B = smem_scale_B[tx];</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> offset_B = smem_offset_B[tx];</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> sum_B_q = (<span class="type">float</span>)smem_sum_B_q[tx];</span><br><span class="line">        </span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> c_q_val = (<span class="type">float</span>)C_q[m * ldc + n];</span><br><span class="line"></span><br><span class="line">        <span class="type">float</span> term1 = scale_A * (c_q_val * scale_B + sum_A_q * offset_B);</span><br><span class="line">        <span class="type">float</span> term2 = offset_A * (sum_B_q * scale_B + K_i * offset_B);</span><br><span class="line">        <span class="type">float</span> final_val = term1 + term2;</span><br><span class="line"></span><br><span class="line">        <span class="meta">#<span class="keyword">if</span> (defined(__CUDACC__) &amp;&amp; (!defined(__CUDA_ARCH__) || (__CUDA_ARCH__ &gt;= 700))) || defined(_NVHPC_CUDA)</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;T, <span class="type">float</span>&gt;)</span> </span>&#123;</span><br><span class="line">                <span class="built_in">atomicAdd</span>(&amp;C_fp_final[m * ldc + n], final_val);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;T, half&gt;) &#123;</span><br><span class="line">                <span class="comment">// printf(&quot;[final_val]%.4f %.4f\n&quot;, __half2float(C_fp_final[m * ldc + n]), final_val);</span></span><br><span class="line">                <span class="built_in">atomicAdd</span>(&amp;C_fp_final[m * ldc + n], __float2half(final_val));</span><br><span class="line">                <span class="comment">// printf(&quot;[C_fp_final]%.4f\n&quot;, __half2float(C_fp_final[m * ldc + n]));</span></span><br><span class="line">            &#125;</span><br><span class="line">        <span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">            C_fp_final[m * ldc + n] += final_val;</span><br><span class="line">        <span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 预计算权重 B 的修正项 (sum_B_q)</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">Precompute_SumBq</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int8_t</span>* B_q, <span class="type">int32_t</span>* sum_B_q_out,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> num_groups, <span class="type">const</span> <span class="type">int</span> ic_per_group,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> oc, <span class="type">const</span> <span class="type">int</span> ic_p</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 每个线程处理一个 (output_channel, group) 的修正项</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> index = blockIdx.x * blockDim.x + threadIdx.x; index &lt; (<span class="type">size_t</span>)oc * num_groups; index += blockDim.x * gridDim.x) &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> i = index % num_groups; <span class="comment">// group_idx</span></span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> n = index / num_groups; <span class="comment">// output_channel</span></span><br><span class="line">        </span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> k_start = i * ic_per_group;</span><br><span class="line">        </span><br><span class="line">        <span class="type">int32_t</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> k_offset = <span class="number">0</span>; k_offset &lt; ic_per_group; ++k_offset) &#123;</span><br><span class="line">            <span class="comment">// 访问 B 矩阵的布局是 [oc][ic_p]</span></span><br><span class="line">            sum += (<span class="type">int32_t</span>)B_q[n * ic_p + k_start + k_offset];</span><br><span class="line">        &#125;</span><br><span class="line">        sum_B_q_out[index] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">BiasAndActivation</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    T* data, <span class="type">const</span> T* bias,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">float</span> minV, <span class="type">const</span> <span class="type">float</span> maxV,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> M, <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> ldc</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> index = blockIdx.x * blockDim.x + threadIdx.x; index &lt; (<span class="type">size_t</span>)M * N; index += blockDim.x * gridDim.x) &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> m = index / N;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> n = index % N;</span><br><span class="line"></span><br><span class="line">        <span class="type">const</span> <span class="type">size_t</span> buffer_idx = m * ldc + n;</span><br><span class="line">        <span class="type">float</span> val = (<span class="type">float</span>)data[buffer_idx];</span><br><span class="line">        val += (<span class="type">float</span>)bias[n];</span><br><span class="line">        val = <span class="built_in">max</span>(val, minV);</span><br><span class="line">        val = <span class="built_in">min</span>(val, maxV);</span><br><span class="line">        data[buffer_idx] = (T)val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这里我们只对 INT8 进行优化，因为 Cutlass 对 INT4 GEMM
的支持与硬件计算能力绑定。</p>
<p>查阅 <a
href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html">PTX
ISA</a> 和 <a
href="https://docs.nvidia.com/cuda/turing-tuning-guide/index.html">Turing
Guide</a> 可知，SM_75 架构（Turing）虽然 Tensor Core 理论支持 INT4
GEMM，也提供了诸如
<code>mma.sync.aligned.m8n8k16.row.col.s32.s4.s4.s32</code> 的 PTX
ISA，但 Cutlass 并没有很好地集成相应能力。而 s4.s4 的 wmma 和 Cutlass
支持则要到 Ampere（SM_80 以上）才能支持。</p>
<p>Cutlass 代码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> CutlassGemmIntParam_hpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CutlassGemmIntParam_hpp</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../CutlassGemmParam.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> MNN &#123;</span><br><span class="line"><span class="keyword">namespace</span> CUDA &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// int8 * int8 =&gt; int32 GEMM.</span></span><br><span class="line"><span class="keyword">using</span> EpilogueGemmInt = cutlass::epilogue::thread::LinearCombination&lt;</span><br><span class="line">    <span class="type">int32_t</span>, <span class="comment">// ElementC</span></span><br><span class="line">    <span class="number">1</span>,       <span class="comment">// Elements per access.</span></span><br><span class="line">    <span class="type">int32_t</span>, <span class="comment">// ElementAccumulator</span></span><br><span class="line">    <span class="type">int32_t</span>  <span class="comment">// ElementCompute, not used for this epilogue</span></span><br><span class="line">&gt;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> CutlassGemmInt = cutlass::gemm::device::Gemm&lt;</span><br><span class="line">    <span class="type">int8_t</span>,                             <span class="comment">// ElementA</span></span><br><span class="line">    cutlass::layout::RowMajor,          <span class="comment">// LayoutA</span></span><br><span class="line">    <span class="type">int8_t</span>,                             <span class="comment">// ElementB</span></span><br><span class="line">    cutlass::layout::ColumnMajor,       <span class="comment">// LayoutB (Using the same trick as before)</span></span><br><span class="line">    <span class="type">int32_t</span>,                            <span class="comment">// ElementC</span></span><br><span class="line">    cutlass::layout::RowMajor,          <span class="comment">// LayoutC</span></span><br><span class="line">    <span class="type">int32_t</span>,                            <span class="comment">// ElementAccumulator</span></span><br><span class="line">    cutlass::arch::OpClassTensorOp,</span><br><span class="line">    cutlass::arch::Sm75,                <span class="comment">// Target GPU Architecture</span></span><br><span class="line">    cutlass::gemm::GemmShape&lt;<span class="number">128</span>, <span class="number">128</span>, <span class="number">32</span>&gt;, <span class="comment">// ThreadblockShape</span></span><br><span class="line">    cutlass::gemm::GemmShape&lt;<span class="number">64</span>, <span class="number">64</span>, <span class="number">32</span>&gt;,  <span class="comment">// WarpShape</span></span><br><span class="line">    cutlass::gemm::GemmShape&lt;<span class="number">8</span>, <span class="number">8</span>, <span class="number">16</span>&gt;,    <span class="comment">// InstructionShape</span></span><br><span class="line">    EpilogueGemmInt,</span><br><span class="line">    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle&lt;&gt;, <span class="comment">// Swizzle</span></span><br><span class="line">    <span class="number">2</span> <span class="comment">// Stages</span></span><br><span class="line">&gt;;</span><br><span class="line"></span><br><span class="line">&#125; <span class="comment">// namespace CUDA</span></span><br><span class="line">&#125; <span class="comment">// namespace MNN</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// CutlassGemmIntParam_hpp</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 准备阶段</span></span><br><span class="line">mGemmArguments = &#123;</span><br><span class="line">    &#123;M, N, ic_per_group&#125;,</span><br><span class="line">    &#123;<span class="literal">nullptr</span>, ic_per_group&#125;, <span class="comment">// ptr_A and lda_A</span></span><br><span class="line">    &#123;<span class="literal">nullptr</span>, <span class="built_in">UP_DIV</span>(K, <span class="number">8</span>) * <span class="number">8</span>&#125;, <span class="comment">// ptr_B and ldb_B</span></span><br><span class="line">    &#123;<span class="literal">nullptr</span>, <span class="built_in">UP_DIV</span>(N, <span class="number">8</span>) * <span class="number">8</span>&#125;, <span class="comment">// ptr_C and ldc_C</span></span><br><span class="line">    &#123;<span class="literal">nullptr</span>, <span class="built_in">UP_DIV</span>(N, <span class="number">8</span>) * <span class="number">8</span>&#125;, <span class="comment">// ptr_D and ldd_D</span></span><br><span class="line">    &#123;<span class="number">1</span>, <span class="number">0</span>&#125;, <span class="comment">// Epilogue: D = 1 * A*B + 0 * C</span></span><br><span class="line">    <span class="number">1</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Check if CUTLASS can support this problem</span></span><br><span class="line">cutlass::Status status = mCutlassGemmInt.<span class="built_in">can_implement</span>(mGemmArguments);</span><br><span class="line"><span class="keyword">if</span> (status != cutlass::Status::kSuccess) &#123;</span><br><span class="line">    <span class="built_in">MNN_ERROR</span>(<span class="string">&quot;CUTLASS GEMM cannot implement this problem\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> NOT_SUPPORT;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Allocate workspace if needed</span></span><br><span class="line"><span class="type">size_t</span> workspace_size = mCutlassGemmInt.<span class="built_in">get_workspace_size</span>(mGemmArguments);</span><br><span class="line"><span class="keyword">if</span> (workspace_size &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    mWorkspaceTensor.<span class="built_in">reset</span>(Tensor::<span class="built_in">createDevice</span>&lt;<span class="type">int8_t</span>&gt;(&#123;(<span class="type">int</span>)workspace_size&#125;));</span><br><span class="line">    <span class="built_in">backend</span>()-&gt;<span class="built_in">onAcquireBuffer</span>(mWorkspaceTensor.<span class="built_in">get</span>(), Backend::STATIC);</span><br><span class="line">    mWorkspacePtr = (<span class="type">void</span>*)mWorkspaceTensor-&gt;<span class="built_in">buffer</span>().device;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Initialize the GEMM kernel</span></span><br><span class="line">status = mCutlassGemmInt.<span class="built_in">initialize</span>(mGemmArguments, mWorkspacePtr);</span><br><span class="line"><span class="built_in">cutlass_check</span>(status);</span><br></pre></td></tr></table></figure>
<p>主函数：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> M = input-&gt;<span class="built_in">batch</span>();</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> K = input-&gt;<span class="built_in">channel</span>();</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = output-&gt;<span class="built_in">channel</span>();</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> ic_p = <span class="built_in">UP_DIV</span>(K, <span class="number">8</span>) * <span class="number">8</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> oc_p = <span class="built_in">UP_DIV</span>(N, <span class="number">8</span>) * <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> num_groups = (mResource-&gt;mQuanC &gt; <span class="number">0</span>) ? (mResource-&gt;mQuanC / N) : <span class="number">1</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> ic_per_group = (num_groups &gt; <span class="number">0</span>) ? (K / num_groups) : K;</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> Cq_tensor = std::<span class="built_in">make_shared</span>&lt;Tensor&gt;(Tensor::<span class="built_in">createDevice</span>&lt;<span class="type">int32_t</span>&gt;(&#123;M, oc_p&#125;));</span><br><span class="line"><span class="built_in">backend</span>()-&gt;<span class="built_in">onAcquireBuffer</span>(Cq_tensor.<span class="built_in">get</span>(), Backend::STATIC);</span><br><span class="line"><span class="type">int32_t</span>* C_q_buffer = (<span class="type">int32_t</span>*)Cq_tensor-&gt;<span class="built_in">deviceId</span>();</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> type_size = mFp16Infer ? <span class="built_in">sizeof</span>(half) : <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"><span class="keyword">auto</span> scaleA_tensor = std::<span class="built_in">make_shared</span>&lt;Tensor&gt;(Tensor::<span class="built_in">createDevice</span>&lt;<span class="type">uint8_t</span>&gt;(&#123;M * type_size&#125;));</span><br><span class="line"><span class="built_in">backend</span>()-&gt;<span class="built_in">onAcquireBuffer</span>(scaleA_tensor.<span class="built_in">get</span>(), Backend::STATIC);</span><br><span class="line"><span class="type">void</span>* scale_A_buffer = (<span class="type">void</span>*)scaleA_tensor-&gt;<span class="built_in">deviceId</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> offsetA_tensor = std::<span class="built_in">make_shared</span>&lt;Tensor&gt;(Tensor::<span class="built_in">createDevice</span>&lt;<span class="type">uint8_t</span>&gt;(&#123;M * type_size&#125;));</span><br><span class="line"><span class="built_in">backend</span>()-&gt;<span class="built_in">onAcquireBuffer</span>(offsetA_tensor.<span class="built_in">get</span>(), Backend::STATIC);</span><br><span class="line"><span class="type">void</span>* offset_A_buffer = (<span class="type">void</span>*)offsetA_tensor-&gt;<span class="built_in">deviceId</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> sumA_tensor = std::<span class="built_in">make_shared</span>&lt;Tensor&gt;(Tensor::<span class="built_in">createDevice</span>&lt;<span class="type">int32_t</span>&gt;(&#123;M&#125;));</span><br><span class="line"><span class="built_in">backend</span>()-&gt;<span class="built_in">onAcquireBuffer</span>(sumA_tensor.<span class="built_in">get</span>(), Backend::STATIC);</span><br><span class="line"><span class="type">int32_t</span>* sum_A_q_buffer = (<span class="type">int32_t</span>*)sumA_tensor-&gt;<span class="built_in">deviceId</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> Aq_tensor = std::<span class="built_in">make_shared</span>&lt;Tensor&gt;(Tensor::<span class="built_in">createDevice</span>&lt;<span class="type">int8_t</span>&gt;(&#123;M, ic_per_group&#125;));</span><br><span class="line"><span class="built_in">backend</span>()-&gt;<span class="built_in">onAcquireBuffer</span>(Aq_tensor.<span class="built_in">get</span>(), Backend::STATIC);</span><br><span class="line"><span class="type">int8_t</span>* A_q_buffer = (<span class="type">int8_t</span>*)Aq_tensor-&gt;<span class="built_in">deviceId</span>();</span><br><span class="line"></span><br><span class="line">runtime-&gt;<span class="built_in">memset</span>(output_addr, <span class="number">0</span>, M * N * type_size);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 按 K 维度块循环执行</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; num_groups; ++i) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> k_start = i * ic_per_group;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// QuantA</span></span><br><span class="line">    <span class="function">dim3 <span class="title">blocks_quant</span><span class="params">(M)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">threads_quant</span><span class="params">(BLOCK_SIZE)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// GEMM_Int8</span></span><br><span class="line">    <span class="function">dim3 <span class="title">blocks_gemm</span><span class="params">(UP_DIV(oc_p, SUB_GEMM_TILE_DIM), UP_DIV(M, SUB_GEMM_TILE_DIM))</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">threads_gemm</span><span class="params">(SUB_GEMM_TILE_DIM, SUB_GEMM_TILE_DIM)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// DequantAndAcc</span></span><br><span class="line">    <span class="function">dim3 <span class="title">blocks_dequant</span><span class="params">(UP_DIV(N, DEQUANT_TILE_DIM), UP_DIV(M, DEQUANT_TILE_DIM))</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">threads_dequant</span><span class="params">(DEQUANT_TILE_DIM, DEQUANT_TILE_DIM)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (mFp16Infer) &#123;</span><br><span class="line">        <span class="type">const</span> half* A_sub_ptr = (<span class="type">const</span> half*)input_addr + k_start;</span><br><span class="line">        <span class="type">const</span> <span class="type">int8_t</span>* B_sub_ptr = (<span class="type">const</span> <span class="type">int8_t</span>*)mResource-&gt;mFilter + k_start;</span><br><span class="line"></span><br><span class="line">        <span class="type">const</span> half* base_scale_B_ptr = (<span class="type">const</span> half*)mResource-&gt;mScale;</span><br><span class="line">        <span class="type">const</span> half* base_offset_B_ptr = (<span class="type">const</span> half*)mResource-&gt;mOffset;</span><br><span class="line">        <span class="type">const</span> <span class="type">int32_t</span>* base_sum_B_q_ptr = (<span class="type">const</span> <span class="type">int32_t</span>*)mResource-&gt;mSumBQ;</span><br><span class="line"></span><br><span class="line">        QuantA&lt;half&gt;&lt;&lt;&lt;blocks_quant, threads_quant&gt;&gt;&gt;(</span><br><span class="line">            A_sub_ptr, A_q_buffer,</span><br><span class="line">            (half*)scale_A_buffer, (half*)offset_A_buffer, sum_A_q_buffer,</span><br><span class="line">            M, ic_per_group, ic_p</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// GEMM_Int8&lt;&lt;&lt;blocks_gemm, threads_gemm&gt;&gt;&gt;(</span></span><br><span class="line">        <span class="comment">//     A_q_buffer, B_sub_ptr, C_q_buffer,</span></span><br><span class="line">        <span class="comment">//     M, N, ic_per_group, ic_per_group, ic_p, oc_p</span></span><br><span class="line">        <span class="comment">// );</span></span><br><span class="line">        </span><br><span class="line">        mGemmArguments.ref_A.<span class="built_in">reset</span>(A_q_buffer);</span><br><span class="line">        mGemmArguments.ref_B.<span class="built_in">reset</span>(B_sub_ptr);</span><br><span class="line">        mGemmArguments.ref_C.<span class="built_in">reset</span>(C_q_buffer);</span><br><span class="line">        mGemmArguments.ref_D.<span class="built_in">reset</span>(C_q_buffer);</span><br><span class="line">        </span><br><span class="line">        cutlass::Status status = <span class="built_in">mCutlassGemmInt</span>(mGemmArguments, mWorkspacePtr, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">cutlass_check</span>(status);</span><br><span class="line">        </span><br><span class="line">        DequantAndAcc&lt;half&gt;&lt;&lt;&lt;blocks_dequant, threads_dequant&gt;&gt;&gt;(</span><br><span class="line">            C_q_buffer, (half*)output_addr,</span><br><span class="line">            (<span class="type">const</span> half*)scale_A_buffer, (<span class="type">const</span> half*)offset_A_buffer,</span><br><span class="line">            base_scale_B_ptr, base_offset_B_ptr,</span><br><span class="line">            base_sum_B_q_ptr,</span><br><span class="line">            i, num_groups,</span><br><span class="line">            sum_A_q_buffer,</span><br><span class="line">            M, N, ic_per_group, oc_p</span><br><span class="line">        );</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// FP32</span></span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* A_sub_ptr = (<span class="type">const</span> <span class="type">float</span>*)input_addr + k_start; <span class="comment">// A 第 k 块的起始位置</span></span><br><span class="line">        <span class="type">const</span> <span class="type">int8_t</span>* B_sub_ptr = (<span class="type">const</span> <span class="type">int8_t</span>*)mResource-&gt;mFilter + k_start; <span class="comment">// B 第 k 块的起始位置</span></span><br><span class="line"></span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* base_scale_B_ptr = (<span class="type">const</span> <span class="type">float</span>*)mResource-&gt;mScale;</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* base_offset_B_ptr = (<span class="type">const</span> <span class="type">float</span>*)mResource-&gt;mOffset;</span><br><span class="line">        <span class="type">const</span> <span class="type">int32_t</span>* base_sum_B_q_ptr = (<span class="type">const</span> <span class="type">int32_t</span>*)mResource-&gt;mSumBQ;</span><br><span class="line"></span><br><span class="line">        QuantA&lt;<span class="type">float</span>&gt;&lt;&lt;&lt;blocks_quant, threads_quant&gt;&gt;&gt;(</span><br><span class="line">            A_sub_ptr, A_q_buffer,</span><br><span class="line">            (<span class="type">float</span>*)scale_A_buffer, (<span class="type">float</span>*)offset_A_buffer, sum_A_q_buffer,</span><br><span class="line">            M, ic_per_group, ic_p</span><br><span class="line">        );</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// GEMM_Int8&lt;&lt;&lt;blocks_gemm, threads_gemm&gt;&gt;&gt;(</span></span><br><span class="line">        <span class="comment">//     A_q_buffer, B_sub_ptr, C_q_buffer,</span></span><br><span class="line">        <span class="comment">//     M, N, ic_per_group, ic_per_group, ic_p, oc_p</span></span><br><span class="line">        <span class="comment">// );</span></span><br><span class="line">        </span><br><span class="line">        mGemmArguments.ref_A.<span class="built_in">reset</span>(A_q_buffer);</span><br><span class="line">        mGemmArguments.ref_B.<span class="built_in">reset</span>(B_sub_ptr);</span><br><span class="line">        mGemmArguments.ref_C.<span class="built_in">reset</span>(C_q_buffer);</span><br><span class="line">        mGemmArguments.ref_D.<span class="built_in">reset</span>(C_q_buffer);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Run the pre-initialized GEMM operation</span></span><br><span class="line">        cutlass::Status status = <span class="built_in">mCutlassGemmInt</span>(mGemmArguments, mWorkspacePtr, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">cutlass_check</span>(status);</span><br><span class="line">        </span><br><span class="line">        DequantAndAcc&lt;<span class="type">float</span>&gt;&lt;&lt;&lt;blocks_dequant, threads_dequant&gt;&gt;&gt;(</span><br><span class="line">            C_q_buffer, (<span class="type">float</span>*)output_addr,</span><br><span class="line">            (<span class="type">const</span> <span class="type">float</span>*)scale_A_buffer, (<span class="type">const</span> <span class="type">float</span>*)offset_A_buffer,</span><br><span class="line">            base_scale_B_ptr, base_offset_B_ptr,</span><br><span class="line">            base_sum_B_q_ptr,</span><br><span class="line">            i, num_groups,</span><br><span class="line">            sum_A_q_buffer,</span><br><span class="line">            M, N, ic_per_group, oc_p</span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">float</span> maxV = FLT_MAX, minV = -FLT_MAX;</span><br><span class="line"><span class="keyword">if</span> (mActivationType == <span class="number">1</span>) minV = <span class="number">0.0f</span>;</span><br><span class="line"><span class="keyword">if</span> (mActivationType == <span class="number">2</span>) &#123; minV = <span class="number">0.0f</span>; maxV = <span class="number">6.0f</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> total_threads_act = M * oc_p;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> block_size_act = BLOCK_SIZE;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> num_blocks_act = (total_threads_act + block_size_act - <span class="number">1</span>) / block_size_act;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (mFp16Infer) &#123;</span><br><span class="line">    BiasAndActivation&lt;half&gt;&lt;&lt;&lt;num_blocks_act, block_size_act&gt;&gt;&gt;((half*)output_addr, (<span class="type">const</span> half*)mResource-&gt;mBias, minV, maxV, M, N, oc_p);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    BiasAndActivation&lt;<span class="type">float</span>&gt;&lt;&lt;&lt;num_blocks_act, block_size_act&gt;&gt;&gt;((<span class="type">float</span>*)output_addr, (<span class="type">const</span> <span class="type">float</span>*)mResource-&gt;mBias, minV, maxV, M, N, oc_p);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">backend</span>()-&gt;<span class="built_in">onReleaseBuffer</span>(Cq_tensor.<span class="built_in">get</span>(), Backend::STATIC);</span><br><span class="line"><span class="built_in">backend</span>()-&gt;<span class="built_in">onReleaseBuffer</span>(scaleA_tensor.<span class="built_in">get</span>(), Backend::STATIC);</span><br><span class="line"><span class="built_in">backend</span>()-&gt;<span class="built_in">onReleaseBuffer</span>(offsetA_tensor.<span class="built_in">get</span>(), Backend::STATIC);</span><br><span class="line"><span class="built_in">backend</span>()-&gt;<span class="built_in">onReleaseBuffer</span>(sumA_tensor.<span class="built_in">get</span>(), Backend::STATIC);</span><br><span class="line"><span class="built_in">backend</span>()-&gt;<span class="built_in">onReleaseBuffer</span>(Aq_tensor.<span class="built_in">get</span>(), Backend::STATIC);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> NO_ERROR;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习入门笔记</title>
    <url>/2025/04/21/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p><a
href="https://www.bilibili.com/video/BV1sd4y167NS">强化学习的数学原理</a></p>
<p><a href="https://www.bilibili.com/video/BV1rooaYVEk8/">RL
基本原理</a></p>
<h2 id="一基本概念">一、基本概念</h2>
<ul>
<li>Agent：操作主体；</li>
<li>State：agent 所处状态（位置、速度等）；State Space：状态集合；</li>
<li>Action：可采取的行动，依赖于 state： <span
class="math inline">\(\mathcal{A}(s_i)\)</span>；State Transition：采取
action 后 state 的转变；</li>
<li>Policy：agent 在特定 state 采取的 action：概率表达为 <span
class="math inline">\(\pi(a_i | s_1)\)</span>；</li>
<li>Reward：采取某个 action 后得到的奖励（可负）； <span
class="math inline">\(p(r=1 | s1, a1)\)</span>；</li>
<li>Trajectory：一条 state-action-reward 链；Return：一个 Trajectory
沿途所有 Reward 之和；Discount Rate：计算 Discounted Return 时，reward
随步数的衰减因子 <span class="math inline">\(\gamma\)</span>；</li>
<li>Episode：走到终止态 Terminal State 的一个 Trajectory；没有 terminal
state 的任务称为 Continuing Tasks；通过将 target state 设为 absorbing
state（吸收态，采取行动仍回到自身且 reward 为
0），或仍直接视为普通状态，我们可以统一 episodic 和 continuing
tasks；</li>
<li>Markov Decision Process（MDP）：
<ul>
<li>具有 State（<span
class="math inline">\(\mathcal{S}\)</span>）、Action（<span
class="math inline">\(\mathcal{A}(s)\)</span>）和 Reward（<span
class="math inline">\(\mathcal{R}(s, a)\)</span>）；</li>
<li>具有 state transition probability <span
class="math inline">\(p(s’|s, a)\)</span>、reward probability <span
class="math inline">\(p(r|s, a)\)</span>；</li>
<li>具有 Policy <span class="math inline">\(\pi(a|s)\)</span>；</li>
<li>无记忆性：memoryless property：<span class="math inline">\(p(s_{t+1}
| a_{t+1}, s_t, \cdots, a_1, s_0) = p(s_{t+1} | a_{t+1}, s_t)\)</span>，
<span class="math inline">\(p(r_{t+1} | a_{t+1}, s_t, \cdots, a_1, s_0)
= p(r_{t+1} | a_{t+1}, s_t)\)</span></li>
</ul></li>
</ul>
<span id="more"></span>
<h2 id="二贝尔曼公式">二、贝尔曼公式</h2>
<ul>
<li>对一个特定的 Trajectory，设 <span class="math inline">\(v_i\)</span>
为处于 <span class="math inline">\(s_i\)</span> 时，此后得到的总
Return，则有 <span class="math inline">\(v_i = r_i + \gamma
v_{next}\)</span>，写成向量形式有 <span class="math inline">\(v = r +
\gamma \mathrm{P} v\)</span>，其中 <span
class="math inline">\(v\)</span>、<span class="math inline">\(r\)</span>
均为向量，<span class="math inline">\(\mathrm{P}\)</span>
为转移矩阵；这就是 deterministic problem（即无随机任务）的 Bellman
equation；</li>
<li>对于有概率的任务：
<ul>
<li><span class="math inline">\(S_t \xrightarrow{A_t} R_{t+1}, S_{t+1}
\xrightarrow{A_{t+1}} R_{t+2}, S_{t+2} \xrightarrow{A_{t+2}} R_{t+3},
\dots\)</span></li>
<li><span class="math inline">\(G_t = R_{t+1} + \gamma R_{t+2} +
\gamma^2 R_{t+3} + \cdots = R_{t+1} + \gamma G_{t+1}\)</span></li>
<li>State Value：当前 Policy 在当前 State 处之后所获 Return
的期望，可拆成 immediate reward 和 future reward 两部分：</li>
<li><span class="math inline">\(v_{\pi}(s) = \mathbb{E}[G_t|S_t = s] =
\mathbb{E}[R_{t+1}|S_t = s] + \gamma\mathbb{E}[R_{t+1}|S_t = s] \\=
\sum_a \pi(a|s) \sum_r p(r|s, a) r + \gamma\sum_{s&#39;} v_\pi(s&#39;)
\sum_a p(s&#39;|s, a) \pi(a|s) \\= \sum_a \pi(a|s) \left[ \sum_r p(r|s,
a) r + \gamma \sum_{s&#39;} p(s&#39;|s, a) v_\pi(s&#39;) \right], \quad
\forall s \in \mathcal{S}.\)</span></li>
<li>联立所有状态的 Bellman 等式，最终得到 <span
class="math inline">\(v_\pi = r_\pi + \gamma P_\pi v_\pi\)</span>，其中
<span class="math inline">\(v_\pi\)</span> 和 <span
class="math inline">\(r_\pi\)</span> 均为长度为状态数 <span
class="math inline">\(n\)</span> 的列向量；</li>
</ul></li>
<li>Bellman
公式的两种解法：直接解方程（必然有解，但复杂度较高），以及迭代法 [1]：
<span class="math inline">\(v_{k+1} = r_\pi + \gamma P_\pi
v_k\)</span>，可以证明最终 <span class="math inline">\(v\)</span>
收敛到解析解；</li>
<li>Action Value： <span class="math inline">\(q_\pi(s, a) =
\mathbb{E}[G_t|S_t = s, A_t = a]\)</span>，可以得到 <span
class="math inline">\(v_\pi(s) = \sum_a \pi(a|s) q_\pi(s,
a)\)</span>；</li>
</ul>
<h2 id="三贝尔曼最优公式">三、贝尔曼最优公式</h2>
<ul>
<li>若所有 <span class="math inline">\(s\)</span>，<span
class="math inline">\(v_{\pi_1}(s) \geq v_{\pi_2}(s)\)</span>，则称
<span class="math inline">\(\pi_1\)</span> 比 <span
class="math inline">\(\pi_2\)</span> 更好；</li>
<li>Bellman Optimality Equation： <span class="math inline">\(v =
\mathrm{max}_\pi (r_\pi + \gamma P_\pi v)\)</span>，就是求使得 Bellman
Equation 的 <span class="math inline">\(v_\pi(s)\)</span> 最大的 <span
class="math inline">\(\pi\)</span>；</li>
<li>使用 Contraction Mapping Theorem 可以证明：每次都将 Policy
改为固定走 Action Value 最大的那个 Action
[2]，多轮迭代后一定<em>指数</em>收敛至最优解，且此解是存在且唯一的、deterministic
的；</li>
<li>对于给定 <span class="math inline">\(\pi\)</span> <span
class="math inline">\(\pi\)</span><span class="math inline">\(v_{k+1} =
f(v_k) = max_\pi(r_\pi + \gamma P_\pi v_k)\)</span> 得到 <span
class="math inline">\(v^* = max_\pi(r_\pi = \gamma P_\pi
v^*)\)</span>，再求 <span class="math inline">\(\pi^* =
\mathrm{argmax}_\pi (r_\pi + \gamma P_\pi
v^*)\)</span>，此时得到<em>最优</em>策略；</li>
<li>定理：将所有 r 作正线性变换（ar+b，a
为正数）之后，最优策略不变；</li>
<li>注意：<span class="math inline">\(\gamma\)</span>
的衰减使得模型会求尽快到达 target state 的策略；</li>
</ul>
<h2 id="四值迭代与策略迭代">四、值迭代与策略迭代</h2>
<ul>
<li>值迭代：先得到初始 <span
class="math inline">\(v_0\)</span>，求得当前策略下的 <span
class="math inline">\(q_k(s, a)\)</span>，并以此得到 <span
class="math inline">\(a^*_k(s) = \mathrm{argmax}_a q_k(a,
s)\)</span>，然后做一次 [2] 得到 <span
class="math inline">\(\pi_{k+1}\)</span>，再做<em>一次</em> [1] 得到
<span class="math inline">\(v_{k+1}(s)\)</span>；</li>
<li>策略迭代：先随机得到 <span
class="math inline">\(\pi_0\)</span>，再用 [1] 求当前 <span
class="math inline">\(v_{\pi_k}\)</span>（这一步包含多次迭代），再用 [2]
得到 <span class="math inline">\(\pi_{k+1}\)</span>，如此循环迭代；</li>
<li>truncated（截断策略迭代）：二者折中，每轮迭代数步 <span
class="math inline">\(v\)</span>；</li>
<li>Policy Evaluation： <span class="math inline">\(v_{\pi_k} =
r_{\pi_k} + \gamma P_{\pi_k} v_{\pi_k}\)</span>；</li>
<li>Policy Improvement：<span class="math inline">\(\pi_{k+1} =
\mathrm{argmax}_\pi (r_\pi + \gamma P_\pi v_{\pi_k})\)</span>；</li>
</ul>
<h2 id="五蒙特卡洛方法">五、蒙特卡洛方法</h2>
<ul>
<li>Model-free 的、Offline 的 Policy Update 方法：需要等 episode
走完才能更新；</li>
<li>MC-Basic：求 <span class="math inline">\(q_k(s, a)\)</span>
时，用回第二节中的期望式，而非需要概率函数的形式；即使用蒙特卡洛随机走到终点（episode）做一次采样，最后统合采样结果得到期望；</li>
<li>MC Exploring Starts：每个 episode 的后缀同样是一个
episode，一次采样可更新多个 (s, a) 对的值；从每个 (s, a)
都要出发一次；</li>
<li>MC <span
class="math inline">\(\varepsilon\)</span>-Greedy：非最优行动也会有概率取到；一次
episode 可以非常长，不再需要每个 (s, a) 都出发；平衡
exploitation（充分利用）和 exploration（探索）；</li>
</ul>
<h2 id="六随机近似与随机梯度下降">六、随机近似与随机梯度下降</h2>
<ul>
<li>增量式求平均数： <span class="math inline">\(w_{k+1} = w_k -
\frac{1}{k} (w_k - x_k)\)</span>；</li>
<li>Stochastic Approximation：随机迭代类算法；</li>
<li>Robbins-Monro 算法： <span class="math inline">\(w_{k+1} = w_k - a_k
\tilde{g}(w_k, \eta_k)\)</span>；有严格的条件；</li>
<li>想求 <span class="math inline">\(\theta^*\)</span> 使得 <span
class="math inline">\(\mathbb{E}[f(\theta^*, X)] = 0\)</span> 时，可使用
<span class="math inline">\(w_{k+1} = w_k + a_k f(w_k,
X_k)\)</span>，其中 <span class="math inline">\(X\)</span> 为随机变量，
<span class="math inline">\(X_k\)</span> 为第 k 个时间步的采样值；</li>
<li>Stochastic Gradient Descent ：随机梯度下降算法，RM
算法的一个特例；</li>
<li>GD（需要知道函数）：<span class="math inline">\(w_{k+1} = w_k -
\alpha_k \nabla_w \mathbb{E}[f(w_k, X)] = w_k - \alpha_k
\mathbb{E}[\nabla_w f(w_k, X)]\)</span>；</li>
<li>BGD（Batch）：<span class="math inline">\(\mathbb{E}[\nabla_w f(w_k,
X)] \approx \frac{1}{n} \sum_{i=1}^{n} \nabla_w f(w_k,
x_i)\)</span>；</li>
<li>SGD：Batch 中 n = 1；MBGD：把采样分成多组，每次用一组（即 Batch 中 n
= m）；</li>
</ul>
<h2 id="七时序差分">七、时序差分</h2>
<ul>
<li><p>TD 算法：求解 Bellman 公式的 RM 算法</p>
<ul>
<li>对于 <span class="math inline">\(s_t\)</span>：<span
class="math inline">\(v_{t+1}(s_t) = v_t(s_t) - \alpha_t(s_t) \left[
v_t(s_t) - \left[ r_{t+1} + \gamma v_t(s_{t+1}) \right]
\right]\)</span></li>
<li>其它未走到状态，state value 估值不变，<span
class="math inline">\(v_{t+1}(s) = v_{t}(s)\)</span>；</li>
<li>第二项是学习率乘上当前与期望修正项的差异；</li>
<li>TD Target： <span class="math inline">\(\bar{v}_t \doteq r_{t+1} +
\gamma v_t(s_{t+1})\)</span>，TD Error： <span
class="math inline">\(\delta_t \doteq v_t(s_t) - \left[ r_{t+1} + \gamma
v_t(s_{t+1}) \right]\)</span>；</li>
<li>该算法只用于估计给定 policy 的 state value，即不依赖模型地计算
Bellman equation；</li>
<li>Model-free 的 Bellman equation： <span
class="math inline">\(v_\pi(s) = \mathbb{E} \left[ R + \gamma
v_\pi(S&#39;) \mid S = s \right]\)</span>；</li>
</ul></li>
<li><p>Sarsa（state-action-reward-state-action）算法：估计 action value
用于做 Policy Evaluation</p>
<ul>
<li>Sarsa：<span class="math inline">\(q_{t+1}(s_t, a_t) = q_t(s_t, a_t)
- \alpha_t(s_t, a_t) \left[ q_t(s_t, a_t) - \left[ r_{t+1} + \gamma
q_t(s_{t+1}, a_{t+1}) \right] \right]\)</span></li>
<li>Model-free 的 action value：<span class="math inline">\(q_\pi(s, a)
= \mathbb{E} \left[ R + \gamma q_\pi(S&#39;, A&#39;) \mid s, a
\right]\)</span></li>
<li>Online 算法：每走一步都可以迭代更新；</li>
<li>Expected Sarsa：将 Sarsa 最后一项改为 <span
class="math inline">\(\gamma \mathbb{E}[q_t(s_{t+1}, A)]\)</span>，即
<span class="math inline">\(v_t(s_{t+1}) = \mathbb{E}[q_t(s_{t+1},
A)]\)</span></li>
<li>所对应的 Bellman 公式：<span class="math inline">\(q_\pi(s, a) =
\mathbb{E} \left[ R_{t+1} + \gamma v_\pi(S_{t+1}) \mid S_t = s, A_t = a
\right]\)</span></li>
<li>Sarsa：<span class="math inline">\(G_t^{(1)} = R_{t+1} + \gamma
q_\pi(S_{t+1}, A_{t+1})\)</span></li>
<li>n-step Sarsa（Half-Online 算法）：<span
class="math inline">\(G_t^{(n)} = R_{t+1} + \gamma R_{t+2} + \cdots +
\gamma^n q_\pi(S_{t+n}, A_{t+n})\)</span></li>
<li>MC： <span class="math inline">\(G_t^{(\infty)} = R_{t+1} + \gamma
R_{t+2} + \gamma^2 R_{t+3} + \cdots\)</span></li>
<li>据此，n-step Sarsa 的迭代公式为 <span
class="math inline">\(q_{t+1}(s_t, a_t) = q_t(s_t, a_t) - \alpha_t(s_t,
a_t) \left[ q_t(s_t, a_t) - \left( r_{t+1} + \gamma r_{t+2} + \cdots +
\gamma^n q_t(s_{t+n}, a_{t+n}) \right) \right]\)</span></li>
</ul></li>
<li><p>Q-Learning 算法：直接估计最优 action value</p>
<ul>
<li><span class="math inline">\(q_{t+1}(s_t, a_t) = q_t(s_t, a_t) -
\alpha_t(s_t, a_t) \left[ q_t(s_t, a_t) - \left( r_{t+1} + \gamma
\max_{a \in \mathcal{A}} q_t(s_{t+1}, a) \right) \right]\)</span></li>
<li>求解的是 Bellman <em>最优</em>方程：<span class="math inline">\(q(s,
a) = \mathbb{E} \left[ R_{t+1} + \gamma \max_{a} q(S_{t+1}, a)
\,\middle|\, S_t = s, A_t = a \right]\)</span></li>
</ul></li>
<li><p>On-Policy 概念</p>
<ul>
<li>Behavior Policy：用于产生经验的 Policy；Target Policy：需要最优化的
Policy；</li>
<li>二者相同时为 On-Policy，不同时为 Off-Policy；</li>
<li>Sarsa 和 MC 是 On-Policy，Q-Learning 可以是 Off-Policy；</li>
</ul></li>
<li><p>总结：</p>
<p>$$</p>
<span class="math display">\[\begin{array}{l|l}
\textbf{Algorithm} &amp; \textbf{Expression of } \bar{q}_t \\
\hline
\text{Sarsa} &amp;
\bar{q}_t = r_{t+1} + \gamma q_t(s_{t+1}, a_{t+1}) \\

\text{n-step Sarsa} &amp;
\bar{q}_t = r_{t+1} + \gamma r_{t+2} + \cdots + \gamma^n q_t(s_{t+n},
a_{t+n}) \\

\text{Expected Sarsa} &amp;
\bar{q}_t = r_{t+1} + \gamma \sum_a \pi_t(a \mid s_{t+1}) q_t(s_{t+1},
a) \\

\text{Q-learning} &amp;
\bar{q}_t = r_{t+1} + \gamma \max_a q_t(s_{t+1}, a) \\

\text{Monte Carlo} &amp;
\bar{q}_t = r_{t+1} + \gamma r_{t+2} + \gamma^2 r_{t+3} + \cdots
\end{array}\]</span>
<p>$$</p></li>
</ul>
<h2 id="八值函数近似">八、值函数近似</h2>
<ul>
<li>值函数近似：用函数 <span class="math inline">\(\hat{v}(s,
w)\)</span> 拟合这些点：<span class="math inline">\(v_\pi(s_1), \ldots,
v_\pi(s_{|\mathcal{S}|})\)</span>；</li>
<li>线性函数近似：<span class="math inline">\(\hat{v}(s, w) = \phi^T(s)
w\)</span>，即类似 <span class="math inline">\(as^2 + bs + c\)</span>
形式，<span class="math inline">\(w\)</span> 即 <span
class="math inline">\([a, b, c]^T\)</span>；</li>
<li>Tabular 的算法是直接更新 <span class="math inline">\(q\)</span>
表，值函数近似算法则是更新 <span
class="math inline">\(w\)</span>，因此公式中 <span
class="math inline">\(q\)</span> 新增一个 <span
class="math inline">\(w\)</span> 参数即可（仍然都是 value update
阶段的算法）；</li>
<li>需要最优化的评估函数：<span class="math inline">\(J(w) = \mathbb{E}
\left[ \left( v_\pi(S) - \hat{v}(S, w) \right)^2 \right]\)</span></li>
<li>两种方法，Normal Distribution（各状态权重均等）与 Stationary
Distribution（状态权重等于它在 Episode 中出现的比例）；</li>
<li>Stationary Distribution： <span class="math inline">\({d_\pi(s)}_{s
\in S}\)</span> 表示一个 episode 中状态 <span
class="math inline">\(s\)</span> 的占比，当 episode
无限长时趋向于一个定值，且理论值符合等式 <span
class="math inline">\(d_\pi^T = d_\pi^T P_\pi\)</span>；于是 <span
class="math inline">\(J(w) = \sum_{s \in \mathcal{S}} d_\pi(s) \left(
v_\pi(s) - \hat{v}(s, w) \right)^2\)</span>；</li>
<li>GD：<span class="math inline">\(w_{k+1} = w_k - \alpha_k \nabla_w
J(w_k)\)</span>；为避免求期望，我们使用 SGD（一次只用一个样本）：<span
class="math inline">\(w_{t+1} = w_t + \alpha_t \left( v_\pi(s_t) -
\hat{v}(s_t, w_t) \right) \nabla_w \hat{v}(s_t, w_t)\)</span>；</li>
<li>用 MC（替换为 <span class="math inline">\(g_t\)</span>） 或
TD（替换为 <span class="math inline">\(r_{t+1} + \gamma \hat{v}(s_{t+1},
w_t)\)</span>）做迭代逼近求 <span
class="math inline">\(v_\pi(s_t)\)</span>；</li>
<li>DQN：用神经网络拟合 <span class="math inline">\(\hat{v}(s,
w)\)</span>
<ul>
<li>回顾 Q-Learning 要最小化的目标函数： <span
class="math inline">\(J(w) = \mathbb{E} \left[ \left( R + \gamma \max_{a
\in \mathcal{A}(S&#39;)} \hat{q}(S&#39;, a, w) - \hat{q}(S, A, w)
\right)^2 \right]\)</span>；</li>
<li>现在，使用两个神经网络分别拟合两项 q：<span class="math inline">\(J
= \mathbb{E} \left[ \left( R + \gamma \max_{a \in \mathcal{A}(S&#39;)}
\hat{q}(S&#39;, a, w_T) - \hat{q}(S, A, w) \right)^2
\right]\)</span>；先固定 <span class="math inline">\(w_T\)</span> 更新
<span class="math inline">\(w\)</span>，再反过来，如此反复；</li>
<li>于是，我们将 <span class="math inline">\(s\)</span>、<span
class="math inline">\(a\)</span>（作为输入特征）、<span
class="math inline">\(y_T = R + \gamma \max_{a \in \mathcal{A}(S&#39;)}
\hat{q}(S&#39;, a, w_T)\)</span>（作为 label）送进神经网络，训练 <span
class="math inline">\(w\)</span>；迭代一定次数后 <span
class="math inline">\(w_T = w\)</span>；</li>
<li>Experience Replay：将样本打散均匀采样，使得一个 episode
中的采样之间不存在因果关系；</li>
</ul></li>
</ul>
<h2 id="九策略梯度方法">九、策略梯度方法</h2>
<ul>
<li>将 <span class="math inline">\(\pi\)</span> 的写法从表格改为函数：
<span class="math inline">\(\pi(a|s, \theta)\)</span>；梯度方法即 <span
class="math inline">\(\theta_{t+1} = \theta_t + \alpha \nabla_\theta
J(\theta_t)\)</span>；</li>
<li>两个指标：
<ul>
<li>average state value <span class="math inline">\(\bar{v}_\pi =
\mathbb{E}[v_\pi(S)] = \mathbb{E} \left[ \sum_{t=0}^{\infty} \gamma^t
R_{t+1} \right] = \sum_{s \in \mathcal{S}} d(s) \, v_\pi(s) = d^T
v_\pi\)</span></li>
<li>average reward <span class="math inline">\(\bar{r}_\pi \doteq
\sum_{s \in \mathcal{S}} d_\pi(s)\, r_\pi(s) = \mathbb{E}[r_\pi(S)] =
\lim_{n \to \infty} \frac{1}{n} \, \mathbb{E} \left[ \sum_{k=1}^{n}
R_{t+k} \right]\)</span>，其中 <span class="math inline">\(r_\pi(s)
\doteq \sum_{a \in \mathcal{A}} \pi(a|s) \, r(s, a)\)</span>；</li>
<li>有性质：<span class="math inline">\(\bar{r}_\pi = (1 - \gamma) \,
\bar{v}_\pi\)</span>；</li>
</ul></li>
<li>目标函数的梯度计算：<span class="math inline">\(\nabla_\theta
J(\theta) = \sum_{s \in \mathcal{S}} \eta(s) \sum_{a \in \mathcal{A}}
\nabla_\theta \pi(a|s, \theta) \, q_\pi(s, a) = \mathbb{E} \left[
\nabla_\theta \ln \pi(A \mid S, \theta) \, q_\pi(S, A)
\right]\)</span>，其中 <span class="math inline">\(J(\theta)\)</span>
可以是 <span class="math inline">\(\bar{v}_\pi\)</span>、 <span
class="math inline">\(\bar{r}_\pi\)</span> 或 <span
class="math inline">\(\bar{v}_\pi^0\)</span>；</li>
<li>梯度上升：
<ul>
<li><span class="math inline">\(\theta_{t+1} = \theta_t + \alpha
\nabla_\theta J(\theta) = \theta_t + \alpha \, \mathbb{E} \left[
\nabla_\theta \ln \pi(A|S, \theta_t) \, q_\pi(S, A)
\right]\)</span>；</li>
<li>使用 Stochastic 避免期望，并用 MC 或 TD 方法近似 <span
class="math inline">\(q_\pi\)</span>即可得到： <span
class="math inline">\(\theta_{t+1} = \theta_t + \alpha \nabla_\theta \ln
\pi(a_t|s_t, \theta_t) \, q_t(s_t, a_t)\)</span>；其中使用 MC
近似的方法就被成为 REINFORCE；</li>
<li>将上式变形并将括号部分算作 <span
class="math inline">\(\beta_t\)</span>，会发现实际上就是在优化 <span
class="math inline">\(\pi(a_t|s_t, \theta_t)\)</span>：<span
class="math inline">\(\theta_{t+1} = \theta_t + \alpha \left(
\frac{q_t(s_t, a_t)}{\pi(a_t \mid s_t, \theta_t)} \right) \nabla_\theta
\pi(a_t|s_t, \theta_t)\)</span>；观察 <span
class="math inline">\(\beta_t\)</span>（步长）与 <span
class="math inline">\(q_t\)</span> 成正比，与 <span
class="math inline">\(\pi\)</span> 成反比，符合直觉；</li>
</ul></li>
</ul>
<h2 id="十actor-critic-方法">十、Actor-Critic 方法</h2>
<ul>
<li>Actor 代表 policy update（上一节中的 <span
class="math inline">\(\theta_t\)</span> 迭代式），Critic 代表 policy
evaluation（MC 或 TD求 <span class="math inline">\(q_t\)</span>，其中用
TD 求的方法就是 QAC 方法）；</li>
<li>A2C 或 TD AC 算法：推导易证将上一节的梯度减去一项 <span
class="math inline">\(b(S)\)</span>，对结果没有影响： <span
class="math inline">\(\nabla_\theta J(\theta)= \mathbb{E}_{S \sim
\eta,\, A \sim \pi} \left[ \nabla_\theta \log \pi(A|S, \theta_t) \left(
q_\pi(S, A) - b(S) \right) \right]\)</span>；经过推导，为了方便，通常将
<span class="math inline">\(b(S)\)</span> 选为 <span
class="math inline">\(v_\pi(S)\)</span>，从而减小方差，使估值更准确；同样具有直觉理解：<span
class="math inline">\(q_\pi(S, A) - v_\pi(S)\)</span>
代表“优势函数”，我们更应在意策略的相对性而非绝对数值；</li>
<li>公式化为： <span class="math inline">\(\theta_{t+1} = \theta_t +
\alpha \nabla_\theta \log \pi(a_t|s_t, \theta_t) \, \delta_t(s_t, a_t) =
\theta_t + \alpha \left( \frac{\delta_t(s_t, a_t)}{\pi(a_t \mid s_t,
\theta_t)} \right) \nabla_\theta \pi(a_t \mid s_t,
\theta_t)\)</span>，其中 <span class="math inline">\(\delta\)</span>
即优势函数；</li>
<li>通过重要性采样实现 off-policy： <span
class="math inline">\(\mathbb{E}_{X \sim p_0}[X]= \sum_x p_0(x) x
= \sum_x p_1(x) \frac{p_0(x)}{p_1(x)} x
= \mathbb{E}_{X \sim p_1} \left[ f(X) \right]\)</span>，允许我们在 p1
分布下获取 p0 分布的期望；于是在原式上除以原分布，乘上现分布（behavior
policy <span class="math inline">\(\beta(a|s)\)</span>）即可；</li>
<li>因为 <span class="math inline">\(\pi(a|s, 0) &gt;
0\)</span>，因此之前的方法均为 stochastic 方法；Deterministic Policy
Gradient（DPG）：改为确定型 <span class="math inline">\(a = \mu(s,
\theta) \dot{=} \mu(s)\)</span>；同样推导得到：<span
class="math inline">\(\nabla_\theta J(\theta) = \sum_{s \in \mathcal{S}}
\rho_\mu(s) \, \nabla_\theta \mu(s) \, \nabla_a q_\mu(s, a) \big|_{a =
\mu(s)}\)</span>；该方法为 off-policy；</li>
</ul>
<h2 id="十一ppo">十一、PPO</h2>
<ul>
<li>TRPO（Trust Region Policy Optimization）：
<ul>
<li>同样使用重要性采样，保证可信域中新策略比久策略更优；</li>
<li>推导得到： <span class="math inline">\(J(\theta’) - J(\theta) =
\mathbb{E}_{s_t \sim p\theta(s_t)} \left[ \mathbb{E}_{a_t \sim
\pi_\theta(a_t | s_t)} \left[ \frac{\pi_{\theta&#39;}(a_t |
s_t)}{\pi_\theta(a_t | s_t)} \cdot \gamma^t \cdot A_{\pi_\theta}(s_t,
a_t) \right] \right]\)</span>;</li>
<li>此时即求： <span class="math inline">\(\arg\max_{\theta&#39;}
\mathbb{E}_{s \sim \nu_\theta,\, a \sim \pi_\theta(\cdot|s)} \left[
\frac{\pi_{\theta&#39;}(a|s)}{\pi_\theta(a | s)} \cdot A_{\pi_\theta}(s,
a) \right] \quad \text{s.t.} \quad D_{\mathrm{KL}}(\pi_\theta(\cdot|s)
\,\|\, \pi_{\theta&#39;}(\cdot|s)) \leq \delta\)</span>；</li>
</ul></li>
<li>PPO（Proximal Policy Optimization）：
<ul>
<li>四个模型：策略（Policy / Actor）、价值（Value /
Critic）、奖励（Reward）、参考（Ref），其中只有前两个模型参与参数更新；</li>
<li>两个损失：策略、价值；</li>
<li>在 TRPO 基础上加一个 <span class="math inline">\(\beta\)</span>
项做实时调整： <span class="math inline">\(\arg\max_{\theta&#39;}
\mathbb{E}_{s \sim \nu_\theta,\, a \sim \pi_\theta(\cdot|s)} \left[
\frac{\pi_{\theta&#39;}(a | s)}{\pi_\theta(a | s)} \cdot
\hat{A}_{\pi\theta}(s, a) -\beta \, D_{\mathrm{KL}}\left[
\pi_\theta(\cdot|s) \, \| \, \pi_{\theta&#39;}(\cdot|s) \right]
\right]\)</span>，其中 <span class="math inline">\(\left\{
\begin{aligned} \beta &amp;\leftarrow \beta / 2 &amp; \text{if }
D_{\mathrm{KL}} &lt; \delta / 1.5 \\ \beta &amp;\leftarrow \beta \times
2 &amp; \text{if } D_{\mathrm{KL}} &gt; \delta \times 1.5 \end{aligned}
\right.\)</span></li>
<li>或直接做截断：<span class="math inline">\(\arg\max_{\theta&#39;}
\mathbb{E}_{s \sim \nu\theta,\, a \sim \pi_\theta(\cdot|s)} \left[ \min
\left( \frac{\pi_{\theta&#39;}(a|s)}{\pi_\theta(a|s)}
\hat{A}_{\pi\theta}(s,a), \
\text{clip}\left(\frac{\pi_{\theta&#39;}(a|s)}{\pi_\theta(a|s)}, 1 -
\epsilon, 1 + \epsilon\right) \hat{A}_{\pi\theta}(s,a) \right)
\right]\)</span></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型推理优化笔记</title>
    <url>/2025/03/04/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="总体框架">总体框架</h2>
<span id="more"></span>
<p>来源：<a href="https://github.com/chenzomi12/AIInfra">ZOMI</a>；</p>
<p><img src="Arch-1.png" /></p>
<p><img src="Arch-2.png" /></p>
<h2 id="gpu-architecture">GPU Architecture</h2>
<h3 id="体系结构以-hopper-为例">体系结构（以 Hopper 为例）</h3>
<ul>
<li><p>一个 GPU 包含 132 个 SM，80GB Global Memory（位于 HBM3（High
Bandwidth Memory） 芯片，此外还有常量内存和纹理内存），50MB L2 Cache（跨
SM 共享）；</p>
<p><img src="gpu-overall.png" /></p></li>
<li><p>一个 SM 中有 128 个 CUDA Core（具体见后文参数表截图），4 个 Sub
Core（每个 Sub Core有一个 Warp Scheduler 和一个 Dispatch Unit
共同控制指令发射），4 个 Tensor Core，1 个 TMA，228KB Shared Memory（L1
缓存，几百 K），256KB Register File，以及一般不需要考虑的 LSU 和 L0/L1
Instruction Cache；</p>
<p><img src="sm-arch.png" /></p></li>
<li><p>每个 CUDA Core 有整数、浮点运算单元，寄存器；寄存器放不下的放在
Local Memory （线程独占，但实际存放在 Global Memory 或 L2 Cache
中）；</p></li>
<li><p>Tensor Core：</p>
<ul>
<li><strong>Ampere（A100）</strong> 4×4×16 FP16, BF16, TF32, INT8；</li>
<li><strong>Hopper（H100）</strong> 8×8×16 FP8, FP16, BF16, TF32,
INT8</li>
<li><strong>Blackwell（GB200）</strong> 16×16×16 FP4, FP8, FP16,
BF16</li>
</ul>
<figure>
<img src="sub-core.png" alt="image.png" />
<figcaption aria-hidden="true">image.png</figcaption>
</figure></li>
<li><p>NCCL：</p>
<ul>
<li>NVLink：高速 GPU 互联总线（对应 CPU 的
PCIe）与通信协议，支持统一内存访问（Unified Memory Access）；</li>
<li>NVSwitch：NVLink 专用交换芯片（Switch Fabric），允许 All-to-All
Communication，解决直连拓扑的限制；</li>
<li>Broadcast：从一个 GPU 向所有 GPU
发送数据，用于模型参数广播（Distributed Training）；</li>
<li>Scatter：将一个 GPU 数据复制到多个 GPU，用于参数分配；</li>
<li>Reduce：将所有 GPU 数据汇总累加到一个 GPU，用于参数收集；</li>
<li>All-Reduce：计算所有 GPU 的数据和，并同步到每个
GPU，用于梯度平均（Data Parallel）；</li>
<li>Gather：将所有 GPU 数据汇总存储到一个 GPU；</li>
<li>All-Gather：所有 GPU 共享所有 GPU 的数据，用于模型并行（Tensor
Parallel）；</li>
<li>ReduceScatter：Reduce + Scatter 结合，用于高效梯度传输；</li>
</ul></li>
</ul>
<h3 id="hopper-架构参数">Hopper 架构参数</h3>
<ul>
<li><p><a
href="https://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/">Ampere
官方介绍</a>，<a
href="https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/">Hopper
官方介绍</a>，<a
href="https://resources.nvidia.com/en-us-data-center-overview/gtc22-whitepaper-hopper">H100
白皮书</a>；</p></li>
<li><p>144 SMs(Streaming Multiprocessor) per full GPU</p></li>
<li><p>128 FP32 CUDA Cores per SM, 18432 FP32 CUDA Cores per full
GPU</p></li>
<li><p>4 fourth-generation Tensor Cores per SM, 576 per full
GPU</p></li>
<li><p>60 MB L2 cache</p></li>
<li><p>引入了 Thread Block Cluster 和 <a
href="https://zhuanlan.zhihu.com/p/708645371">Distributed Shared
Memory</a>，硬件层面加入了 SM-to-SM Network；</p>
<p><img src="h100-arg-1.png" /></p>
<p><img src="h100-arg-2.png" /></p>
<p><img src="h100-arg-3.png" /></p>
<p><img src="h100-arg-4.png" /></p>
<p><img src="h100-arg-5.png" /></p>
<p><img src="h100-arch.png" /></p></li>
</ul>
<h3 id="blackwell-架构参数">Blackwell 架构参数</h3>
<ul>
<li><a
href="https://resources.nvidia.com/en-us-blackwell-architecture">Blackwell
伪白皮书</a>；</li>
<li>引入 FP4 / FP6；</li>
</ul>
<p><img src="gb200-arg-1.png" /></p>
<p><img src="gb200-arg-2.png" /></p>
<h3 id="cuda">CUDA</h3>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/680075822">入门1</a>，<a
href="https://zhuanlan.zhihu.com/p/690880124">入门2</a>，<a
href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/contents.html">官方文档</a>，<a
href="https://docs.nvidia.com/cuda/index.html">部分官方文档索引</a>；<a
href="https://zhuanlan.zhihu.com/p/632244210">内存访问</a>；</li>
<li>一个 Grid 对应一次 Kernel Launch；每个 Block 与 唯一一个 SM
对应（一个 SM 可以同时处理多个 Block）；线程调度的基本单位是 Warp，一个
Warp 32 个线程；</li>
<li>通过 WMMA API 或 mma.sync PTX（asm volatile）
指令<strong>异步</strong>调用 Tensor Core（或调用 cuBLAS 和 CUTLASS
库，后者定制化程度更高），分配调度单位是 Warp；</li>
</ul>
<h2 id="transformer-优化">Transformer 优化</h2>
<ul>
<li><p>常见推理优化指标：</p>
<ul>
<li>Throughput（吞吐量）：单位时间内处理 token 数 / 请求数；</li>
<li>TPS（Tokens Per Second）/ TPOT（Time Per Output Token）；</li>
<li>TTFT（Time to First Token）/ First-Token Latency；</li>
<li>MFU（Model FLOPs Utilization）模型算力利用率 / HFU（Hardware FLOPs
Utilization）硬件算力利用率；</li>
</ul></li>
<li><p>分布式训练：</p>
<ul>
<li>数据并行（Data Parallelism）：将模型复制 n
份，输入不同的小批量数据（mini-batch）并行训练，最后 All-Reduce
合并梯度更新；扩展：DeepSpeed ZeRO-1（优化器状态拆分）/
2（梯度信息拆分）/ 3（参数动态加载）；</li>
<li>流水线并行 Pipeline Parallelism：每个 GPU 负责几层，同时与前后 GPU
交互数据（后、前向传播），相当于纵向切割；需要尽可能减少 Bubble；</li>
<li>张量并行（Tensor Parallelism）：单个算子拆到多个 GPU
上，相当于横向切割；与流水线并行统称模型并行（Model Parallelism）；</li>
<li>LoRA：冻结其余参数，只微调 Attention
权重；使用低秩矩阵（将一个大矩阵拆成两个秩更低的矩阵之和）分解减少存储需求；</li>
</ul></li>
<li><p>Attention 相关公式：</p>
<ul>
<li><p><strong>前向传播公式：</strong></p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{a}^{(0)} &amp;= \mathbf{x} \\
\mathbf{z}^{(l)} &amp;= \mathbf{W}^{(l)} \, \mathbf{a}^{(l-1)} +
\mathbf{b}^{(l)}, \quad l=1,2,\ldots,L \\
\mathbf{a}^{(l)} &amp;= f^{(l)}\left(\mathbf{z}^{(l)}\right), \quad
l=1,2,\ldots,L \\
L &amp;= \mathcal{L}\left(\mathbf{a}^{(L)}, \mathbf{y}\right)
\end{aligned}
\]</span></p></li>
<li><p><strong>反向传播公式（</strong> <span
class="math inline">\(\odot\)</span>
为逐元素相乘）<strong>：</strong></p>
<p><span class="math display">\[
\begin{aligned}
\boldsymbol{\delta}^{(L)} &amp;= \nabla_{\mathbf{a}^{(L)}} \mathcal{L}
\odot f^{(L){\prime}}\left(\mathbf{z}^{(L)}\right) \\
\boldsymbol{\delta}^{(l)} &amp;= \left(\mathbf{W}^{(l+1)T}
\boldsymbol{\delta}^{(l+1)}\right) \odot
f^{(l){\prime}}\left(\mathbf{z}^{(l)}\right), \quad l=L-1,\ldots,1 \\
\frac{\partial L}{\partial \mathbf{W}^{(l)}} &amp;=
\boldsymbol{\delta}^{(l)} \, \mathbf{a}^{(l-1)T} \\
\frac{\partial L}{\partial \mathbf{b}^{(l)}} &amp;=
\boldsymbol{\delta}^{(l)}
\end{aligned}
\]</span></p></li>
<li><p>Self-Attention（ <span class="math inline">\(\mathbf{X} \in
\mathbb{R}^{n \times d}, \ \mathbf{W}^{Q}, \mathbf{W}^{K},
\mathbf{W}^{V} \in \mathbb{R}^{d \times d_k},\ d_k=d/head\)</span>）：
其它优化：</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Q} &amp;= \mathbf{X} \mathbf{W}^{Q}, \\
\mathbf{K} &amp;= \mathbf{X} \mathbf{W}^{K}, \\
\mathbf{V} &amp;= \mathbf{X} \mathbf{W}^{V}
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\mathbf{A} =
\text{softmax}(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}})\mathbf{V}, \\
a_{ij} = \frac{\exp\left(\frac{q_i \cdot
k_j}{\sqrt{d_k}}\right)}{\sum_{j{\prime}=1}^{n} \exp\left(\frac{q_i
\cdot k_{j{\prime}}}{\sqrt{d_k}}\right)}\mathbf{V}
\]</span></p></li>
<li><p>Multi-Head Attention：</p>
<p><span class="math display">\[
\text{head}_i = \text{Attention}(Q_i, K_i, V_i) = \text{softmax} \left(
\frac{Q_i K_i^T}{\sqrt{d_k}} \right) V_i
\]</span></p>
<p><span class="math display">\[
\text{MultiHead}(Q, K, V) = \text{Concat} ( \text{head}_1,
\text{head}_2, \cdots, \text{head}_h ) W^O
\]</span></p></li>
</ul></li>
<li><p>Attention 优化：</p>
<ul>
<li><p>KV-Cache：每次新加一个 token（上次的输出）， <span
class="math inline">\(Q\)</span> 新增一行， <span
class="math inline">\(QK^T\)</span> 新增一行（由 <span
class="math inline">\(Q\)</span> 新增那行与整个 <span
class="math inline">\(K\)</span> 共同算得）， <span
class="math inline">\(A\)</span> 新增一行（由 <span
class="math inline">\(QK^T\)</span> 的最新行与整个 <span
class="math inline">\(V\)</span> 共同算得）；一般分至少 30% 显存用于
KV-Cache；</p></li>
<li><p>KV-Cache Reuse：常用 KV Cache 常驻显存，适合 Long System Prompt
场景；</p></li>
<li><p><a
href="https://www.zhihu.com/question/611905691/answer/3457031781">PagedAttention</a>：由于序列增长速度快，需要类似
OS 的内存分配机制，设一个块表（Block
Table），用于从连续的逻辑地址映射到不连续的物理地址；<a
href="https://juejin.cn/post/7259249904778018853">GIF
演示</a>；</p></li>
<li><p><a
href="https://juejin.cn/post/7259287148321800253">FlashAttention</a>：合理利用
GPU 内存结构，减少访存次数；计算复杂度保持 <span
class="math inline">\(O(n^2)\)</span> 但不存储 <span
class="math inline">\(O(n^2)\)</span> 的权重矩阵；尽量将 GMEM 的访存移到
SMEM 中；</p>
<p><img src="flashattention.png" /></p></li>
<li><p>LinearAttention：利用核函数（Kernel）和低秩分解将时空复杂度均从
<span class="math inline">\(QK^T\)</span> 的 <span
class="math inline">\(O(n^2)\)</span> 降到 <span
class="math inline">\(\phi(Q) \cdot \phi(K)^T = KQ^T\)</span> 的 <span
class="math inline">\(O(n^2)\)</span>；</p></li>
<li><p>StreamingAttention：类似 Sliding Window
Attention，将全局注意力限制在常数级别的固定窗口内以达到加速，又尽可能捕捉到全局信息；</p></li>
</ul></li>
<li><p>其它优化：</p>
<ul>
<li>Continuous Batching（In-flight Batching）：因此当一个 Batch
中某个回答结束后，立即加入新的回答以填满 Batch；</li>
<li>Chunked Prefill / Context：将长 Prompts 拆成多个
Chunks，按批次计算，允许多个请求共享资源；提高吞吐量、降低推理延迟、节省计算资源，避免某个
Generation Phase 的 token 由于进来一个超长 Context
而被阻塞；对显存大小要求更高、访存代价更高；</li>
<li>Grouped-Query Attention：多个 Head 共享一组 Key 和
Value；Multi-Query Attention：所有 Head 共享一组 Key 和 Value；</li>
<li>Split-K：矩阵乘法维度分割；</li>
<li>模型压缩：量化（Quantization）、蒸馏（Distillation）、剪枝（Pruning）、二值化（Binarization）；</li>
<li>训练部分：<a
href="https://www.bilibili.com/video/BV1UQw2erEPW">Training
Resiliency</a>；</li>
<li>Batch GEMM：允许多个形状相同的矩阵对并行计算，在单一 Kernel
内完成；Grouped GEMM 允许不同形状，限制更少；</li>
</ul></li>
</ul>
<h2 id="量化"><strong>量化</strong></h2>
<ul>
<li><p>混合精度训练：</p>
<p><img src="mixed-precision-1.png" /></p>
<p><img src="mixed-precision-2.png" /></p></li>
<li><p>DeepSeek-V3 中的混合精度：</p>
<p><img src="dpsk-1.png" /></p></li>
<li><p>作用：保精度加速、省显存；指标：性能、精度、显存；</p>
<p><img src="quant-1.png" /></p>
<p><img src="quant-2.png" /></p></li>
<li><p>TRT-LLM
会将量化（Quant）、重量化（ReQuant）和反量化（DeQuant）均作为算子；</p>
<p><img src="quant-3.png" /></p></li>
<li><p>量化参数：缩放因子（scale）和零点（zero-point）；</p></li>
<li><p>各类方法：</p>
<ul>
<li><a
href="https://zhuanlan.zhihu.com/p/548174416">训练时量化</a>（Quant
Aware Training）：插入伪量化算子（Fake
Quant，作用通常是检测数据极差以确定缩放因子、阶梯化高精度数据），作为高精度模型一部分参与微调，然后导出为低精度；这些伪量化算子在推理时直接做常量折叠；</li>
<li>训练后量化（Post-Training
Quantization）：离线静态、动态量化：用一些实际数据分布模拟输入用于校准（Calibration），使用
KL
散度（计算真实激活值分布与预测分布的相对熵差异）计算量化参数；静态量化参数固定，动态量化则会根据输入确定
scale 和 zero-point；目前推理引擎多使用静态；</li>
<li>激活感知量化（Activation-aware Weight
Quantization）：静态，根据不同通道在前向传播中的影响（离群值、关键
Channel 等），针对性调整策略，仅量化影响小的参数；</li>
<li>GPT-Q：静态，采用梯度下降，追求全局最优化，可以追求极低比特
4bit；</li>
</ul></li>
<li><p>量化粒度：</p>
<ol type="1">
<li>Per-token，Per-channel，Per-tensor；</li>
<li>Block（块级量化） + Double（双重量化） + Dynamic
Quant（根据输入动态量化）；</li>
</ol></li>
</ul>
<h2 id="nvidia-ai-software">NVIDIA AI Software</h2>
<h3 id="cutlass"><a
href="https://www.bilibili.com/video/BV1XH4y1c7JZ">Cutlass</a></h3>
<p><img src="cutlass-1.png" /></p>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/703256080">CUDA
矩阵乘法</a>；<a href="https://zhuanlan.zhihu.com/p/461060382">Cutlass
入门</a>；<a href="https://zhuanlan.zhihu.com/p/697571068">Tensor Core
利用</a>；</p></li>
<li><p>可以做 Kernel Fusion，直接成果 Fused Multi-Head
Attention；</p></li>
<li><p>流水优化：在前一个 Thread 做运算的同时做后一个 Thread 的 Data
Loading（Prefetch），从而掩盖访存 Latency；</p>
<ul>
<li>Prologue：Launch，Load Activation，Load Weights；</li>
<li>Main Loop（Tensor Core 使用阶段）；</li>
<li>Epilogue：Store Activation；</li>
</ul></li>
<li><p>Cutlass 2.x：针对 Pre-Hopper archs（Ada sm_89 及之前）；</p>
<ul>
<li>计算完成后，在 Shared Memory 中做 Epilogue 和
Alignment，对齐后使用更大访存 API 写回 Global Memory；</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">using</span> <span class="variable">ThreadBlockShape</span> <span class="operator">=</span> cutlass::gemm::GemmShape&lt;<span class="number">128</span>, <span class="number">128</span>, <span class="number">64</span>&gt;; </span><br><span class="line"><span class="type">using</span> <span class="variable">ShapeMMAWarp</span> <span class="operator">=</span> cutlass::gemm::GemmShape&lt;<span class="number">64</span>, <span class="number">64</span>, <span class="number">64</span>&gt;; </span><br><span class="line"><span class="type">using</span> <span class="variable">ShapeMMAThread</span> <span class="operator">=</span> cutlass::gemm::GemmShape&lt;<span class="number">16</span>, <span class="number">8</span>, <span class="number">16</span>&gt;;</span><br><span class="line"><span class="type">using</span> <span class="variable">EpilogueOp</span> <span class="operator">=</span> cutlass::epilogue::thread::LinearCombination&lt;...&gt;;</span><br></pre></td></tr></table></figure></li>
<li><p>Cutlass 3.x：增加 Hopper sm_90a kernels；</p>
<ul>
<li><p>只需要指定 BlockShaper 和 ClusterShape，WarpShape
会自动推断；</p></li>
<li><p>分阶段使用 <code>using</code> 指定 Shape 和操作而非一次性全塞进
<code>cutlass::gemm::device::Gemm</code> 中；</p></li>
<li><p>自动根据 Alignment 是否符合 TMA 要求决定使用 UTMALDG 还是 LDGSTS
异步指令，前者只需一个或两个 Warp 做异步 Data Loading，其余 Warp 只做
Tensor Core 计算（在所需数据加载完之后）；</p></li>
<li><p>Kernel Scheduler: Warp Specialized + Pingpong；使用 Barrier
做同步；</p></li>
<li><p>绿色代表 Producer Warps（Prologue / Epilogue），蓝色代表 TC
Warps（Tensor Core Calculation）；</p>
<p><img src="cutlass-2.png" /></p>
<p><img src="cutlass-3.png" /></p></li>
</ul></li>
<li><p>CuTe：Cutlass 3.0 提出；</p>
<ul>
<li><p>Layout&lt;Shape, Stride&gt;：将 n-D 逻辑坐标映射到 1-D
物理索引；Shape 指定逻辑矩阵形状，Stride
按行、列、层的顺序指定相邻两值在物理索引的距离；</p></li>
<li><p>Tensor&lt;Ptr, Layout&gt;：Layout + 对应物理空间指针；同一个 Ptr
可以组合不同 Layout；</p></li>
<li><p>关键数据传输指令：Copy 和 TiledCopy；</p>
<p><img src="cutlass-4.png" /></p></li>
</ul></li>
</ul>
<h3 id="tensorrt-llm">TensorRT-LLM</h3>
<ul>
<li><p>TensorRT 不支持多卡、未对 LLM 做针对性适配；</p></li>
<li><p>FasterTransformer 太上层、C++
搭建、未发布为产品，不再维护；</p></li>
<li><p>TRT-LLM 结合了 FasterTransformer 的性能和 TRT
的迭代速度；</p></li>
<li><p>对非 LLM 模型可以直接使用 TensorRT Engine 搭建，再与 TRT-LLM
Engine 结合成 Pipeline；也支持用户自定义模型架构；</p></li>
<li><p>显存结构：Weight、Internal Activation Tensors（Activation）、IO
Tensors（KV-Cache）；max_num_tokens 参数决定了 Activation
的维度，从而影响剩余的 KV-Cache 大小；</p></li>
<li><p>支持量化：</p>
<ul>
<li><p>FP16 / BF16；</p></li>
<li><p>Weight-only（INT8 / INT4）；</p></li>
<li><p>W4A16（AWQ / GPTQ）；</p></li>
<li><p>W8A8 SmoothQuant（INT8）；</p></li>
<li><p>FP8（Hopper / Ada Lovelace）；</p></li>
<li><p>KV Cache Quantization（INT8 / FP8）；</p>
<p><img src="trtllm.png" /></p></li>
</ul></li>
<li><p>架构流程：</p>
<ul>
<li>Convert Checkpoint：ONNX 等模型导入，反序列化，转换成计算图和
Inference IR；在此指定 TP、PP Size 和 Data Type；</li>
<li>Define Model Architecture：预设各类主流 LLM；</li>
<li>Load weight &amp; Build engine：构建一个独立的执行引擎；根据当前 GPU
做 Self-Attention 优化、混合精度量化和反量化、算子融合与图优化、Kernel
级别流水线优化；NVIDIA AMMO 低精度量化校准库；</li>
<li>Execution：推理，Summarize，MMLU 评估；</li>
</ul></li>
</ul>
<h3 id="megatron-lm">Megatron-LM</h3>
<ul>
<li>多种并行模式混合的分布式训练框架，使用多种并行；</li>
<li>混合精度矩乘：使用 FP16 前、反向传播但主权重仍为 FP32；通过 Loss
Scaling（计算梯度前将损失 L 乘上缩放因子 S，更新时再除以
S）避免数值下溢；</li>
<li>引入 Context Parallelism 和 Sequence Parallelism；</li>
</ul>
<h3 id="triton">Triton</h3>
<ul>
<li><p>多框架（PyTorch、TensorFlow）、多种请求（实时、批处理、流式）、多种硬件（CPU、GPU）、跨平台的统一推理服务；</p></li>
<li><p>可与 K8S 结合以实现 MLOps，提供性能评估等功能；</p></li>
<li><p>动态批处理：多个请求打包成一个 Batch（PD 可以被打进一个
Batch）；</p></li>
<li><p>一卡多用：提供请求调度功能；</p></li>
<li><p>版本管理：方便 A/B 测试、在线更新与回滚、日志与监控；</p></li>
<li><p>模型仓库、配置文件；</p></li>
<li><p>API：RESTful 与 gRPC 与客户端交互；</p>
<p><img src="triton-1.png" /></p>
<p><img src="triton-2.png" /></p></li>
</ul>
<h3 id="nemo">NeMo</h3>
<ul>
<li><p>在 Triton 基础上新增端到端云上训练、微调与部署：同样包含
Megatron-LM 中带有 Transformer Engine 的核心功能
Megatron-Core；</p></li>
<li><p>推理：NeMo Framework Inference 即 TRT-LLM
开发与运行时库；</p></li>
<li><p>多模态、结构化数据处理（Curation）；简化各项配置；</p></li>
<li><p>检测硬件，自动选择合适的超参（Batch Size、Data Type
等）；</p></li>
<li><p>SFT、RLHF 等后训练支持；</p></li>
<li><p>企业级安全性；</p>
<p><img src="nemo.png" /></p></li>
</ul>
<h3 id="nim">NIM</h3>
<ul>
<li>与 Triton
同层级或更高层级的版本管理、动态批处理、负载均衡、监控与管理；</li>
<li>原生支持容器化与 K8S
云原生部署，开箱即用（OOTB），更易扩展，更适配多机部署；</li>
<li>与 Triton 一样后端使用 TensorRT-LLM；</li>
<li>解耦【应用层代码】与【模型代码、权重、Infrastructure】；</li>
<li>NIM Pod 可与 KServer 等结合；</li>
</ul>
<h2 id="其它推理框架"><strong>其它推理框架</strong></h2>
<ul>
<li><p>推理框架常见架构：</p>
<ul>
<li>Inference IR：将 TensorFlow、ONNX 等格式转换为统一中间表示；</li>
<li>Pre Optimization：公共表达式消除、死代码优化、代数简化；</li>
<li>Optimization：算子融合（典型：Conv2d+BN+RELU ⇒
CBR）、冗余算子消除、算子替换、常量折叠；</li>
<li>Post Optimization：数据格式转换、内存布局优化、重复算子合并；</li>
</ul></li>
<li><p>MNN：</p>
<ul>
<li><p>针对移动端和嵌入式的轻量推理框架，支持 iOS 和支持 POSIX
的所有系统；</p></li>
<li><p>无依赖，深度裁剪：静态库体积 iOS 几 M，安卓几百 K；</p></li>
<li><p>组成部分：Converter（前端多种格式转换 → 图优化、算子融合） ⇒
Interpreter（Engine 加载转换后的模型，Backends 支持
Metal、OpenCL、Vulkan 等多种实现）</p></li>
<li><p>其它优化：预推理（评估不同计算策略的资源需求，预分配资源），手写汇编低精度运算库、关键算子；</p>
<p><img src="mnn-1.png" /></p>
<p><img src="mnn-2.png" /></p></li>
</ul></li>
<li><p><a
href="https://zhuanlan.zhihu.com/p/706097807">MoonCake</a>：</p>
<ul>
<li>PD 分离：解耦 Prefill（Context Phase，Compute
Bound，计算密集、带宽打不满）和 Decode（Generation Phase，Memory
Bound，访存密集、算力不满）两阶段（即分布式内存系统 +
流处理系统）；</li>
<li>构建全局 KVCache Pool，实现以 Cache 为中心的调度（KVCache-centric
Scheduling）；</li>
</ul></li>
<li><p>vLLM：</p>
<ul>
<li>PagedAttention：除了解决显存分配问题外，可以更方便地实现部分 Cache
的共用，特别是共用前缀的情况；</li>
<li>Continuous Batching，将任务分为 waiting、running、swapped
三类，计算结束的立即释放；</li>
</ul></li>
</ul>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>大语言模型（LLM）随笔</title>
    <url>/2025/02/20/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E9%9A%8F%E7%AC%94/</url>
    <content><![CDATA[<p><em>本文知识截止至 2025.2.20</em></p>
<p>以下每节标题的标注表示该技术在这个时期趋于成熟。</p>
<h2 id="transformer-介绍gpt-3-及之前">Transformer 介绍（GPT-3
及之前）</h2>
<p>Transformer 是这波 AI
热潮的起点，除了它的发明以外，大模型没有魔法。</p>
<p>Transformer 结构的
LLM，本质是一个可并行加速的有损压缩包：它将海量的知识、语法、运算模式、应答模式等等压缩到自己的权重中。</p>
<p>其本体是一个由线性、非线性变换组成的复杂函数，这个函数是一个文章续写器：输入是一段（编码后的）文本，输出是对这段文本的续写下一个词。与之前模型不同的是，每个预测词的生成都会考虑之前所有词（包括输入和已经生成的词），综合计算得到下一个预测词，且这个过程可以并行。</p>
<p>每次运行这个函数，会输出一个模型预测的概率最大的续写在输入之后的词（实际上是
token），然后将这个词接在输入之后形成新的输入再次运行函数，一直循环直到模型生成表示停止的
token；（以上为最基础的过程，现在已有 MTP 等优化技术）。</p>
<p>这个函数中的参数（如线性变换的系数）是可训练的，训练过程是将文字资料的一部分输入给函数，然后将函数生成的续写与文字资料原本的后续做比对，根据差异调整函数参数。</p>
<span id="more"></span>
<h2 id="模型训练与推理gpt-3.5">模型训练与推理（GPT-3.5）</h2>
<p>训练：通过调整模型参数（也即上文中的“函数参数”），使这个文章续写器的内容生成质量更高、更符合人类需要，主要包含两类：</p>
<ul>
<li><p>预训练（Pre-train）：输入（筛选后的）互联网上的海量知识，使模型学习知识、语法、运算模式等；这一步使模型成为一个语法（基本）通顺、简单数学运算（大体）正确、知识（部分）正确的文本续写器；这一步结束时，会得到一个能说会道的续写器（成为
Base 模型），但并不能正确理解并回应人类要求；</p></li>
<li><p>后训练（Post-train）：这个训练阶段用于将续写器调整成指令应答器，即让模型学会“回答”人类的指令，而不只是续写；以下为两个常见步骤（由于这一部分的训练数据量远小于
Pretrain，因此常被称为微调 Fine-tuning）：</p>
<ul>
<li>Instruction Tuning：Supervised
Fine-Tuning（SFT）的一种，使用人工标注的任务数据训练模型；训练者人工生成大量
&lt;用户提问, 机器应有的应答&gt; 对。这个过程可以使用 LLM 辅助，由 LLM
生成文本，人只需要将其整理编排成一个合适的回答。如下例，前两行是训练数据。训练完成，开始推理时，会将用户提问包装成后两行的形式，让大模型续写：</li>
</ul>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&lt;|im_start|&gt;user&lt;|im_sep|&gt;What is 2+2?<span class="tag">&lt;<span class="name">im_end</span>&gt;</span></span><br><span class="line">&lt;|im_start|&gt;assistant&lt;|im_sep|&gt;2+2 = 4<span class="tag">&lt;<span class="name">im_end</span>&gt;</span></span><br><span class="line"></span><br><span class="line">&lt;|im_start|&gt;user&lt;|im_sep|&gt;What is 3+4?<span class="tag">&lt;<span class="name">im_end</span>&gt;</span></span><br><span class="line">&lt;|im_start|&gt;assistant&lt;|im_sep|&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>Reinforcement Learning from Human
Feedback（RLHF）：人类标注者对模型的不同输出进行排序，告诉模型什么样的输出相对更优；通过强化学习的奖励机制，使模型做出调整；这将人类从生成指令-应答对的工作中解放出来，而只需要评价，大幅减少工作量。</li>
</ul></li>
</ul>
<p>需要意识到的是，后训练让模型能够应答人类指令，但这并不改变它本质上仍然是一个“续写器”的事实，只是它续写的内容能够构成对输入指令的应答；</p>
<p>推理：训练结束后，参数固定，输入指令（以下称为
prompt），获得应答；</p>
<h2 id="模型能力">模型能力</h2>
<p>之所以后训练能够起效，是因为随着参数量和训练数据的增长，大模型涌现出了以下能力：</p>
<ul>
<li>泛化能力：可以粗略理解为“模仿能力”，它能找出训练文本或输入文本的一定规律，并使得输出也按照此规律；这使得
few-shot 甚至 zero-shot 成为可能；</li>
<li>推理能力：在数学、逻辑等理科层面进行多步逻辑推演的能力；</li>
</ul>
<p>此外，大模型还擅长完全复述，这使得输入中的一串特定文本（如一个名字、一串秘钥）能够被完全一致地输出；</p>
<p>相反，大模型不擅长以下问题：</p>
<ul>
<li>直接作答：大模型确实有推理能力，但由于模型是一个词一个词地输出，因此推理能力也分摊到每个词之上；对于一个逻辑问题，模型需要先分析（输出推理的过程）再得到结果，如果强行使它直接报出答案，正确率会很低；</li>
<li>计数问题：数用户输入中有多少个字母等；这是一个典型的“直接作答”问题，如果不可以拉长推理过程，回答很可能出错；</li>
<li>严格地推理：因为 LLM
是概率模型，每个预测词的输出都是选择概率最高的那一个；</li>
<li>改变知识：由于知识储存在模型参数中，而用户的使用不影响模型参数，因此一旦参数确定，用户无法改变大模型的知识和“信念”；</li>
<li>自我识别（self-recognition）：再次重复，大模型的本质是经过大量人为调整后的“续写器”，它之所以能条理清晰地应答用户指令，很大程度是因为它在
SFT
阶段学习了相似的用户指令，然后凭借模型自身的模仿能力，模仿生成了一段能够应答新用户问题的输出。</li>
</ul>
<h2 id="多模态与工具使用gpt-4o">多模态与工具使用（GPT-4o）</h2>
<p>多模态大模型使用共享 Transformer
结构，通过编码等技术使得文字、图像、音频最终能被嵌入到同一个 Transformer
结构中，从而在统一的框架下进行处理；</p>
<p>此外，大模型可以使用一些外部工具（浏览器搜索、计算器、代码执行器等），其流程是模型经过
SFT
后，学习到在一些情况下，生成需要在浏览器中搜索的关键字、需要计算器辅助计算的算式等，并用特殊特殊
token 包裹，然后暂停输出；系统取出特殊 token
中间的关键字或算式，交给浏览器或计算器执行，并将结果重新输入到模型中；此时模型根据输入继续预测输出，得到结果。</p>
<p>可以认为一个 LLM 应用（如
ChatGPT）是一个操作系统，其中核心是大模型（即续写器），外围是各类可以与
LLM
交互的工具。这些工具提供确定的计算结果、或是最新的网络搜索结果并交给大模型。</p>
<h2 id="模型推理gpt-o1">模型推理（GPT-o1）</h2>
<p>从前文我们已经可以得出，模型推理所需要的一个必要条件：让多个 token
分摊推理任务，而不是期望一个 token
完成全部的推理操作。此外，一个自然的想法是，对于很多问题，人类无法指定思考过程（也并不重视此过程而只重视结果），因此希望大模型自己学习出推理的能力。</p>
<p>这两个想法分别诞生了以下两个 Reasoning 关键技术：</p>
<ol type="1">
<li>慢思考：通过拉长 Chain of
Thought（思维链）长度，输出大段思考过程，从而减轻单个 token
的推理负担。这一技术用输出长度换取推理准确度；</li>
<li>强化学习：对于一些强逻辑性的推理问题，只提供问题和结果，设置合理的奖励函数，让模型自己训练出合理的思考方式；方法有
PPO、GRPO
等，这些方法可以让模型在思考的过程的某几个时刻有“自我纠错”的能力，以及重复验证的能力（类似于人类解答和检查理科试题时“用不同方法各算一次看结果是否一致”的技巧）。</li>
</ol>
<p>从此开始，大模型开始具备“思考”的能力。</p>
<h2 id="未来展望">未来展望</h2>
<p>以下为我个人极其简单粗略的预测。</p>
<h3 id="回答准确度">回答准确度</h3>
<p>这一点可以通过继续扩大基础模型参数量和训练文本量、拉长思维链、使用更优秀的强化学习实现。</p>
<p>但是，这三点的发展都将很快进入瓶颈。模型参数量和训练文本量都已经几乎达到上限（Pre-training
as we know it will unquestionably
end），思维链目前已经很长，而更优秀的强化学习算法则是极难发现的。</p>
<p>个人预测，这一轮大模型的上限将很大程度上取决于强化学习、对比学习、模仿学习等算法的进展。</p>
<h3 id="记忆能力">记忆能力</h3>
<p>大模型的上下文记忆能力仍然不够。目前的典型值为
128K，这个长度对于常规问答来说足够，但对于需要多步处理的复杂问题（如需要多次改进的编程问题、要数百步数千步才能解决的数学难题、各类因素和参数繁杂的工程问题），这个长度远远不够。</p>
<p>目前已有针对此问题提出的一些解决方案（如改用 Sparse
Attention，只计算与当前 token 关联较大的之前 token
的信息），有希望让时空复杂度低于传统 Full Attention
的长度平方复杂度而达到近线性；</p>
<p>个人预测，在不远的未来，大模型上下文能力能有显著增强，以至于可以覆盖
90% 以上的<em>单次</em>复杂任务。</p>
<h3 id="推理成本">推理成本</h3>
<p>目前以 MoE 为首的稀疏模型架构正在快速取代传统 Attention
架构，显卡支持的量化精度也在不断降低，以这个趋势发展，大模型成本将进一步降低。</p>
<p>另一方面，端侧设备往往并不需要存储大量知识，而只需要存储语法和应答模式（均用于人机交互），因此所需的参数量会远低于目前的大模型，个人预测对于端侧
AI 助理或机器人 AI 大脑（语言指令部分），70B 模型即可胜任。目前，核显 PC
或手机可以以相对可以接受的速度运行 14B 左右的模型。14B 与 70B
之间的鸿沟将由硬件与 MLsys 领域的发展来跨越。</p>
<p>个人认为，边缘设备（PC、手机、机器人）将有机会具有运行特化模型的能力，具体可行性取决于是否能跨越
14B 到 70B 的鸿沟；</p>
<h3 id="多模态能力">多模态能力</h3>
<p>目前大模型多模态能力还非常差，将多个模态的数据统一到同一空间下的难度较高，特别是图片、视频、富文本文件。</p>
<p>另一方面，在工厂、户外等场景中，有更多其它形式的富文本格式信息输入，除非有能够泛化处理各个模态信息的技术突破，否则很难胜任各类场景。</p>
<p>个人认为，未来多模态能力将有发展，能够应对更多的多模态场景，但取得突破难度较大。</p>
<h3 id="ai-agent">AI Agent</h3>
<p>在前文提到的工具使用过程中，AI 充当系统大脑的角色，这个系统就是
Agent。在完成多场景、多阶段、多目标任务时，可能需要多个 Agent
相互协调、合作，结合多个外围工具，最终完成任务。</p>
<p>这是最难攻破的领域，上文所有能力均需要突破，才能达到强大 Agent
的基础要求。如果高完成度实现，可以认为摸到 AGI 的门槛（但距离真正的 AGI
还很远，暂时不必要考虑）。</p>
<p>个人认为，这一轮 AI 热潮能诞生强 AI Agent 的概率极低，诞生 AGI
的概率更是几乎为零。但这不代表当前 LLM 路线并不能通往
AGI，只是至少还需要一两个 Transformer
级别的技术突破，短期内还不可能。</p>
<p>顺带一提，取代程序员岗位并不需要这么强的
Agent，因此取代程序员的进程会相对更快，但也要求前文四个方向全面突破，不是一蹴而就的事情。</p>
<h3 id="其余能力">其余能力</h3>
<ul>
<li>Test-time training：短期内不会有太大发展；</li>
<li>可解释性：短期内没有希望；</li>
<li>动态知识更新：将来知识更新成本会降低，频率会上升；</li>
<li>混合专家系统与定制化：每个领域都将会有所进展，能够提高相关领域研究效率，但不会对有太大影响；</li>
<li>创新与设计能力：暂时不会有显著进展；</li>
<li>人类智慧：暂时不需要考虑 AI 能够拥有自我意识的可能性；</li>
<li>自我迭代：会有进展，但难以突破。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>西方古近代哲学史入门</title>
    <url>/2024/11/18/%E8%A5%BF%E6%96%B9%E5%8F%A4%E8%BF%91%E4%BB%A3%E5%93%B2%E5%AD%A6%E5%8F%B2%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h2 id="导论">导论</h2>
<ul>
<li>哲学不是科学；
<ul>
<li>黑格尔终结了西方两千年对于”使哲学成为一门科学“的努力；</li>
<li>二十世纪之后的哲学不再致力于成立一门科学，因此几乎都在批判黑格尔；</li>
<li>哲学是一切科学之母，在古希腊，能被明确地求解的体系会被剥离哲学，自成一门学科；</li>
</ul></li>
<li>philosophia = philos（爱）+ sophia（智慧）；</li>
<li>哲学是关注最终关怀问题的学科。哲学研究生死，而意识到自己的死（有限性）是人的基本特质之一。终死之人求永生，求永生者终归死；</li>
<li>哲学 = 哲学史 = 问题史；</li>
<li>语言非常重要，决定了思考方式；</li>
</ul>
<span id="more"></span>
<h2
id="早期希腊自然哲学公元前六世纪">早期希腊自然哲学（公元前六世纪）</h2>
<ul>
<li>希腊第一位哲学家：泰勒斯；</li>
<li>孕育哲学的条件：有闲暇的时间、有允许各学说存在和冲突的时代背景；</li>
<li>最初的从命运到必然性的转变，脱胎于神话，试图给世界以合理的说明：
<ul>
<li>相互补偿，得到报应 —— 阿那克西曼德；</li>
<li>天之道，损有余而补不足 —— 老子；</li>
</ul></li>
<li>希腊人认为自然的构成：水、火、土、气；</li>
<li>西哲的第一个概念：本原（arche）：开端与主宰；万物从其而来，归于其去；</li>
<li>泰勒斯宇宙生成论（<strong><em>水</em></strong>）：
<ul>
<li>大地浮在水上，宇宙充满灵魂；</li>
<li>水是比喻；</li>
</ul></li>
<li>赫拉克利特（<strong><em>火</em></strong>）：
<ul>
<li>万物自同的宇宙非神造，而是永恒的活火；</li>
<li>唯有变化不变；</li>
<li>人不能两次踏入同一条河流；</li>
<li>变化有规律；</li>
<li>Logos：说、计算、理性、推理；</li>
</ul></li>
<li>毕达哥拉斯学派：万物本原是<strong><em>数</em></strong>；</li>
<li>巴门尼德（埃利亚学派）：
<ul>
<li>本质不变（与赫拉克利特相反）；</li>
<li>只有<strong><em>存在</em></strong>能被诉说和思想，存在与思想具有同一性；</li>
<li>区分了意见之路和真理之路；</li>
<li>存在是西方哲学的核心概念；</li>
<li>希腊人认为语言能描述万物，且发现语言中只有”是“是不变的；”是“有了名词的特征（being），在中文语境中被与”存在“等同；</li>
<li>本体论（Ontologia，与形而上学同义，但本体论同认识论一样，近代才被创造）的奠定者：研究”存在“；</li>
<li>开启了推理论证；</li>
<li>芝诺的导师；</li>
</ul></li>
</ul>
<h2 id="鼎盛希腊哲学">鼎盛希腊哲学</h2>
<h3 id="苏格拉底前470年前399年">苏格拉底（前470年—前399年）</h3>
<ul>
<li>发扬本体论，没有留下任何著作，后由柏拉图形成于文字；</li>
<li>智者：收费收徒；智者的兴起是雅典民主制的产物，也标志着雅典民主制的衰败；</li>
<li>第一个自称智者的哲学家：普罗泰戈拉：</li>
<li>智者学派（诡辩）：
<ul>
<li>人是万物的尺度；</li>
<li>一切理论都有其对立的说法；</li>
<li>只有意见，没有知识；</li>
<li>比谁更雄辩；</li>
</ul></li>
<li>苏格拉底否定智者学派和水火土气的自然本原说；认为万物的主宰和原因不是物质性的本原，而是内在的目的，即<strong><em>善</em></strong>（agathon）；</li>
<li>座右铭：认识你自己；</li>
<li>自认无知，致力于通过探讨使人意识到自己的无知，从而求知，70
岁被处死；</li>
<li>人性本善；德性（arete）即知识，无知即罪恶；</li>
<li>开创伦理学；</li>
<li>什么是“美”：抽象能力；</li>
<li>知识不可教，是先天的，只是忘了；柏拉图称为“学习就是回忆”；</li>
</ul>
<h3 id="柏拉图前429年前347年">柏拉图（前429年—前347年）</h3>
<ul>
<li>享年 80 岁，28
岁时导师苏格拉底被处死，由此开始试图拯救希腊城邦文明；后回到雅典郊区阿卡德摩（后演化为词
Academy）开设柏拉图学园；</li>
<li>主张“现象可感而不可知，理念可知而不可感”；</li>
<li>后著《国家篇》（又译《理想国》），探讨国家的理想状态：
<ul>
<li>提出国家由理性（统治者）、激情（保卫者）、欲望（生产者）构成；三者各司其职，即得正义国家；</li>
<li>太阳之喻：世界分为现象（可见，对应”个别“）世界和实在（不可见，对应”一般“）世界，二者的主宰分别为太阳和善；</li>
<li>线段之喻：一条线段分为两部分，一部分相等于可感世界，一部分相等于理念世界；</li>
<li><strong>洞穴之喻</strong>：人类住在洞穴之中且只能面向穴壁，其后有火在烧，所有洞穴之外之物都通过火光映射到穴壁；哲学家的使命是带领人们走出洞穴；</li>
</ul></li>
<li><strong><em>理念（idea）论</em></strong>：
<ul>
<li>知识只存在于理念世界；</li>
<li>理念是事物存在的根据和摹仿的模型，事物通过<strong><em>分有</em></strong>和<strong><em>摹仿</em></strong>获取一部分理念（如<strong>美</strong>）；</li>
<li>人的灵魂原本居于理念世界，下降与肉体结合后将知识全部遗忘，学习就是通过诱导使人回忆起原本知道的东西；</li>
<li>普遍必然的知识不可能建立在相对偶然的经验基础之上，因此柏拉图早期认为知识是先天的，晚期认为认知能力是先天的；</li>
</ul></li>
<li><a
href="https://www.richardfarrar.com/plato-and-object-oriented-programming/">柏拉图与面向对象编程</a>，<a
href="https://wwj718.github.io/post/%E7%BC%96%E7%A8%8B/plato-and-object-oriented-programming/">中译</a>；</li>
<li>西哲史上第一个<strong><em>客观唯心主义</em></strong>；等级观念对后期基督教影像很大；</li>
<li>局限性：
<ul>
<li>后人对柏拉图的批评没有超过柏拉图的自我批评；</li>
<li>理念的普遍性：为什么会有恶；后期欧洲中世纪教父哲学圣奥古斯丁也提出过类似问题（神正论：世界之所以存在是因为上帝的存在，恶不是存在，而是善的缺失）；</li>
</ul></li>
<li>晚期通种论：
<ul>
<li>Genos —— 种；</li>
<li>打通理念和理念之间关系的学说；</li>
</ul></li>
</ul>
<h3
id="亚里士多德前384年6月19日前322年3月7日">亚里士多德（前384年6月19日—前322年3月7日）</h3>
<ul>
<li>”百科全书的思想家“；</li>
<li>强调事物和事物自身的概念是融为一体、不可分离的；</li>
<li>“吾爱吾师，吾更爱真理”；</li>
<li>雅典的敌邦人，37
岁柏拉图逝世后，做马其顿国王亚历山大的导师；后亚历山大吞并雅典波斯，一路打到喜马拉雅山脉，后一分为三。亚里士多德返回雅典，被雅典人追杀，对外著作全部烧毁，仅剩教学手稿存于地窖，二百年后被发现运至罗马图书馆；其中哲学卷被安德罗尼柯整理到自然物理学卷之后，取名“物理学之后诸卷”，英语
metaphysics，中译形而上学；</li>
<li>原因论：四因说：质料因（本原探讨）、形式因（理念探讨）、动力因（运动探讨）、目的因；后三者归结为“形式”。为适应自然运动，质料有潜能。质料最基础的是水火土气，最高级是隐德莱希（entelecheia），是整个世界的神，世界的第一推动者；</li>
<li>三段论；</li>
<li>形而上学：
<ul>
<li>与恩格斯所用于与辩证法对立的概念不一致，是单独的西哲门类；</li>
<li>存在不可定义，但存在有意义和方式；</li>
<li>范畴：对于事物最普遍、最一般的说明，“世界的逻辑结构”；</li>
<li>十范畴：实体、数量、性质、关系、地点、时间、状态、动作、所有、承受；</li>
<li>实体（ousia），原以为 essence，后在拉丁文被翻译成
substantia，后中译为“实体”；</li>
<li><em>事物被称之为 ousia 有两种方式：ousia
是终极的主体（主词），它不再述说其他事物；以及 ousia 是某个”这个“（tode
ti），它也是独立的</em>；</li>
<li>后来亚里士多德认为相比于质料，形式是事物的第一实体；</li>
<li>不可无穷后退；</li>
<li>一切实体皆可生灭的，而生灭基于时间和运动，因此时间和运动不可生灭；时间和运动永恒不变，因此需要找到永恒不变的实体，称为”不动的动者“，即亚里士多德的隐德莱希，柏拉图的善；</li>
</ul></li>
</ul>
<h2 id="晚期希腊哲学公元二世纪之前">晚期希腊哲学（公元二世纪之前）</h2>
<ul>
<li>伊壁鸠鲁主义：利用德谟克利特的原子论构建的快乐主义伦理学；</li>
<li>斯多亚学派（画廊学派）：强调灵魂和肉体的区别，按照理性即使按照自然生活，人生目的是摆脱肉体限制，净化灵魂，深刻影响后来的基督教；</li>
<li>怀疑主义：对一切不下判断，不探求自然，达到心的安宁；</li>
<li>新柏拉图主义（普罗提诺主义）：在柏拉图之上新增存在”一“（或”太一“），完满而流溢，如太阳发光；一向下流溢得到事物，人也可向上与一融为一体，物我两忘；重回神秘主义；</li>
</ul>
<h2 id="信仰的时代二世纪至十六世纪">信仰的时代（二世纪至十六世纪）</h2>
<ul>
<li>中世纪三个基本要素：罗马帝国、基督教、日耳曼人；</li>
<li>基督教为哲学提供了超验性、内在性、自由的问题、改造自然的观念；</li>
<li>教父哲学：
<ul>
<li>代表人物奥古斯丁；对”上帝创世之前在干什么“的回答：世界和时间的概念同时出现；</li>
<li>神圣罗马帝国开国皇帝，法兰克王国查理曼大帝意识到日耳曼人的野蛮，开始借助基督教会组织兴办学校，带来了小文艺复兴；</li>
<li>主流为新柏拉图主义；</li>
</ul></li>
<li>经院哲学（又称繁琐哲学，十一至十四世纪）：
<ul>
<li>查理曼帝国的宫廷学校以及基督教的大修道院和主教管区的附属学校发展起来的基督教；</li>
<li>正宗流传的日耳曼人哲学，是基督教对希腊思想的融合；</li>
<li>对上帝存在的本体论证明：完满的全知全能全善之物必然存在于现实，否则与此概念矛盾；</li>
<li><strong><em>唯实论</em></strong>（实在论）：
<ul>
<li>普遍的共相（一般）是真正的实在，殊相（个别）只是现象，类似柏拉图；</li>
</ul></li>
<li><strong><em>唯名论</em></strong>：
<ul>
<li>个别才是真正存在，共相只是概念，类似亚里士多德；</li>
<li>强调理性和信仰不可调和，维护王权，其兴盛代表了经院哲学的衰落；</li>
<li>亚里士多德思想被称为基督教的特洛伊木马，用于说明发现理性无法证明上帝的存在后会危害信仰；</li>
<li>代表人物：奥卡姆的威廉（思维经济原则）：如无必要，勿增<strong><em>实体</em></strong>；</li>
</ul></li>
</ul></li>
<li>文艺复兴与宗教改革（十四至十六世纪）：
<ul>
<li>文艺复兴：
<ul>
<li>1453
年拜占庭（东罗马帝国）首都君士坦丁堡被奥斯曼帝国消灭，希腊学者逃回欧洲，开启搜集整理古希腊文献的浪潮；</li>
<li>达芬奇、但丁、莎士比亚、《十日谈》、《堂吉诃德》、《巨人传》；</li>
<li>人文主义：以人为中心；并非将人与神对立，而是将人与自然对比，体现人的高贵性，强调人的情感；</li>
</ul></li>
<li>宗教改革：
<ul>
<li>马丁·路德大字报《关于赎罪券意义与效果之见解》（俗称《九十五条论纲》）；</li>
<li>对抗宗教的腐败（赎罪券等政策），形成路德宗（后称新教）；</li>
<li>新教教义主张不需要教会作为人与神的沟通渠道，因此屡次被天主教讨伐；</li>
<li>长期战争后，双方签订《奥格斯堡信纲》，变相承认新教的合法权利；</li>
<li>谁统治，信谁的教 —— 《奥格斯堡信纲》；</li>
<li>之后又有<em>三十年战争</em>，在德国本土（所谓神圣罗马帝国）打的全欧战争；</li>
<li><strong><em>原教旨主义</em></strong>：对基本经文或文献做出文字解释，并相信阐释出的教义应被用于社会、经济、政治生活的所有方面，回归教父哲学而无需各类排场和繁文缛节；</li>
<li>求己而不求人，向主体性的回归；</li>
</ul></li>
</ul></li>
</ul>
<h2 id="近代哲学十七至十九世纪">近代哲学（十七至十九世纪）</h2>
<ul>
<li>近代哲学的曙光：三个发现：世界（十五世纪大航海）、人（文艺复兴与宗教改革）、科学（近代自然科学）；</li>
<li>孕育：两希文明（希腊与希伯来）的冲突；</li>
<li>开端：经验论（培根）与唯理论（笛卡尔）围绕认识论的争论；</li>
<li>启蒙主义：十八世纪法国哲学的启蒙运动（伏尔泰、狄德罗、巴赫）；</li>
</ul>
<h2 id="笛卡尔法1596---1650">笛卡尔（法，1596 - 1650）</h2>
<ul>
<li>主体性原则：“我思故我在”
构成近代哲学开端，确立了理性主义的地位；</li>
<li>对课本失望，“去读世界这本大书”，当兵赶上<em>三十年战争</em>；后从巴黎移居荷兰，著《第一哲学沉思集》；</li>
<li>取代经院哲学，恢复理性地位，重建形而上学；</li>
<li>推崇几何学，力求仿照《几何原本》，通过几条定义和公理建立整个哲学体系；</li>
<li>观念的三个来源：天赋的（纯粹的理智）、外来的（感觉）、自己制造的（虚构想象）；</li>
<li>清除历来信以为真的一切，从根本上重新开始，寻找纯粹的、可以作为形而上学第一原理的天赋观念：我思故我在；</li>
<li>通过否定（怀疑）排除知识内容，最终剩下认识主体的过程，从而确立主体性；</li>
<li>形而上学三条原理：
<ul>
<li>我思故我在；</li>
<li>上帝存在（<em>我肯定不是上帝概念的原因，它一定另有原因。有一个无限完满的心灵，它把这种观念赋予我的心灵，所以我有上帝的观念</em>）；</li>
<li>物质世界存在（上帝不会骗我）；</li>
</ul></li>
<li>实体是能自己存在而不依赖别物的事物；</li>
<li>局限性：引出了<strong><em>二元论</em></strong>问题：心灵（精神）和身体（物质）是两个完全不同的实体，难以确定主体与客体、思维与存在的一致；</li>
</ul>
<h2 id="斯宾诺莎西班牙犹太人1632---1677">斯宾诺莎（西班牙犹太人，1632 -
1677）</h2>
<ul>
<li>斯宾诺莎哲学体系：本体论、认识论、伦理学；</li>
<li>力求消除笛卡尔的二元论问题，达成一元论；继承笛卡尔未完成的以欧几里得几何学为范本的公理化哲学体系；</li>
<li>实体：无限的、永恒的、不可分的、唯一的、不依赖与他物的事物；实体即神（非人格神）、即自然（包含心和物）；神就在世界之内，即神圣的自然必然性（与各教严重冲突，导致被迫害）；</li>
<li>自然神论：在宇宙之外的神（可以是人格神），牛顿信仰的第一动者，它提供了宇宙的第一个力和能量；</li>
<li>泛神论：没有人格神，神就是自然必然性；</li>
<li>将笛卡尔的两个实体，下降为一个实体的两个<strong><em>属性</em></strong>：思维和广延；实体一元论，心物两面论；</li>
<li><strong><em>样式</em></strong>：在他物内通过他物而被认知的东西，是实体的分殊、表现形式；</li>
</ul>
<h2 id="洛克英国1632---1704">洛克（英国，1632 - 1704）</h2>
<ul>
<li>唯理论代表：笛卡尔、斯宾诺莎、莱布尼茨；</li>
<li>经验论：从经验出发，重视实验科学；代表：洛克、贝克莱、休谟；</li>
<li>《人类理智论》，批判笛卡尔天赋观念，提出“白板说”，强调“经验—观念—知识”；</li>
<li>“消极的反映论“，心灵本是一块白板，外部影响形成观念（洛克哲学的基本范畴之一）；</li>
<li>心灵通过组合各个感官获取的简单观念，构成复杂观念；</li>
<li>第一性的质：物体的大小、形状等广延性质；</li>
<li>第二性的质：事物本身的运动对心灵造成的感觉；</li>
<li>知识是对于两个观念之间关系的认识；</li>
<li>感官所得到的简单观念是被动接受的，因此必然存在外部事物；简单观念与事物符合一致，复杂观念与心灵自身符合一致；</li>
</ul>
<h2 id="休谟英国1711---1776">休谟（英国，1711 - 1776）</h2>
<ul>
<li>彻底的经验主义者，导向”温和的怀疑论“；</li>
<li>两种知识：关于观念的、必然的知识（几何学），关于事实的、或然的知识（建立在感觉经验基础上的）；</li>
<li>休谟问题：归纳问题，一切归纳不能下全称判断；</li>
<li>在所有原则里，只有因果观念使人们超出经验去下判断；</li>
<li>对因果律的质疑：经验也不可能必然地推论因果；从纯粹理性的角度不可能做必然的结果推论；</li>
<li>因果观念来源于习惯性联想；</li>
<li><em>休谟是”英国经验论的逻辑终局“</em>—— 罗素；</li>
</ul>
<h2 id="近代哲学的社会政治思想">近代哲学的社会政治思想</h2>
<ul>
<li>霍布斯（英国）：国家是人们之间签订契约所诞生的，应拥有最高的、不可挑战的权利；</li>
<li>洛克（英国）：
<ul>
<li>反对霍布斯，强调国家是人民让渡维护自然法、惩罚罪犯的执行权后的结果；</li>
<li>人们签订契约，建立政府，且有权推翻没有很好行使此义务的政府；</li>
<li>反对专制，提出政权分散、相互制约的”分权“学说；</li>
</ul></li>
<li>孟德斯鸠（法）：
<ul>
<li>《论法的精神》，一切皆有法，人的法是根本理性；</li>
<li>一般的法与具体的国家、人的结合，称为法的精神；</li>
<li>对于共和、君主、专制三种政体，孟德斯鸠推崇君主政体，君主拥有最高权利，但必须依法行使；</li>
<li>发扬三权分立；</li>
</ul></li>
<li>卢梭（法）：
<ul>
<li>《社会契约论》（未完成）：自然状态下人生而平等，应力求自然人不以自由平等作为代价，仍能进入社会状态；</li>
<li>”社会越发展越不平等“；</li>
<li>提出”公意“，所有人必须服从；</li>
<li>人们让渡权利给”大家“，每个人既是统治者也是被统治者；</li>
</ul></li>
</ul>
<h2 id="康德德国1724---1804">康德（德国，1724 - 1804）</h2>
<ul>
<li>德国古典哲学创始人，现代哲学的开端；</li>
<li>《纯粹理性批判》、《实践理性批判》、《判断力批判》；</li>
<li>以康德的教授演讲《论感觉界与理智界的形式和原则》为界（1770年），分为前后批判时期；</li>
<li>康德哲学的问题：理性的危机、自由的失落、形而上学名存实亡；工具理性（科学）与价值理性（神学）的对立，上帝的退位而科学无法弥补此精神价值的空缺；</li>
<li>”哥白尼式的革命”：
<ul>
<li>融合统一了经验主义和理性主义；</li>
<li>认同经验论的基本原则：知识必然来源于感觉经验；</li>
<li>同时力求使其也具备普遍必然性，提出不是知识必须符合对象，而是对象必须符合认识主体的先天认识形式；</li>
</ul></li>
<li>不可知论：只能认识到事物所能被主体感受到的部分；认识形式的限制体现了认识能力的有限性，物自体不可知也表明认识领域之外还有一个不受认识形式限制、可能无限自由的领域，因此实践理性（伦理学）便有了用武之地；</li>
<li>限制知识以给理性留有余地，给形而上学（自由意志）留出路；</li>
<li>人是完全的自然存在（完全遵循自然法则），但是<strong><em>有限</em></strong>的理性存在，理性是<em>应该</em>但<em>不一定</em>遵循的标准，具体体现为<em>道德法则</em>；</li>
<li>与柏拉图“现象不可知而本质可知”的观念相反；用先验哲学取代本体论地位；</li>
<li>知识的基本单位是判断而非概念；
<ul>
<li>分析判断：判断宾词是蕴含在主词中、被抽出来的概念，不带来新信息；</li>
<li>综合判断：宾词是通过经验加在主词之上的，是扩展性的；</li>
<li>经验、先验、超验；</li>
<li>“知性为自然立法”；</li>
</ul></li>
<li>”头顶的星空和心中的道德律“：人的内心的道德法则是人与一个超感性的、理智的世界发生关系，人的价值和尊严由此体现；</li>
<li>费希特、谢林、黑格尔致力于继续解决康德的二元论问题，重建完整的形而上学体系；</li>
</ul>
<h2 id="黑格尔德国1770---1831">黑格尔（德国，1770 - 1831）</h2>
<ul>
<li>古典哲学和形而上学的终结；</li>
<li>《精神现象学》：
<ul>
<li>将认识看作发展的过程，统一了认识论和本体论；</li>
<li>“实体即主体”：”我”也处在这个世界之中，认识世界也即认识自己；</li>
<li>人的精神是最高形态的精神，是绝对精神的代言人，人对宇宙的认识就是宇宙的自我认识；</li>
</ul></li>
<li>将康德对知识静态分析的过程扩展为动态过程：新知识产生新对象、如此循环；</li>
<li><em>考察思维形式已经是一种认识历程了。所以，我们必须在认识的过程中将思维形式的活动对于思维形式的批判结合在一起。我们必须对于思维形式的本质及其整个的发展加以考察。思维形式既是研究的对象，同时又是对对象自身的活动。因此可以说，这乃是思维形式考察思维形式自身，故必须由其自身去规定其自身的限度，并揭示其自身的缺陷。这种思想活动便叫做思想的‘矛盾发展’（Dialektik，又译<strong>辩证法</strong>）。</em></li>
<li>辩证法：“辩证的否定”；<em>否定性是毁灭的力量，但唯独有一种东西能在毁灭中仍然保持生命，那就是精神</em>；</li>
<li>糟糕的翻译“存在即合理”：<em>凡是合乎理性的东西都是现实的，凡是现实的东西都是合乎理性的</em>；</li>
</ul>
<h2 id="维特根斯坦奥地利1889---1951">维特根斯坦（奥地利，1889 -
1951）</h2>
<ul>
<li>属于现代西哲；</li>
<li>粗略区分：古代哲学 —— 本体论；近代哲学 —— 认识论；英美现代哲学 ——
语言学；</li>
<li>维特根斯坦完成了向语言学的转向，后期提出人工语言不可实现且没有必要，一定程度使分析哲学从人工语言转向日常语言；</li>
<li>给语言划界，基于以布尔提出的逻辑代数为开端的数理逻辑；<em>凡是可以说的都可以说清楚，凡是不可以说的都必须保持沉默</em>；</li>
<li>师生：怀特海 - 罗素 - 维特根斯坦；</li>
<li>前期《逻辑哲学论》：
<ul>
<li>特别的唯我论：我的语言就是我的世界，语言的界限 = “自我”的界限 =
世界的界限；</li>
<li><em>当时我要写的是：我的著作由两部分组成：写在这里的再加上所有我没写的。正是这第二部分是重要的部分</em>；</li>
<li><em>人生的意义问题是无意义的。不过这种无意义的表达式不是无意义的。我用它们来超越世界，也就是说，超越有意义的语言；</em></li>
<li><em>只要伦理学是由于想要说一些关于人生的最终意义、关于绝对的善和绝对的有价值的东西而产生，它就不能是一门科学，它所说的无论如何都不增加我们的知识。但它是人类内心一种倾向的证明，我个人对这倾向不禁深怀敬意，终身不会嘲笑它</em>；</li>
<li><em>我的语句是通过下述方式而成为阐释的，凡是理解我的人，当他借助这些语句，把它们当做梯子，攀登上去超越它们时，最后会意识到它们是无意义的，可以说在爬上梯子之后，他必须把梯子丢掉，他必须超越这些语句然后才会正确地看世界</em>；</li>
<li>言者所以在意，得意而忘言。——《庄子 · 外物》</li>
<li><em>我以为，哲学问题在根本上已经最后地解决了。如果我的这个信念不错的话，则这本著作的价值就在于它指出了，解决了这些问题，所得是如此之少。</em></li>
</ul></li>
<li>后期《哲学研究》（未完成）：
<ul>
<li>思想转变，主张“日常语言没有错误，错在哲学家使用语言的方式”；</li>
<li>提出语言的意义不在于对象，而在于语言本身及其使用之中；</li>
<li>语言游戏：学习一个语词就意味着学习一种语言，想象一种语言就是想象一种生活方式；<em>游戏的中心就在于它拥有规则，没有规则语言符号就失去意义</em>；</li>
<li><em>语言是不需要用其它的目的来证明的</em>；</li>
<li>语言的教育不在于说明而在于训练；</li>
<li>语言的用法会随着环境而变化，传统形而上学在语言上犯了本质主义的错误（“哲学的精神病”）；</li>
<li>反本质主义：家族相似；</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>哲学</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.5840（原 6.824）课程笔记</title>
    <url>/2024/11/04/MIT-6-5840%EF%BC%88%E5%8E%9F-6-824%EF%BC%89%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p><a
href="https://pdos.csail.mit.edu/6.824/schedule.html">课程官网</a></p>
<p><a
href="https://www.bilibili.com/video/BV1R7411t71W/?vd_source=9282f15e6d326725afd47615733d4bd1">Morris
2020 授课录播</a></p>
<p><a
href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824">中文翻译</a></p>
<h2 id="paper-1-mapreduce">Paper 1: MapReduce</h2>
<p><a
href="https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf">原文</a>，<a
href="https://blog.csdn.net/weixin_52861033/article/details/135903901">笔记</a></p>
<p>提出背景：本世纪初，根据存储技术发展趋势，存储能力的增速已经快于全互联网内容的增速，谷歌预判出将来一家巨型公司的数据库将有能力存储下整个互联网。基于此，谷歌提出对于海量数据的分布式处理框架。</p>
<p>本文发表于 2004
年，提出了严格的网络设备间吞吐量限制，并据此将架构设计为在存储设备上直接做计算（Map
等操作）。事实上谷歌已抛弃这种老式 MapReduce 方法（<a
href="https://www.the-paper-trail.org/post/2014-06-25-the-elephant-was-a-trojan-horse-on-the-death-of-map-reduce-at-google/">MapReduce
之死</a>），且现在吞吐量已往往不再是瓶颈，存算分离架构已逐渐成为主流。</p>
<span id="more"></span>
<h3 id="问题抽象">问题抽象</h3>
<ul>
<li>map (k1, v1) → list(k2, v2)</li>
<li>reduce (k2, list(v2)) → list(v2)</li>
</ul>
<p>两个函数均为无副作用的函数式函数。</p>
<h3 id="流程要点">流程要点</h3>
<ul>
<li>将每个文件分成 64 MB 的块，每块保存 3
个副本在不同的机器上。尽量让存有数据的机器做对应的 Map 任务；</li>
<li>每个 map-worker 为每个 reduce-worker 生成一个文件，Map(key) 输出到
Hash(key) % R 的文件上；</li>
<li>由于 output file 可能是下一个 MapReduce 任务的 input
file，因此不做合并；</li>
<li>容错：Master 定期 ping Worker，故障的 Worker 负责的任务会分到其它
Worker 上；若 Master 故障则直接报告用户；</li>
<li>原子性：依靠底层文件系统提供的原子重命名操作来保证最终文件系统状态仅包含
reduce 任务执行的一次数据；</li>
<li>解决长尾效应（水桶效应）：在 MapReduce 临近结束时，Master 会备份
in-process task 同时运行，原任务和备份任务有一个完成即可；</li>
</ul>
<p><img src="MapReduce.png" /></p>
<h2 id="paper-2-gfs">Paper 2: GFS</h2>
<p><a
href="https://pdos.csail.mit.edu/6.824/papers/gfs.pdf">原文</a>，<a
href="https://pdos.csail.mit.edu/6.824/papers/gfs-faq.txt">FAQ</a></p>
<h3 id="主从复制">主从复制</h3>
<ul>
<li>用于解决并发操作造成的不一致问题，设置一主多从结构；</li>
<li>Coordinator 通过记录版本号（每次更换 Primary
时递增）确保重启后能读到最新数据；</li>
</ul>
<h3 id="client-读文件流程">Client 读文件流程</h3>
<ul>
<li><p>将 filename 和 offset 发送给 Coordinator，后者存有 filename
→chunkhandle 和 chunk handler → chunk server list 表；</p></li>
<li><p>Coordinator 根据偏移量返回 chunk handler 和对应 chunk server
list；</p></li>
<li><p>Client 缓存 chunk handler 和 chunk server list，并猜测最近的
chunk server 发送请求；</p></li>
<li><p>chunk server 根据 offset 读取数据返回给 Client；</p>
<p><img src="GFS_Read.png" /></p></li>
</ul>
<h3 id="client-写文件流程">Client 写文件流程</h3>
<ul>
<li>Client 向 Coordinator 指定文件块和 offset，Coordinator 返回 Primary
和 Secondary；</li>
<li>若对应 chunk 没有 Primary，Coordinator
负责与其中一个服务器签订租约；</li>
<li>Client
向所有服务器发送数据（生成临时数据，但不真正写入，可以以任何拓扑顺序）；</li>
<li>收到所有服务器回复后，Client 要求 Primary 写入；</li>
<li>Primary 检查租约是否过期，若没有则写入块文件；</li>
<li>Primary 通知所有 Secondary 写入（将临时数据复制到块文件中）；</li>
<li>Primary 等待所有 Secondary 回复，若超时则返回失败，Client
重新请求；</li>
</ul>
<figure>
<img src="GFS_Write.png" alt="GFS_Write.png" />
<figcaption aria-hidden="true">GFS_Write.png</figcaption>
</figure>
<h3 id="其它">其它</h3>
<ul>
<li>快照（Snapshot）：使用写时复制（Copy-on-Write）；</li>
<li>Checksum：使用 CRC32 做文件完整性校验；</li>
<li>每个 chunk 至少保有三个副本；</li>
</ul>
<h3 id="局限性">局限性</h3>
<ul>
<li>弱一致性（不同服务器存储内容很可能不同，不保证 get 能得到最近一次
put 后的结果）、单
Master（Coordinator）、没有明确对各种故障的相应处理、仅用于 Google
内部而不提供交互式；</li>
<li>GFS 论文发表于 2003 年，与 MapReduce 一样，GFS 已被取代（<a
href="https://highscalability.com/googles-colossus-makes-search-real-time-by-dumping-mapreduce/">新的
Colossus 框架</a>），但其设计思想仍保留在包括 HDFS
的大部分存储系统中；</li>
<li>若写入失败，则本次 [old-offset, new-offset)
的部分失效（空间浪费），下一次写入请求会接着 new 继续 Append 而非在
old-offset 上重试；这要求数据之间的顺序没有影响；</li>
</ul>
<h2 id="paper-3-raft">Paper 3: Raft</h2>
<p><a
href="https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf">原文</a>，<a
href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md">中文翻译</a></p>
<h3 id="persistent-or-volatile课堂内容">Persistent or Volatile（<a
href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-07-raft2/7.4-chi-jiu-hua-persistent">课堂内容</a>）</h3>
<ul>
<li>每个服务器都持久化的数据：currentTerm（防止投错周期），voteFor（防止投给两个候选者），log[]；</li>
<li>每个服务器的易失数据：commitIndex（已提交的最高日志索引，领导者会通知），lastApplied（已应用的最高日志索引，日志中有记录）；</li>
<li>领导者上的易失数据（选举后重新初始化）：nextIndex[]（记录每个节点下一个应该接收的日志索引），matchIndex[]（节点目前与
Leader 已匹配的最大日志索引）；</li>
</ul>
<h3 id="过半票决majority-vote的性质">过半票决（Majority
Vote）的性质</h3>
<ul>
<li>不可能同时票选出两个 Leader（Election Safety）；</li>
<li>不可能在同一个日志索引应用（写入状态机）不同的日志条目（State
Machine Safety）；</li>
<li>任意两个过半子集必有交，故 new leader 可以通过交集获取 old leader
的版本信息；</li>
<li>发生网络分区（Network Partition）时，较大分区可能票选出新
Leader，而位于较小分区的旧 Leader 由于凑不齐半数回应，无法再 commit
新请求；</li>
</ul>
<h3 id="写流程">写流程</h3>
<ul>
<li>Client 向 Leader 的应用层（数据库）发起请求；</li>
<li>Leader 不立即执行，而是通过下层 Raft 库通知所有 Follower
将新操作（AppendEntries）加入日志中并更新任期号；Follower
会忽略所有低于自身当前任期号的请求；</li>
<li>收到超过半数节点（包括自己）完成 AppendEntries
并回应后执行操作并回应 Client；</li>
<li>Leader 提交操作后再次通知 Follower，后者应用层执行相应操作；</li>
</ul>
<h3 id="选举流程">选举流程</h3>
<ul>
<li>每个 Raft 节点持有一个 Election Timer，若耗尽之前仍未收到 Leader
心跳包，则认为 Leader 以下线并开始一次选举；</li>
<li>服务器增加任期号（Term Number），并成为
Candidate，向所有节点广播投票请求；</li>
<li>对于 Follower 来说，如果 Candidate
的日志任期号较高，或相同但日志条目更长，才会投票支持，从而保证新 Leader
的日志至少与过半节点的日志一样新，进而保证新 Leader 的状态包含所有旧
Leader 提交过的状态；</li>
<li>新 Leader 直接在下一次 AppendEntries 时标明新的任期号，其它
Candidate 接收到不小于自己的任期号后会放弃选举；</li>
<li>Leader 不会删除或覆盖自己的日志而只会增加（Leader
Append-Only），它的日志就是共识；新 Leader 会不断让 Follower
的日志回退直到与自己匹配；</li>
<li>AppendEntries
中带有领导人任期号，但同一个日志操作不会被覆盖成新任期号，从而防止一个过半持有的日志不被提交（Raft
永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交，由于日志匹配特性，之前的日志条目也都会被间接的提交。见
5.4.2）；</li>
</ul>
<h3 id="正确性证明">正确性证明</h3>
<ul>
<li>特性 1：若一个日志的最大任期号大于另一个，以前者为准；
<ul>
<li>证明：Leader
日志是共识，后者会被先删除（若有必要）后新增，最终同步到与前者相同；</li>
</ul></li>
<li>特性 2（Log Matching，见
5.3）：若两个日志同一索引任期号相同，则日志从头到该位置均相同；
<ul>
<li>任期号相同说明两个日志都以被新 Leader 同步至相同状态（即当时新
Leader 的状态），然后均被执行相同 Append 操作；AppendEntries
会指定日志索引，也会检查上一个日志是否正确，归纳即可；</li>
</ul></li>
<li>特性 3（Leader Completeness，见
5.4）：若一个日志在某个任期号中被提交，则此条目必出现在更大任期号的领导人日志中；
<ul>
<li>被提交说明过半数节点已认可这次提交，新 Leader
必然也认可否则不能得到过半数赞同；反证（5.4.3）：由于必然存在既接受此提交的又投票给新
Leader 的节点，而新 Leader 又没有此次提交，说明新 Leader
并不比这个节点更新，因此不会被它投票，矛盾；</li>
<li>除此之外，领导人 U
的最后一条日志的任期号就必须比投票人大了。此外，他也比 T
大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T
的已提交的日志）。创建了领导人 U
最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人
U 是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，领导人 U
一定也包含那条被提交的日志，这里产生矛盾。（5.4.3）</li>
</ul></li>
</ul>
<h3 id="日志快照">日志快照</h3>
<ul>
<li>Raft 可以要求应用程序记录到某个 log entry
为止的状态机快照，下次重启是从此处恢复；这样可以删除该索引之前的 log
以节省磁盘空间；</li>
<li>但是有这样的问题：若一个 Follower 只有前两个 log，而 Leader
已经删除了前三个 log，此时 Follower 已无从得知第三个 log 的内容；</li>
<li>为此引入继 AppendEntries 和 RequestVote
之后的第三个消息类型：InstallSnapshot RPC；当出现上述情况时，先回退到
Leader 还保存的最早的 log（此情形中是第三个），然后 Leader 将快照发给
Follower，然后再继续常规的 AppendEntries 同步；</li>
<li>Follower 的日志中若存在与当前快照对应的 log
索引相同、任期号相同的记录，则其之前的可以全部删除，之后的可以依次应用并回复；若不存在，删除本地存储的所有
log；</li>
</ul>
<h3 id="局限性-1">局限性</h3>
<ul>
<li>极端情况：Leader
的所有出向网络均正常而入向网络损坏，将仍然发出心跳包组织票选新
Leader；</li>
<li>选举定时器：依靠 Election Timer 的随机性保证节点不会同时成为
Candidate 从而分割选票，但极端情况下每次节点都同时成为
Candidate；广播时间（broadcastTime） &lt;&lt;
选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF）；</li>
<li>新 Leader 与 Follower 同步 log
时，若发现差异，每次仅回退一条记录，效率较低；课程中给出的改进：Follower
在同步失败时返回三元组 &lt;XTerm（冲突记录对应的任期号）,
XIndex（任期号为 XTerm 的第一条 log 的索引, XLen（可能对应位置没有
log，此时 XLen 返回空白 log 槽位数&gt;；</li>
<li>Raft 的设计初衷是一个比 Paxos 更易懂的模型（understandable consensus
algorithm）；BTW，Paxos 的发明人 Leslie Lamport 同样是 Lamport
面包店算法、Bakery 互斥算法和 LaTeX 的发明人；</li>
<li>不支持拜占庭容错（有恶意节点发送错误数据）；</li>
<li>Morris 教授原话：<em>Raft论文图 13 的规则 6
有相应的说明。我认为正常的响应是，Follower可以忽略明显旧的快照。其实我看不懂那条规则6。</em></li>
</ul>
<h2 id="paper-4-zookeeper">Paper 4: Zookeeper</h2>
<p><a
href="http://nil.csail.mit.edu/6.5840/2023/papers/zookeeper.pdf">原文</a>，<a
href="https://github.com/mapleFU/zookeeper_paper_cn">中文</a>，<a
href="https://mp.weixin.qq.com/s/DwyPt5YZgqE0O0HYEC1ZMQ">笔记</a></p>
<h3 id="概述">概述</h3>
<ul>
<li>Zookeeper 伴随 NoSQL 崛起，成为 Hadoop 核心技术栈；etcd 则伴随
Kubernetes 崛起，成为云原生核心分布式协调服务；</li>
<li>线性一致性（Linearizability）：又称强一致性（Strong
Consistency），表示所有操作都可以看成瞬时发生，且按顺序生效；每次读操作能读取到最新的写操作结果；</li>
<li>根据以下两个条件画箭头，若构成环，则说明这一系列请求记录得到的结果不是线性一致的：
<ul>
<li>如果一个操作在另一个操作开始前就结束了，那么这个操作必须在执行历史中出现在另一个操作前面；</li>
<li>执行历史中，读操作，必须在相应的key的写操作之后；</li>
</ul></li>
<li>etcd 有线性一致性，而 Zookeeper 允许 Client 直接向 Follower
发起询问从而提升性能，代价是放弃线性一致性（可能存在一个客户端发起的写请求结束后，另一个客户端会读到旧值）；</li>
<li>Zookeeper 有以下两条保证，这使其仍然具备相当的可用性：
<ul>
<li>Zookeeper 保证写请求是线性一致的（写请求仍必然经过 Leader）；</li>
<li>且对于同一个客户端的请求会严格按照顺序执行（FIFO）：每次读取会返回一个
log entry（称为 zxid），下一次读会要求至少读到 log entry
之后的状态；也就是说同一个客户端在写入一个值后读取，读到的不可能再是旧值（单个客户端视角线性一致）；</li>
</ul></li>
<li>Zookeeper 提供 Sync
操作：本质是一个写请求，在客户端发送读请求时可以要求副本，在看到上一个
Sync 请求之前不要返回我的读请求，这就保证读取到了至少不旧于 Sync
的数据；</li>
<li>可以使用一个本质为读操作的 exists(file)
来获取是否存在文件并保证之后的读文件均不旧于此条请求，但无法避免 exists
操作之后文件被删除重建；因此 Zookeeper 支持 exists 的同时增加
watch，使得服务器在 watch 之后若执行修改操作会通知客户端（服务器维护
watch 表单，表明哪些客户端在 watch 哪些文件）；</li>
</ul>
<h3 id="api">API</h3>
<ul>
<li><code>create(path, data, flags)</code>：创建<code>path</code>的<code>znode</code>节点，保存<code>data</code>，返回新的<code>znode</code>的名字。<code>flag</code>用于指明<code>znode</code>类型，也可指明是否使用顺序标志；排他性：若文件已存在会返回失败；</li>
<li><code>delete(path, version)</code>：删除<code>path</code>的<code>znode</code>节点，并且版本号满足<code>version</code>
（不一致直接返回失败）；</li>
<li><code>exists(path, watch)</code>：返回<code>path</code>的<code>znode</code>是否存在。<code>watch</code>可允许客户端在该节点上应用
watch；</li>
<li><code>getData(path, watch)</code>：获取<code>path</code>的<code>znode</code>的值，<code>watch</code>和<code>exists()</code>一样，除非<code>znode</code>不存在；</li>
<li><code>setData(path, data, version)</code>：向<code>path</code>下的<code>znode</code>写入<code>data</code>，节点版本需要匹配<code>version</code>
；</li>
<li><code>getChildren(path, watch)</code>：返回<code>path</code>子节点的所有名字；</li>
<li><code>sync(path)</code>：操作开始时，等待所有的更新都发送到客户端所连接的服务器，<code>path</code>当前是被忽略的；</li>
</ul>
<h3 id="分布式锁服务">分布式锁服务</h3>
<ul>
<li>实现原子计数器（mini-transaction，最坏复杂度为 O(n^2)）：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">WHILE TRUE:</span><br><span class="line">    X, V = GETDATA(&quot;filename&quot;)</span><br><span class="line">    IF SETDATA(&quot;filename&quot;, X + 1, V):</span><br><span class="line">        BREAK</span><br></pre></td></tr></table></figure>
<ul>
<li>简单互斥锁：上锁就是创建
znode，解锁就是删除；节点多时会造成羊群效应：过多客户端监听同一个 znode
导致网络阻塞；</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">WHILE TRUE:</span><br><span class="line">    IF CREATE(&quot;f&quot;, data, ephemeral=TRUE): RETURN</span><br><span class="line">    IF EXIST(&quot;f&quot;, watch=TRUE):</span><br><span class="line">        WAIT</span><br></pre></td></tr></table></figure>
<ul>
<li>可扩展锁：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE(&quot;f&quot;, data, sequential=TRUE, ephemeral=TRUE)</span><br><span class="line">WHILE TRUE:</span><br><span class="line">    LIST(&quot;f*&quot;)</span><br><span class="line">    IF NO LOWER #FILE: RETURN</span><br><span class="line">    IF EXIST(NEXT LOWER #FILE, watch=TRUE):</span><br><span class="line">        WAIT</span><br></pre></td></tr></table></figure>
<ul>
<li>Morris 教授原话：
<ul>
<li><em>不得不说，我有点迷惑为什么Zookeeper论文要讨论锁。因为这里的锁并不像线程中的锁，在线程系统中，不存在线程随机的挂了然后下线。如果每个线程都正确使用了锁，你从线程锁中可以获得操作的原子性（Atomicity）。假如你获得了锁，并且执行了47个不同的读写操作，修改了一些变量，然后释放了锁。如果所有的线程都遵从这里的锁策略，没有人会看到一切奇怪的数据中间状态。这里的线程锁可以使得操作具备原子性。</em></li>
<li><em>而通过Zookeeper实现的锁就不太一样。如果持有锁的客户端挂了，它会释放锁，另一个客户端可以接着获得锁，所以它并不确保原子性。因为你在分布式系统中可能会有部分故障（Partial
Failure），但是你在一个多线程代码中不会有部分故障。如果当前锁的持有者需要在锁释放前更新一系列被锁保护的数据，但是更新了一半就崩溃了，之后锁会被释放。然后你可以获得锁，然而当你查看数据的时候，只能看到垃圾数据，因为这些数据是只更新了一半的随机数据。所以，Zookeeper实现的锁，并没有提供类似于线程锁的原子性保证。</em></li>
<li><em>所以，读完了论文之后，我不禁陷入了沉思，为什么我们要用Zookeeper实现锁，为什么锁会是Zookeeper论文中的主要例子之一。</em></li>
<li><em>我认为，在一个分布式系统中，你可以这样使用Zookeeper实现的锁。每一个获得锁的客户端，需要做好准备清理之前锁持有者因为故障残留的数据。所以，当你获得锁时，你查看数据，你需要确认之前的客户端是否故障了，如果是的话，你该怎么修复数据。如果总是以确定的顺序来执行操作，假设前一个客户端崩溃了，你或许可以探测出前一个客户端是在操作序列中哪一步崩溃的。但是这里有点取巧，你需要好好设计一下。而对于线程锁，你就不需要考虑这些问题。</em></li>
</ul></li>
</ul>
<h2 id="paper-5-craq">Paper 5: CRAQ</h2>
<p><a
href="http://nil.csail.mit.edu/6.5840/2023/papers/cr-osdi04.pdf">CR</a>，<a
href="https://pdos.csail.mit.edu/6.824/papers/craq.pdf">CRAQ</a>，<a
href="https://keys961.github.io/2020/05/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-CRAQ/">笔记</a></p>
<h3 id="链复制chain-replication">链复制（Chain Replication）</h3>
<ul>
<li>从 HEAD 写，TAIL 写完通知 HEAD 返回；从 TAIL
读；保证线性一致；发生故障时将故障节点移出链即可；但是链复制无法抵御网络分区和脑裂，因此它通常需要有一个容错的
Configuration Manager（CRAQ 使用
ZooKeeper），用于通告所有参与者链的信息；</li>
</ul>
<p><img src="CR.png" /></p>
<h3 id="链复制下的分摊查询-craq">链复制下的分摊查询 CRAQ</h3>
<ul>
<li>CRAQ 可以做到从任意副本执行读请求，同时保留线性一致性；</li>
<li>每个节点保存多版本的对象，每个版本的对象包含一个版本号（单调递增）和一个标记（标识该版本是<code>clean</code>还是<code>dirty</code>，初始为<code>clean</code>）</li>
<li>当节点收到新版本的对象，将最新版本追加到该对象的列表中
<ul>
<li>若节点不是尾节点，则标记最新版本是<code>dirty</code>，并传播给下一个节点</li>
<li>若节点是尾节点，则标记最新版本是<code>clean</code>（此时该版本的写已经提交），并沿链反向传播<code>ACK</code>（包含版本号）给其它节点</li>
</ul></li>
<li>当节点收到尾节点的<code>ACK</code>，将最新版本标记为<code>clean</code>，并可以删除旧版本的数据</li>
<li>当节点收到读请求
<ul>
<li>若最新版本是<code>clean</code>，直接返回数据</li>
<li>若最新版本是<code>dirty</code>，则
<ul>
<li>先向尾节点询问最新已提交的版本</li>
<li>根据尾节点返回的版本，返回对应版本的数据（可以保证该版本肯定没有被删除）</li>
</ul></li>
</ul></li>
</ul>
<p><img src="CRAQ.png" /></p>
<h3 id="一致性">一致性</h3>
<p>CRAQ 支持三种一致性模型：</p>
<ul>
<li><strong>强一致性</strong>：系统保证对一个对象的读写操作都以顺序执行，并且对于一个对象的读操作总是会观察到最新被写入的值；<em>4.1</em> 中描述的读操作可以使每次读取都读到最新写入的数据，因此提供了强一致性；</li>
<li><strong>最终一致性</strong>：在系统中，对一个对象的写入仍是按顺序在所有节点上应用的，但对不同节点的最终一致性读取可能会在一段时间内（在写操作应用于所有节点之前）返回过时的数据（单Client
视角仍线性一致）；允许节点返回未提交的新数据，即允许 <em>client</em> 可从不同的节点读到不一致的对象版本；</li>
<li><strong>带有最大不一致边界的最终一致性</strong>：允许节点返回未提交的新数据，但是有不一致性的限制，这个限制可以基于版本，也可以基于时间。如允许返回一段时间内新写入但未提交的数据；</li>
</ul>
<h2 id="lecture-12-distributed-transaction">Lecture 12 Distributed
Transaction</h2>
<p>此处为 <a
href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-12-distributed-transaction/12.1">Lecture
12</a> 分布式事务的笔记。</p>
<h3 id="数据库事务">数据库事务</h3>
<ul>
<li>四大要求（ACID）：原子性（All-or-Nothing）、一致性（正确性）、隔离性（与串行执行表现一致，即可序列化）、持久化；</li>
<li>并发事务控制的场景为不同服务器持有不同的数据，负责事务的不同子项，而不是
Raft 场景中的所有服务器存储数据相同；因此可用性低；</li>
</ul>
<h3 id="并发控制两阶段锁">并发控制：两阶段锁：</h3>
<ul>
<li>第一阶段：事务开始前获取所有需要的锁；</li>
<li>第二阶段：事务结束前保持所有锁，即使某个值已用完也不释放其锁，从而保证隔离性；</li>
<li>悲观锁：常规锁，必须先获取锁再做操作；</li>
<li>乐观锁：无论是否有锁均先操作，操作完若发现有干扰则回退；</li>
</ul>
<h3
id="原子提交两阶段提交2pctwo-phase-commit">原子提交：两阶段提交（2PC，Two-Phase
Commit）：</h3>
<ul>
<li>事务协调者 TC（Transaction
Coordinator）接到客户端请求后，向每个服务器发送 Prepare
指令，每个服务器成功将指令操作持久化（但不提交）后返回 yes/no；</li>
<li>TC 收到全 yes 后，向所有服务器发送 commit 指令；服务器提交后返回
ACK；</li>
<li>TC 收到全 ACK 后，向客户端返回成功；</li>
<li>此过程中，只要有一个服务器 commit 了，整个事务必须全部 commit
而不可再 Abort，所有在此阶段下线的节点必须在重新上线后将此事务
commit；</li>
<li>所有 commit 和 Abort 指令必须由 TC
决定并发出，其余节点无权自行商讨决定是否 commit 或
Abort；这可能造成等待，因此 2PC 的性能和可用性都不高</li>
</ul>
<h2 id="paper-6-bitcoin">Paper 6: Bitcoin</h2>
<p><a
href="http://nil.csail.mit.edu/6.5840/2023/papers/bitcoin.pdf">原文</a>，<a
href="https://bitcoin.org/files/bitcoin-paper/bitcoin_zh_cn.pdf">中文</a></p>
<p>比特币：一种基于密码学的、点对点、采用分布式共识算法、完全不依赖第三方可信任机构的电子货币系统；</p>
<h3 id="论文未提及">论文未提及</h3>
<ol type="1">
<li>私钥签名技术：
<ul>
<li>每个用户拥有一个公钥（公开）与一个私钥（保密），二者一一对应；</li>
<li>签名方可以使用自己的私钥产生自己的签名
Encrpyt(Hash(originalMessage), privateKey) = signature；</li>
<li>接收方可以得到 Hash(originalMessage)、signature 和 publicKey，比较
Decrypt(signature, publicKey) 与 Hash(originalMessage)
是否一致即可；</li>
</ul></li>
<li>局限性：
<ul>
<li>工作量证明对算力有巨量需求，导致后来的大量矿场灾难造成的资源浪费；目前已有更先进、不消耗大量资源的持有量证明（Proof
of State，或权益证明）算法；</li>
</ul></li>
</ol>
<h3 id="交易">交易</h3>
<ul>
<li><p>我们将一枚电子货币定义为一条数字签名链。每个拥有者都通过将上一次交易和下一个拥有
者的公钥的哈希值的数字签名添加到此货币末尾的方式将这枚货币转移给下一个拥有者。收
款人可以通过验证数字签名来证实其为该链的所有者；仅这一个技术无法避免拥有者将一枚货币交易给两个接受者，因此需要工作量证明；</p>
<p><img src="bitcoin_transaction.png" /></p></li>
<li><p>传统中心化电子支付系统防止双重支付的方式：每次交易先讲货币退回铸币厂，再有铸币厂直接向接收人发行一枚新货币。这种方式依赖中心机构铸币厂；</p></li>
<li><p>比特币系统公开全部交易，任何节点可以通过网络追溯出整个系统的交易历史，每次交易时，需要多数节点认同此交易是最先收到的证据；使用时间戳服务器，将每几个项目合在一起打上时间戳作为一个区块，每个时间戳哈希值都纳入了上一个时间戳，形成一条链；</p></li>
<li><p>工作量证明（Proof of
Work）：搜索一个数使其与区块数据一起被（SHA-256）哈希后得到的值以数个 0
比特为开头；由于区块形成一个后面包含前面的链，若想篡改一个区块，必须重做此后所有区块，其成功概率服从泊松分布呈指数消减；</p></li>
</ul>
<h3 id="网络">网络</h3>
<ul>
<li>新交易向所有节点广播，每个节点将其收集至区块并为它寻找工作量证明（因此比特币交易通常需要等待一定时间才能成功）；</li>
<li>当一个节点找到工作量证明，向所有节点广播这个区块；</li>
<li>若节点认可区块中所有交易且没有双重支付，接收此区块并在链中创建下一个区块；</li>
<li>节点总是认为最长的链是正确的；只要诚实节点够多，就几乎没有被攻击（伪造区块链）的可能，伪造者需要付出的算力将远高于所获收益；</li>
<li>为激励找到工作量证明的节点，下一个区块的第一笔交易为对此节点的奖励；由于方程的解是有限且随机的，可以作为货币资源被发放；或是由交易费充当；奖励将随时间递减以抑制通货膨胀；</li>
<li>将旧交易哈希进默克尔树以节省磁盘；</li>
</ul>
<p><img src="bitcoin_network.png" /></p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>CS 美硕学校信息汇总</title>
    <url>/2024/10/11/CS-%E7%BE%8E%E7%A1%95%E5%AD%A6%E6%A0%A1%E4%BF%A1%E6%81%AF%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<p>括号中排名对应：U.S. News世界排名，QS世界排名，THE世界排名，U.S.
News美国排名，CSRankings全选（均为2023年）</p>
<span id="more"></span>
<h2 id="uiuc-74-85-48-41-2">UIUC (74, 85, 48, 41, 2)</h2>
<p>一个学院限一个项目，有Coop，MSIM关联度小转码，<strong>不接受
WES</strong></p>
<p>TOEFL 79-102 有限状态准入，需要 EPT</p>
<p><a
href="https://grad.illinois.edu/admissions/apply">https://grad.illinois.edu/admissions/apply</a></p>
<h3 id="mcs-a-">*MCS (A-)</h3>
<p><a
href="https://cs.illinois.edu/academics/graduate/professional-mcs/campus-master-computer-science">https://cs.illinois.edu/academics/graduate/professional-mcs/campus-master-computer-science</a></p>
<p>2-3 continuous
semesters（官网可申请延期），non-thesis，课程设置与MSCS一致</p>
<p>DDL：早 1.15，晚 3.30</p>
<p>PS 1000词，可 Update，可以 defer 至多一年</p>
<p>GRE: Not required（若要提交可只提交 PDF 而不用 ETS 送分），TOEFL:
1836, 78（可不填）</p>
<h3 id="ece-meng-b">*ECE MEng (B+)</h3>
<p>Rolling，DDL：6.1，1.5-2 years，能选成CS课</p>
<p>GRE：Optional</p>
<p><a
href="https://ece.illinois.edu/admissions/graduate/meng-degree">https://ece.illinois.edu/admissions/graduate/meng-degree</a></p>
<p><img src="timeline.jpeg" /></p>
<h2 id="cornell-21-20-20-17-8">Cornell (21, 20, 20, 17, 8)</h2>
<p>ECE与ECE CT为转码项目</p>
<p>一个校区限一个项目，ECE很硬（限修一门CS）</p>
<p><a
href="https://gradprofessional.cornell.edu/apply/">https://gradprofessional.cornell.edu/apply/</a></p>
<h3 id="cs-meng-ss">CS MEng (SS)</h3>
<p><a
href="https://www.cs.cornell.edu/masters/apply">https://www.cs.cornell.edu/masters/apply</a></p>
<p>1 year，名校</p>
<p>GRE: Not Accepted</p>
<h3 id="mps-is-b">MPS-IS (B+)</h3>
<p><a
href="https://infosci.cornell.edu/masters/mps/admissions/how-apply">https://infosci.cornell.edu/masters/mps/admissions/how-apply</a></p>
<p>2+1 semesters，口语卡25</p>
<h3 id="cs-meng-ct-a">CS MEng CT (A+)</h3>
<p><a
href="https://tech.cornell.edu/programs/masters-programs/master-in-computer-science/">https://tech.cornell.edu/programs/masters-programs/master-in-computer-science/</a></p>
<p>DDL 1.5 后 Rolling，9 months，WES，创业，名校，不可延期</p>
<h3 id="cm-cta">*CM CT(A)</h3>
<p><a
href="https://tech.cornell.edu/programs/masters-programs/jacobs-technion-cornell-dual-ms-connective-media/">https://tech.cornell.edu/programs/masters-programs/jacobs-technion-cornell-dual-ms-connective-media/</a></p>
<p>2 years，MSIS degree，thesis，面试，创业，实习，名校，转码友好</p>
<p>要求WES，PS 2100词有格式要求，不可 update，不可春季入学</p>
<p>DDL：一轮 1.5，二轮 2.1，滚动 4.1</p>
<p>GRE: Not Accepted，TOEFL: 2098, 0000（undecided）</p>
<h2 id="uc-berkeley-4-27-8-20-9">UC Berkeley (4, 27, 8, 20, 9)</h2>
<p><a
href="https://gradapp.berkeley.edu/apply/">https://gradapp.berkeley.edu/apply/</a></p>
<h3 id="eecs-meng-a">*EECS MEng (A+)</h3>
<p><a
href="https://eecs.berkeley.edu/academics/graduate/industry-programs/meng">https://eecs.berkeley.edu/academics/graduate/industry-programs/meng</a></p>
<p><a
href="https://funginstitute.berkeley.edu/programs-centers/full-time-program/engineering-departments/eecs/">https://funginstitute.berkeley.edu/programs-centers/full-time-program/engineering-departments/eecs/</a></p>
<p>9 months，名校，接受WES</p>
<p>DDL：1.8，GRE：Not required（4833）TOEFL：4833；</p>
<h2 id="cmu-118-52-28-22-1">CMU (118, 52, 28, 22, 1)</h2>
<p>不同项目不同通道，可多选</p>
<p><a
href="https://www.cmu.edu/academics/index.html">https://www.cmu.edu/academics/index.html</a></p>
<p>项目汇总：<a
href="https://zhuanlan.zhihu.com/p/538394187">https://zhuanlan.zhihu.com/p/538394187</a></p>
<p><strong>SCS</strong></p>
<p>*MITS(A)</p>
<p>CSD: MSCS(SS)</p>
<p>HCI: MHCI</p>
<p>ISR: MSE(B+)</p>
<p>LTI: MCDS(S), MSAII(S), MIIS(S), MLT(SS)</p>
<p>MLD: MSML(SS)</p>
<p>RI: MSCV(S)</p>
<p><strong>CE</strong></p>
<p>ECE: <em>MS(A), </em>SE-SV(A);</p>
<p>INI: <em>MSIN(A+), </em>MSMITE(A-，原MSIT-Mob), MSIS(安全),
MSIT-IS(第一年在日本，安全), MSIT-SM;</p>
<p><strong>Heinz</strong></p>
<p>SISM:MISM(B+), MSISPM(安全，管理)</p>
<h3 id="scs">SCS</h3>
<p>GRE：Required（2074-0402），TOEFL：4256-78</p>
<p><a
href="https://www.cs.cmu.edu/academics/graduate-admissions">https://www.cs.cmu.edu/academics/graduate-admissions</a></p>
<p><strong>MIIS (S)</strong></p>
<p><strong>MSE (B+)</strong></p>
<p><a
href="https://applygrad.cs.cmu.edu/apply/index.php?domain=17">https://applygrad.cs.cmu.edu/apply/index.php</a></p>
<p>4 semesters，无实习，无选课自由，不编程</p>
<p>PRO 三年工作经验，SS 有工作经验，ES 无信息</p>
<h3 id="mits-a">*MITS (A)</h3>
<p>非常贵，可选 3 或 4 quarters</p>
<p>要求 WES，推荐信需要有实习老板</p>
<p>GRE：Not Accepted，TOEFL：C583</p>
<p>DDL：1.15</p>
<p><a
href="https://www.cmu.edu/cmist/academics/graduate-programs/mits/index.html">https://www.cmu.edu/cmist/academics/graduate-programs/mits/index.html</a></p>
<h3 id="ece">ECE</h3>
<p>3-4 semesters</p>
<p>DDL：12.15，可以 Update 简历和考试成绩</p>
<p>GRE：Optional（2074），TOEFL：2074</p>
<p>*<strong>MS (A)</strong></p>
<p><a
href="https://www.ece.cmu.edu/academics/ms-ece/index.html">https://www.ece.cmu.edu/academics/ms-ece/index.html</a></p>
<p>*<strong>SE-EV (A)</strong></p>
<p><a
href="https://www.ece.cmu.edu/academics/ms-se/index.html">https://www.ece.cmu.edu/academics/ms-se/index.html</a></p>
<h3 id="ini">INI</h3>
<p>GRE: Not Accepted(2024 Spring)</p>
<p>DDL：早 12.1，晚 1.15</p>
<p>GRE：Not Accepted，TOEFL：2074</p>
<p>*<strong>MSIN</strong></p>
<p><a
href="https://www.cmu.edu/ini/academics/msin/index.html">https://www.cmu.edu/ini/academics/msin/index.html</a></p>
<p>*<strong>MSMITE</strong></p>
<p>2学期匹兹堡，1~2学期硅谷</p>
<p><a
href="https://www.cmu.edu/ini/academics/bicoastal/index.html">https://www.cmu.edu/ini/academics/bicoastal/index.html</a></p>
<h3 id="heinz">Heinz</h3>
<p><strong>MISM (B+)</strong></p>
<p><a
href="https://www.heinz.cmu.edu/programs/information-systems-management-master/concentrations">https://www.heinz.cmu.edu/programs/information-systems-management-master/concentrations</a></p>
<p>偏金融管理，有一定的选课自由</p>
<p>General track-16 months 60%有工作经验，有实习</p>
<p>General track-12 months 三年工作经验</p>
<p>Global 21 months，第一年在澳大利亚，不能实习</p>
<p>BIDA 16 months，更偏商业，没录降级成general 16 months</p>
<p>BIDA 12 months，三年工作经验</p>
<h2 id="gatech-51-88-38-44-10">GaTech (51, 88, 38, 44, 10)</h2>
<p>限两个项目，MSA转码项目且比例不高，Cybersecurity学硕选课限制大</p>
<p><a
href="https://gradapp.gatech.edu/apply/">https://gradapp.gatech.edu/apply/</a></p>
<h3 id="mscs-a">*MSCS (A+)</h3>
<p>1.5 years，Coop</p>
<p><a
href="https://catalog.gatech.edu/programs/computer-science-ms/">https://catalog.gatech.edu/programs/computer-science-ms/</a></p>
<p>GRE: Required(R5248)</p>
<p>DDL：2.1</p>
<h3 id="cse-a">*CSE (A)</h3>
<p><a
href="https://catalog.gatech.edu/programs/computational-science-engineering-ms/">https://catalog.gatech.edu/programs/computational-science-engineering-ms/</a></p>
<p><a
href="https://www.cse.gatech.edu/sites/cse.gatech.edu/files/handbook-2022-12-06.pdf">https://www.cse.gatech.edu/sites/cse.gatech.edu/files/handbook-2022-12-06.pdf</a></p>
<p>1.5-2 years，难度CoC&gt;ISyE&gt;CEE等，只能选一个home
unit，偏数学</p>
<p>GRE: Required(R5248)</p>
<h3 id="ece-a-">ECE (A-)</h3>
<p><a
href="https://www.ece.gatech.edu/masters-degrees">https://www.ece.gatech.edu/masters-degrees</a></p>
<p>1.5-2 years，选课无限制但要抢，共10门，要修6门ECE，可选有无thesis</p>
<p>可转ECE博，有机会转CSE（难），有一学期Coop</p>
<h2 id="columbia-7-22-11-18-14">Columbia (7, 22, 11, 18, 14)</h2>
<p>限选一个</p>
<h3 id="mscs-a-">*MSCS (A-)</h3>
<p><a
href="https://apply.engineering.columbia.edu/apply/">https://apply.engineering.columbia.edu/apply/</a></p>
<p><a
href="https://www.cs.columbia.edu/education/ms/">https://www.cs.columbia.edu/education/ms/</a></p>
<p><a
href="https://www.gradengineering.columbia.edu/graduate-admissions/application-requirements">https://www.gradengineering.columbia.edu/graduate-admissions/application-requirements</a></p>
<p>3 semesters (4+4+2)，4千刀占位费</p>
<p>有劝退（class size大，career support小），10 个 track</p>
<p>DDL：早 1.15，晚 2.15，不可 defer，付款后有视频面试</p>
<p>GRE：Optional（2111），TOEFL：2111；</p>
<h3 id="msds-a-">MSDS (A-)</h3>
<p><a
href="https://datascience.columbia.edu/education/programs/m-s-in-data-science/">https://datascience.columbia.edu/education/programs/m-s-in-data-science/</a></p>
<p>1.5 years</p>
<h2 id="yale-11-18-9-3-33">Yale (11, 18, 9, 3, 33)</h2>
<p>限选一个</p>
<p><a
href="https://apply.grad.yale.edu/apply/">https://apply.grad.yale.edu/apply/</a></p>
<h3 id="mscs-a-1">*MSCS (A+)</h3>
<p><a
href="https://cpsc.yale.edu/academics/graduate-program/master-science">https://cpsc.yale.edu/academics/graduate-program/master-science</a></p>
<p>可选1 or 2 years（2年极少，1 year即9 months）</p>
<p>GRE: Required (3987), TOEFL: 3987</p>
<p>DDL：1.2，可以 Update</p>
<h2 id="upenn-15-93-14-7-17">UPenn (15, 93, 14, 7, 17)</h2>
<p><a
href="https://www.applyweb.com/upenng/index.ftl">https://www.applyweb.com/upenng/index.ftl</a></p>
<p>MCIS (SS) 陆本黑洞，DS (S) 比同档差，MCIT零基础转码，CGGT
(A-)游戏图形学</p>
<p>建议 WES</p>
<p>Early DDL：11.1，Regular DDL：2.1</p>
<p>GRE: Optional (2888)</p>
<h3 id="se">SE</h3>
<p><a
href="https://catalog.upenn.edu/graduate/programs/systems-engineering-mse/">https://catalog.upenn.edu/graduate/programs/systems-engineering-mse/</a></p>
<p>1.5 years，选课友好，压力稍小（有可能转专业或dual）</p>
<h3 id="ds">DS</h3>
<p><a
href="https://dats.seas.upenn.edu/program/">https://dats.seas.upenn.edu/program/</a></p>
<p>1.5-2 years，</p>
<h2 id="ucla-14-44-21-20-19">UCLA (14, 44, 21, 20, 19)</h2>
<p>限选一个</p>
<p><a
href="https://apply.grad.ucla.edu/portal/landing">https://apply.grad.ucla.edu/portal/landing</a></p>
<h3 id="mscs-ss">MSCS (SS)</h3>
<p><a
href="https://www.cs.ucla.edu/graduate-admissions/">https://www.cs.ucla.edu/graduate-admissions/</a></p>
<p>2 years</p>
<h3 id="meng-b">*MEng (B+)</h3>
<p><a
href="https://www.meng.ucla.edu/admissions/">https://www.meng.ucla.edu/admissions/</a></p>
<p>下有7个areas，分别是Artificial Intelligence、Autonomous Systems、Data
Science、Digital Health Technology、Green Energy Systems、IoT
Systems、Translational Medicine。</p>
<p>1 year，新设项目，无CS title，可转码，可延期1
quarter暑期实习（2022据说难）</p>
<p>DDL：12.1</p>
<p>GRE: Not required，TOEFL: 4837，不接受 WES</p>
<p>Expected TOEFL: W25+S24+R21+L17</p>
<h2 id="ucsd-20-53-32-20-4">UCSD (20, 53, 32, 20, 4)</h2>
<p>同一部门限选一个，录取后需要做 WES</p>
<p>CS76 CE方向，偏硬，自由度稍低；EC82 (B+) 信号处理，适合不转码；</p>
<p>MSDS 数据统计，CSME数学，DSE面向从业者</p>
<p>仅 fall，DDL（12.20）后 Rolling，不可 update</p>
<p><a
href="https://connect.grad.ucsd.edu/apply/">https://connect.grad.ucsd.edu/apply/</a></p>
<p><a
href="https://cse.ucsd.edu/graduate/degree-programs/ms-program">https://cse.ucsd.edu/graduate/degree-programs/ms-program</a></p>
<p><a
href="https://www.ece.ucsd.edu/graduate/graduate-admissions">https://www.ece.ucsd.edu/graduate/graduate-admissions</a></p>
<p><a
href="https://www.xiaohongshu.com/explore/62e358ca000000001202e9ed">https://www.xiaohongshu.com/explore/62e358ca000000001202e9ed</a></p>
<h3 id="cs75-a">*CS75 (A)</h3>
<p>1+ years，random，CS方向</p>
<p>GRE: Optional(4836)，TOEFL：4836</p>
<h3 id="ec79-a-">*EC79 (A-)</h3>
<p>能选CS课最多的CE，不可转CS</p>
<p>GRE:
Required（4836-1203，部门码不必须），TOEFL：4836-66，部门码不必须</p>
<h3 id="ec93-mlds-b">EC93 (MLDS) (B+)</h3>
<p><a
href="https://www.ece.ucsd.edu/faculty-research/ece-research-areas/machine-learning-data-science-impacted">https://www.ece.ucsd.edu/faculty-research/ece-research-areas/machine-learning-data-science-impacted</a></p>
<p><a
href="https://www.ece.ucsd.edu/sites/www.ece.ucsd.edu/files/research-areas/DP-%20MLDS%20%28EC93%29%202022-2023%20FILLABLE.pdf">https://www.ece.ucsd.edu/sites/www.ece.ucsd.edu/files/research-areas/DP-
MLDS (EC93) 2022-2023 FILLABLE.pdf</a></p>
<p>ML相关，需要对口的科研经历</p>
<p>GRE:
Required（4836-1203，部门码不必须），TOEFL：4836-66，部门码不必须</p>
<h2 id="jhu-10-24-15-7-53">JHU (10, 24, 15, 7, 53)</h2>
<p>MSSI信息安全</p>
<p><a
href="https://applygrad.jhu.edu/apply/">https://applygrad.jhu.edu/apply/</a></p>
<h3 id="msecs-b">*MSECS (B)</h3>
<p><a
href="https://www.cs.jhu.edu/academic-programs/graduate-studies/mse-programs/">https://www.cs.jhu.edu/academic-programs/graduate-studies/mse-programs/</a></p>
<p><a
href="https://engineering.jhu.edu/admissions/graduate-admissions/full-time-programs/how-to-apply/international-students/">https://engineering.jhu.edu/admissions/graduate-admissions/full-time-programs/how-to-apply/international-students/</a></p>
<p>3-4 semesters，科研校</p>
<p>DDL 2.15，春夏秋均有，建议 WES（可以不送）</p>
<p>SOP 500K，1 inch</p>
<p>GRE: 学院要求但系不看（4655-0402）, TOEFL: C559-78</p>
<h2 id="duke-25-50-25-10-28">Duke (25, 50, 25, 10, 28)</h2>
<p>MIDS跨学科</p>
<p>不可 update</p>
<p><a
href="https://applygp.duke.edu/apply/">https://applygp.duke.edu/apply/</a></p>
<h3 id="mscs-a-2">*MSCS (A+)</h3>
<p><a
href="https://www.cs.duke.edu/graduate/ms">https://www.cs.duke.edu/graduate/ms</a></p>
<p>官网定性为研究项目</p>
<p>1.5-2 years</p>
<p>GRE: Required(5156-5199)，TOEFL: 5156，可以同时提交 WES</p>
<p>DDL：1.31</p>
<h3 id="ece-a--1">*ECE (A-)</h3>
<p><a
href="https://ece.duke.edu/masters/degrees/ms">https://ece.duke.edu/masters/degrees/ms</a></p>
<p><a
href="https://ece.duke.edu/masters/degrees/meng">https://ece.duke.edu/masters/degrees/meng</a></p>
<p>1.5-2 years，MS与MEng可互转，可全软课</p>
<p>DDL：MEng 1.15（3.15 出结果），3.15（4.15 出结果）；MS 1.16（2.28
出结果）</p>
<p>GRE: Optional，TOEFL: 5156</p>
<p>MEng 600刀 占位费</p>
<h2 id="uchi-22-10-13-6-25">UChi (22, 10, 13, 6, 25)</h2>
<p>MScA数据分析</p>
<h3 id="mpcs-a-">MPCS (A-)</h3>
<p><a
href="https://masters.cs.uchicago.edu/page/admissions">https://masters.cs.uchicago.edu/page/admissions</a></p>
<p><a
href="http://course-info.cs.uchicago.edu/">http://course-info.cs.uchicago.edu/</a></p>
<p><a
href="https://www.1point3acres.com/bbs/thread-843060-1-1.html">https://www.1point3acres.com/bbs/thread-843060-1-1.html</a></p>
<p>4
quarters，转码项目，Bar高，人少，夜校，不安全，课很基础，纯就业导向，找工好。</p>
<p>9-Course学制没有实习、不提供CPT，12-Course有实习、提供CPT</p>
<h2 id="nwu-24-32-26-10-31">NWU (24, 32, 26, 10, 31)</h2>
<p><a
href="https://www.applyweb.com/nugrad/index.ftl">https://www.applyweb.com/nugrad/index.ftl</a></p>
<p>限选一个</p>
<h3 id="mscs-a--1">*MSCS (A-)</h3>
<p><a
href="https://www.mccormick.northwestern.edu/computer-science/academics/graduate/masters/">https://www.mccormick.northwestern.edu/computer-science/academics/graduate/masters/</a></p>
<p>4 quarters/1.5 years，MSCS研究向，看SoP，就业一般，学费贵</p>
<p>三个track，thesis，project，course，前两者可以最多延2 quarters</p>
<p>DDL：早 11.30（1.10 出结果），中 12.31（2.10 出结果），晚 2.28（4.30
出结果）</p>
<p>GRE：Not required，TOEFL：1565</p>
<h2 id="umich-19-25-23-25-57">UMich (19, 25, 23, 25, 57)</h2>
<p>ECE仅AI相关</p>
<h3 id="mscses">MSCSE（S）</h3>
<p><a
href="https://cse.engin.umich.edu/academics/graduate/admissions/apply/">https://cse.engin.umich.edu/academics/graduate/admissions/apply/</a></p>
<p>偏学术，DP极少</p>
<p>GRE: Not Accepted，Toefl：1839；只有fall。</p>
<p>DDL：1.15</p>
<h3 id="ds-a-">DS (A-)</h3>
<p><a
href="https://lsa.umich.edu/stats/masters_students/mastersprograms/data-science-masters-program.html">https://lsa.umich.edu/stats/masters_students/mastersprograms/data-science-masters-program.html</a></p>
<p><a
href="https://www.1point3acres.com/bbs/thread-576109-1-1.html">https://www.1point3acres.com/bbs/thread-576109-1-1.html</a></p>
<p>1-2 years，就业不太好，选不了CS课</p>
<h2 id="nyu-31-39-24-25-19">NYU (31, 39, 24, 25, 19)</h2>
<h3 id="courant-mscs-b">*Courant MSCS (B+)</h3>
<p><a
href="https://cs.nyu.edu/home/master/prospective_admission.html">https://cs.nyu.edu/home/master/prospective_admission.html</a></p>
<p><a
href="https://apply.gsas.nyu.edu/apply/">https://apply.gsas.nyu.edu/apply/</a></p>
<p>4 semesters</p>
<p>GRE: Suggested（2596），TOEFL：2596</p>
<p>DDL：3.1，不支持 Update</p>
<h3 id="tandon-mscs-b">*Tandon MSCS (B+)</h3>
<p><a
href="https://engineering.nyu.edu/academics/programs/computer-science-ms">https://engineering.nyu.edu/academics/programs/computer-science-ms</a></p>
<p><a
href="https://apply.engineering.nyu.edu/apply/">https://apply.engineering.nyu.edu/apply/</a></p>
<p>4 semesters</p>
<p>有自己评估系统，不接受 WES，不可 defer</p>
<p>DDL：早 12.1，晚 2.15</p>
<p>GRE: Suggested (2668)，TOEFL: 2668</p>
<h3 id="tandon-ce-b-">Tandon CE (B-)</h3>
<p><a
href="https://www.zhihu.com/question/453935331">https://www.zhihu.com/question/453935331</a></p>
<p>转码，较硬</p>
<h2 id="ut-austin-43-72-50-38-14">UT-Austin (43, 72, 50, 38, 14)</h2>
<p><a
href="https://cockrell.utexas.edu/admissions/graduate">https://cockrell.utexas.edu/admissions/graduate</a></p>
<h3 id="mscs-ss-1">MSCS (SS)</h3>
<p><a
href="https://www.cs.utexas.edu/graduate/prospective-students/apply">https://www.cs.utexas.edu/graduate/prospective-students/apply</a></p>
<p>偏科研，可转博</p>
<h3 id="ece-a">*ECE (A+)</h3>
<p><a
href="https://www.ece.utexas.edu/academics/graduate">https://www.ece.utexas.edu/academics/graduate</a></p>
<p>2 years，SES track可当CS，有Coop和TA/RA机会，可转博</p>
<p>DDL：12.1，不可 Update</p>
<p>GRE：Not Considered（6882），TOEFL：6882；</p>
<p>SOP 不是最终版不要提交</p>
<h2 id="uw-madison-63-83-81-38-16">UW-Madison (63, 83, 81, 38, 16)</h2>
<p>可以一份申请费申三个项目，用同一个 CV 但不同的 PS</p>
<p>关于第二专业：<a
href="https://www.cs.wisc.edu/add-a-second-cs-ms-major/">https://www.cs.wisc.edu/add-a-second-cs-ms-major/</a></p>
<h3 id="cs-pmpmscsmsde">*CS-PMP/MSCS/MSDE</h3>
<p><a
href="https://guide.wisc.edu/graduate/computer-sciences/computer-sciences-ms/computer-sciences-professional-program-ms/#admissionstext">https://guide.wisc.edu/graduate/computer-sciences/computer-sciences-ms/computer-sciences-professional-program-ms/</a></p>
<p><a
href="https://www.cs.wisc.edu/ms-data-engineering/">https://www.cs.wisc.edu/ms-data-engineering/</a></p>
<p><a
href="https://www.cs.wisc.edu/our-graduate-degrees-programs/">https://www.cs.wisc.edu/our-graduate-degrees-programs/</a></p>
<p><a
href="http://apply.grad.wisc.edu/">http://apply.grad.wisc.edu/</a></p>
<p>3-4 semesters，学费便宜，无TA/RA，学位与 MSCS 相同</p>
<p>一份申请费可以同时申三个志愿</p>
<p>DDL：MSCS 12.15，PMP 3.15，MSDE 3.15可以 Update</p>
<p>GRE: Not Required，TOEFL：1846</p>
<p>MSCS 与 PhD 同标准，可互转</p>
<h2 id="usc-80-134-65-25-26">USC (80, 134, 65, 25, 26)</h2>
<h3 id="cs28-general-b">*CS28 (General) (B+)</h3>
<p><a
href="https://www.cs.usc.edu/academic-programs/masters/computer-science-general/">https://www.cs.usc.edu/academic-programs/masters/computer-science-general/</a></p>
<p>1.5-2 years，纯看GPA</p>
<p>GRE: Not Required，TOEFL：4852</p>
<p>DDL：12.15，Update 较麻烦，1000 刀占位费，可以 defer 半年或一年</p>
<h2 id="uw6-63-26-6-7">UW（6, 63, 26, 6, 7）</h2>
<h3 id="ee-pmpb-">*EE PMP（B-）</h3>
<p><a
href="https://www.ece.uw.edu/academics/pmp/">https://www.ece.uw.edu/academics/pmp/</a></p>
<p><a
href="https://grad.uw.edu/prospective-students/how-to-apply/international-applicants/">https://grad.uw.edu/prospective-students/how-to-apply/international-applicants/</a><a
href="https://grad.uw.edu/prospective-students/how-to-apply/apply-now/">https://grad.uw.edu/prospective-students/how-to-apply/apply-now/</a></p>
<p><a
href="https://www.1point3acres.com/bbs/thread-604805-1-1.html">https://www.1point3acres.com/bbs/thread-604805-1-1.html</a></p>
<p><a
href="https://www.1point3acres.com/bbs/thread-979569-1-1.html">https://www.1point3acres.com/bbs/thread-979569-1-1.html</a></p>
<p><a
href="https://www.1point3acres.com/bbs/thread-719858-1-1.html">https://www.1point3acres.com/bbs/thread-719858-1-1.html</a></p>
<p>1.5-3 years，4 quarters，晚上上课</p>
<p>DDL：1.5（3月初出结果），3.15（5月中出结果），5.15（7月中出结果）</p>
<p>GRE: Not Required，TOEFL：4854</p>
<h2 id="其它">其它</h2>
<h3 id="unc-41-102-69-29-48">UNC (41, 102, 69, 29, 48)</h3>
<p>MSCS几乎不收陆本</p>
<h3 id="brown-129-63-6113-37">Brown (129, 63, 61,13, 37)</h3>
<h3 id="scm-cs-a-">ScM CS (A-)</h3>
<p><a
href="https://graduateprograms.brown.edu/graduate-program/computer-science-scm">https://graduateprograms.brown.edu/graduate-program/computer-science-scm</a></p>
<p>2-4 semesters，托福卡105，课程质量高，wkld 小</p>
<p>DDL：1.15</p>
<p>GRE: Suggested</p>
<h3 id="ucsb-67-149-64-32-23">UCSB (67, 149, 64, 32, 23)</h3>
<p>MSCS (A-)</p>
<p><a
href="https://www.cs.ucsb.edu/index.php/education/graduate/masters-degree">https://www.cs.ucsb.edu/index.php/education/graduate/masters-degree</a></p>
<p>1.5 years，关注prof的match度，可申TA，陆本较少</p>
<p>UCI (84, 235, 95, 34, 26)</p>
<p>MCS (B+)</p>
<p><a href="https://mcs.ics.uci.edu/">https://mcs.ics.uci.edu/</a></p>
<p>Rolling，4 quarters/15
months，就业向（MSCS研究向，课程设置类似），不可转博</p>
<p>NetSys (B-)</p>
<p>4-6 quarters，一年3个quarter</p>
<p>MSWE</p>
<p>15 months，5 quarters</p>
<p>Rice (180, 100, 147, 15, 43)</p>
<p>NEU (194, 388, 168, 44, 12)，Rolling</p>
<p>Dartmouth (261, 205, 123, 12, 65)</p>
<p>TAMU (148, 164, 181, 67, 37)</p>
]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
  <entry>
    <title>留美备忘录</title>
    <url>/2024/10/11/%E7%95%99%E7%BE%8E%E5%A4%87%E5%BF%98%E5%BD%95/</url>
    <content><![CDATA[<h2 id="护照">护照</h2>
<ul>
<li>护照最好在户籍地公安局办理，在其它地区公安局会寄送到户籍地审核，所需资料也按户籍地标准要求；</li>
<li>护照办理流程：带身份证，自助机器生成表格，拍照，填表格，在人工柜台办理，拿回执，数日后凭回执取护照；仅凭身份证也可取护照，可以选择寄送；</li>
<li>在美国，护照充当最权威的身份证的作用，但可以使用驾照等证明文件作为大多数时间的身份证明；</li>
</ul>
<span id="more"></span>
<h2 id="签证">签证</h2>
<ul>
<li>步骤：
<ul>
<li>获取对应学校 I-20，打印后签名即可；</li>
<li>填写 <a href="https://ceac.state.gov/genniv/">DS-160
申请表</a>；</li>
<li>支付 <a
href="https://www.ustraveldocs.com/cn/zh/payment-options">F-1 签证费</a>
和 <a href="https://www.fmjfee.com/i901fee/index.html">SEVIS I-901
费用</a>；</li>
<li>准备文件：学校成绩单、托福 GRE
成绩单、Offer、资产证明与关系证明、身份证、护照、DS-160
表确认单、面签预约确认单、SEVIS I-901 缴费凭证、六个月内拍摄的 2 英寸 x
2 英寸（5.1 厘米 x 5.1 厘米）照片、学习计划和简历；</li>
<li>预约并参加面试；</li>
</ul></li>
<li>若 check 则收走护照，4-6 周后进入处理流程，再数个工作日后 issue；EMS
邮寄护照和签证（本人签收或委托信）；</li>
</ul>
<h2 id="流量">流量</h2>
<ul>
<li>美国三大运营商：Verizon、T-Mobile、AT&amp;T；其余流量套餐：Mint
Mobile、Visible 等；</li>
<li>先买国内运营商的国际套餐或国际漫游（或淘宝买 Sim
卡），到美国后买那边运营商的卡即可；</li>
<li>我的套餐：<a href="https://www.att.com/prepaid/plans/">AT&amp;T $25
套餐</a>；</li>
</ul>
<h2 id="银行卡">银行卡</h2>
<ul>
<li>先用家长 Visa 信用卡办一张副卡，在美国消费后由家人还款；</li>
<li>到美国后再办一张美国信用卡（BOA 或 Chase）；</li>
<li>有两个账户，checking account 用于日常消费，saving account
用于存钱（年化利率仅 0.01%，消费超过 6 次每次需交
$10，总体用处不大）；</li>
<li>信用卡可以透支，部分消费会有返现，使用美国借记卡还款；学生由于没有稳定收入，借记卡金额需要境外汇款，过程产生的手续费可能与返现抵消，因此用处不大；</li>
</ul>
<h2 id="飞机">飞机</h2>
<ul>
<li>机票在携程上直接购买即可，注意价格变动大；</li>
<li>准备纸质备忘录，记录常用电话、信息等，防止手机不能用；</li>
<li>剃须刀、充电宝、电池不要放箱子里；火柴、打火机等均不能带；</li>
<li>不需要参与行李过海关的环节，只有人过海关；</li>
<li>廉航随身行李不收费，托运行李一般每件在 $60~$100
左右（联乘直挂只算一次）；</li>
<li>肉、液体、种子等管控较严，其余食品管控较松；</li>
<li>只有两步：值机和登机；行李直挂转机无需值机，找到 transit 或 transfer
的地点即可；非直挂需要先去 baggage claim 取行李，再去 connection
重新值机；</li>
</ul>
<h2 id="生活">生活</h2>
<ul>
<li>租房不带家具，带家电；</li>
<li>购物有消费税；非快餐店吃饭给最少 18% 的小费；</li>
<li>消费使用刷卡或现金；</li>
<li>对机动车之外的交通工具不太友好；</li>
<li>多数情况可以用驾照 permit 代替护照证明身份；</li>
<li>人们打招呼很热情；</li>
<li>坐公交车在路边招手即可，想下车拉一下黄色杆即可；</li>
<li>UPS 退货要留着快递盒，否则得买他的袋子；Whole food store
则不需要；</li>
</ul>
<h2 id="其它">其它</h2>
<ul>
<li>Duke 直接通过校内平台在 Lancaster 租房，提前找好室友；</li>
<li>到国际旅行卫生保健中心体检、打疫苗、填写学校要求的强制疫苗表、领小红本与小黄本；有签证可以免体检费；</li>
<li>自行打印成绩单后找校教务处密封盖章，自行邮寄。拿到学位证和毕业证后在档案馆办理翻译证明，同样在教务处密封盖章；</li>
</ul>
<h2 id="单位">单位</h2>
<ul>
<li>华氏度：F = 32 + 1.8 * C；100 F ≈ 37.78 C；</li>
<li>美制加仑：1 gallon-us ≈ 3.8 L；</li>
<li>液量盎司：1 gallon-us = 8 pt = 128 fl oz；1 fl oz ≈ 30 ml；</li>
<li>磅：1 Lb ≈ 454 g；</li>
<li>英尺：1 ft ≈ 30.48 cm；1 ft = 12 in；</li>
<li>英寸：1 in ≈ 2.54 cm；</li>
</ul>
<h2 id="找工">找工</h2>
<p>资料：</p>
<p>https://github.com/eliaszon/Programmers-Overseas-Job-Interview-Handbook?tab=readme-ov-file</p>
<p>https://www.eecsresume.com/article</p>
<h3 id="简历">简历</h3>
<ul>
<li>写好 Linkedin Profile，另外为每个岗位类型准备一份简历；建议使用
Overleaf Resume 模板；</li>
<li>简历保证不超过一页，附上自己的联系方式；</li>
<li>实习 Bullet Point 按【目的、内容、工具、特色、提升】来写；</li>
<li>项目 Bullet Point 按【内容、特色、工具、细节、工作量】来写；第一个
BP 用于概述；</li>
<li>使用“最小项目法”，思考符合当前描述的最小项目，从而丰富内容；</li>
</ul>
<h3 id="投递">投递</h3>
<ul>
<li>Github 上会有当年开放的所有岗位，包括 Intern 和
NG，实时更新；此外主流求职平台有：<a
href="https://www.linkedin.com/jobs/search/?currentJobId=3968882269">Linkedin</a>、<a
href="https://www.indeed.com/?from=jobsearch-empty-whatwhere">Indeed</a>、<a
href="https://www.google.com/search?q=software+engineer+jobs&amp;hl=en&amp;oq=software+engineer+jobs&amp;ibp=htl;jobs&amp;sa=X&amp;htivrt=jobs&amp;htichips=&amp;htischips=#htivrt=jobs&amp;htidocid=iBeBi4RlDep4KEcnAAAAAA%3D%3D&amp;fpstate=tldetail">Google
Career</a>、<a
href="https://www.glassdoor.com/Job/index.htm">Glassdoor</a>、<a
href="https://app.joinhandshake.com/stu/postings">Handshake</a>；</li>
</ul>
<h3 id="面试">面试</h3>
<ul>
<li>提前了解公司，展现热情，强调自己需要这份工作；</li>
<li>准备常问问题的回答（特别是 Behavior
Questions）；准备反问的问题（技术栈、给员工的建议）；面试完后邮件感谢；</li>
<li>面试写题环节要注重
Communication，即使写不出来也要多明确需求、描述想法；</li>
</ul>
<h3 id="其它-1">其它</h3>
<ul>
<li>美国目前主要招 8+ yoe ，Entry-level 招的非常少；需要公司帮抽
H-1B；</li>
<li>Amazon 和 Meta 都是 General
Hire（目前招人少），其余公司均寻求技术栈一致的；</li>
<li>时间线：入学当年 7 月开始找第二年暑期 Summer Intern；</li>
<li>常见 OA 平台：CodeSignal、HackerRank；</li>
</ul>
]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Spring 系列入门</title>
    <url>/2024/10/11/Java-Spring-%E7%B3%BB%E5%88%97%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h2 id="spring-framework">Spring Framework</h2>
<ul>
<li>IoC（Inversion of Control）：程序中不主动 new
对象，而是由外部（Spring
的容器）提供对象，实现充分解耦；这一创建权的转移称为控制反转，这些被管理的对象称为
Bean；</li>
<li>DI（Dependency Injection）：在容器中建立各个 Bean
之间的依赖关系的过程，称为依赖注入；</li>
<li>Maven Dependency 中导入 spring-context 坐标后：</li>
</ul>
<span id="more"></span>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在 resources/ 中创建 applicationContext.xml：</span></span><br><span class="line"><span class="comment">// 可添加 autowire 自动注入依赖</span></span><br><span class="line">&lt;bean id=”bookService” class=”com.example.service.impl.BookServiceImpl”&gt;</span><br><span class="line">	&lt;property name=<span class="string">&quot;bookDao&quot;</span> ref=<span class="string">&quot;bookDao&quot;</span> /&gt; <span class="comment">/* Setter 注入 */</span></span><br><span class="line">	<span class="comment">// name 为构造函数形参名，可改为使用 type，或使用 index=&quot;0&quot;</span></span><br><span class="line">	&lt;constructor-arg name=<span class="string">&quot;bookDao&quot;</span> ref=<span class="string">&quot;bookDao&quot;</span> /&gt; <span class="comment">/* 构造器注入 */</span></span><br><span class="line">	&lt;property name=<span class="string">&quot;databaseName&quot;</span> value=<span class="string">&quot;mysql&quot;</span> /&gt;</span><br><span class="line">&lt;/bean&gt;</span><br><span class="line"><span class="comment">// name 起别名，scope 设置不为单例（默认为 singleton）</span></span><br><span class="line">&lt;bean id=<span class="string">&quot;bookDao&quot;</span> name=<span class="string">&quot;dao dao1&quot;</span> class=<span class="string">&quot;com.example.dao.impl.BookDaoImpl&quot;</span></span><br><span class="line">	scope=<span class="string">&quot;prototype&quot;</span> init-method=<span class="string">&quot;init&quot;</span> destroy-method=<span class="string">&quot;destroy&quot;</span> /&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 给 BookDao 定义 Setter 方法或构造方法，然后添加</span></span><br><span class="line"><span class="type">ClassPathXmlApplicationContext</span> <span class="variable">ctx</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ClassPathXmlApplicationContext</span>(<span class="string">&quot;applicationContext.xml&quot;</span>);</span><br><span class="line"><span class="type">BookService</span> <span class="variable">bookService</span> <span class="operator">=</span> (BookService)ctx.getBean(<span class="string">&quot;bookService&quot;</span>);</span><br><span class="line">ctx.close(); 或 ctx.registerShutdownHook();</span><br></pre></td></tr></table></figure>
<ul>
<li>Bean 的生命周期：创建对象（内存分配）→ 构造 → 属性注入（Setter）→
初始化（继承自 InitializingBean 的 afterPropertiesSet()）→ 使用 →
销毁（继承自 DisposableBean 的 destroy()）；</li>
<li>Bean Factory ⇒ ApplicationContext ⇒
ClassPathXmlApplicationContext；</li>
</ul>
<h2 id="spring-boot">Spring Boot</h2>
<ul>
<li>Spring Boot Web 内置 Tomcat，兼容 Servlet 与 JSP
规范；三层架构：Controller（控制层）、Service（业务逻辑层）、DAO（数据访问层
/ 持久层）；</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 注解配置 Bean</span></span><br><span class="line">&lt;context:component-scan base-<span class="keyword">package</span>=<span class="string">&quot;com.example&quot;</span> /&gt;</span><br><span class="line"><span class="comment">// 纯注解 SpringConfig.java</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@ComponentScan(&quot;com.example&quot;)</span></span><br><span class="line"><span class="meta">@PropertySource(&quot;jdbc.properties&quot;)</span></span><br><span class="line"><span class="meta">@Import(&#123;JdbcConfig.class&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SpringConfig</span> &#123;</span><br><span class="line">	<span class="comment">// 用于第三方 Bean</span></span><br><span class="line">	<span class="meta">@Bean</span></span><br><span class="line">	<span class="keyword">public</span> DataSource <span class="title function_">dataSource</span><span class="params">(BookService bookService)</span> &#123;</span><br><span class="line">		<span class="type">DataSource</span> <span class="variable">ds</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataSource</span>();</span><br><span class="line">		ds.setUsername(<span class="string">&quot;root&quot;</span>);</span><br><span class="line">		<span class="keyword">return</span> ds;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 代码里改为</span></span><br><span class="line"><span class="type">ApplicationContext</span> <span class="variable">ctx</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AnnotationConfigApplicationContext</span>(SpringConfig.class);</span><br></pre></td></tr></table></figure>
<ul>
<li>通过注解开发支持无 XML 配置；纯注解开发：
<code>@Component("bookDao")</code> ，三个与之完全等同的注解：
<code>@Service</code> 、 <code>@Repository</code> 、
<code>@Controller</code> ；</li>
<li><code>@Scope("prototype")</code> ， <code>@PostConstruct</code> ，
<code>@PreDestroy</code> ， <code>@Autowired</code>
（默认按类型注入）；</li>
<li><code>@Primary</code>
（指定优先此类对象）、<code>@Qualifier("")+@AutoWired</code>
（类型耦合）、 <code>@Resource(name="")</code>（名字耦合，不推荐）、
<code>@Value("")</code> ；</li>
</ul>
<h2 id="springmvc">SpringMVC</h2>
<ul>
<li>使用 <code>@RestController</code> 声明 Controller 负责 Tomcat
路由和返回；原始方法为在 <code>@RequestMapping("/")</code>方法中声明
<code>HttpServletRequest</code> 对象参数，再通过
<code>getParameter(name)</code>
获得对应参数字符串；现在处理函数只需定义好参数即可获取 GET 与 POST
方法后接的各项参数；
<code>@RequestParam(name="username", require=false)</code>
设置不必须的后接参数；</li>
<li>一个 <code>@RestController</code> 类的方法的返回值即为
<code>@ResponseBody</code> ，若为复杂类型，会转换成 JSON
返回给客户端；</li>
<li>前端工程化框架打包的结果存放在 /Resources 中；</li>
<li>启动类声明注解 <code>@SpringBootApplication</code> 中包含了
<code>@ComponentScan</code> ；</li>
<li>过滤器、Cookie、Session 等内容属于 JavaWeb；JWT、OSS
等技术属于解决方案；接受请求、相应数据、拦截器、全局异常处理等 Spring 内
Web 功能属于 SpringMVC；IoC、DI、AOP、事务管理等架构理念支持属于 Spring
Framework，JDBC 等数据库操作被封装在 MyBatis；后三者统称为
SSM；SpringBoot 用于快捷启动整个项目的开发；</li>
</ul>
<h2 id="mybatis">Mybatis</h2>
<ul>
<li>在 application.properties
中配置连接四要素：Driver、URL、Username、Password；</li>
<li>接口类使用 <code>@Mapper</code> 注解，返回值变量定义前加
<code>@Select("command")</code>
注解，会自动将查询答案返回到此变量中，也可以定义方法；增删改的操作类似；使用
<code>@Options</code> 返回插入后条目的主键值；可以用
<code>@Results</code> 和 <code>@Result</code>
字段注解手动映射返回值封装；</li>
<li>使用 <code>getConnection()</code> 获取数据库连接池的连接；可使用
lombok 工具包根据特定注解自动生成各类方法（getter()、toString()
等）；</li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>部分基础编程术语中英对照表</title>
    <url>/2024/10/11/%E9%83%A8%E5%88%86%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B%E6%9C%AF%E8%AF%AD%E4%B8%AD%E8%8B%B1%E5%AF%B9%E7%85%A7%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="部分基础编程术语中英对照表">部分基础编程术语中英对照表</h1>
<table>
<colgroup>
<col style="width: 14%" />
<col style="width: 13%" />
<col style="width: 15%" />
<col style="width: 23%" />
<col style="width: 9%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr>
<th>中文</th>
<th>English</th>
<th>中文</th>
<th>English</th>
<th>中文</th>
<th>English</th>
</tr>
</thead>
<tbody>
<tr>
<td>逗号</td>
<td>comma</td>
<td>句号</td>
<td>period</td>
<td>波浪号</td>
<td>tilde</td>
</tr>
<tr>
<td>冒号</td>
<td>colon</td>
<td>分号</td>
<td>semicolon</td>
<td>省略号</td>
<td>ellipsis</td>
</tr>
<tr>
<td>问号</td>
<td>question mark</td>
<td>感叹号</td>
<td>exclamation mark</td>
<td>引号</td>
<td>quotation marks</td>
</tr>
<tr>
<td>小括号</td>
<td>parentheses</td>
<td>中括号</td>
<td>square brackets</td>
<td>大括号</td>
<td>curly braces</td>
</tr>
<tr>
<td>星号</td>
<td>asterisk</td>
<td>与号（&amp;）</td>
<td>ampersand</td>
<td>井号</td>
<td>number sign / hash / pound</td>
</tr>
<tr>
<td>下划线</td>
<td>underline</td>
<td>百分号</td>
<td>percent sign</td>
<td>连字符</td>
<td>hyphen</td>
</tr>
<tr>
<td>斜杠</td>
<td>slash</td>
<td>反斜杠</td>
<td>backslash</td>
<td>`</td>
<td>back-tick</td>
</tr>
<tr>
<td>取模</td>
<td>modulus</td>
<td>余数</td>
<td>remainder</td>
<td>加数</td>
<td>addend</td>
</tr>
<tr>
<td>被除数</td>
<td>dividend</td>
<td>除数</td>
<td>divisor</td>
<td>乘数</td>
<td>multiplier</td>
</tr>
<tr>
<td>被减数</td>
<td>minuend</td>
<td>减数</td>
<td>subtracter</td>
<td>操作数</td>
<td>operand</td>
</tr>
<tr>
<td>语法</td>
<td>syntax</td>
<td>语义</td>
<td>semantics</td>
<td>变量</td>
<td>variable</td>
</tr>
<tr>
<td>标识符</td>
<td>identifier</td>
<td>初始化</td>
<td>initialize</td>
<td>语句</td>
<td>statement</td>
</tr>
<tr>
<td>赋值</td>
<td>assignment</td>
<td>表达式</td>
<td>expression</td>
<td>优先级</td>
<td>precedence</td>
</tr>
<tr>
<td>形参</td>
<td>parameter</td>
<td>实参</td>
<td>argument</td>
<td>栈帧</td>
<td>stack frame</td>
</tr>
<tr>
<td>作用域</td>
<td>scope</td>
<td>局部</td>
<td>local</td>
<td>全局</td>
<td>global</td>
</tr>
<tr>
<td>转义</td>
<td>escape</td>
<td>短路</td>
<td>short circuit</td>
<td>嵌套</td>
<td>nest</td>
</tr>
<tr>
<td>语法糖</td>
<td>syntactic sugar</td>
<td>通配</td>
<td>glob</td>
<td>描述符</td>
<td>descriptor</td>
</tr>
<tr>
<td>终端</td>
<td>terminal</td>
<td>缓冲</td>
<td>buffer</td>
<td>内存</td>
<td>memory</td>
</tr>
<tr>
<td>编译</td>
<td>compile</td>
<td>单例</td>
<td>singleton</td>
<td>运算符</td>
<td>operator</td>
</tr>
<tr>
<td>一元</td>
<td>unary</td>
<td>二元</td>
<td>binary</td>
<td>三元</td>
<td>ternary</td>
</tr>
<tr>
<td>可变（数量）</td>
<td>variadic</td>
<td>精度</td>
<td>precision</td>
<td>上下文</td>
<td>context</td>
</tr>
<tr>
<td>类型转换（人为）</td>
<td>cast</td>
<td>类型转换（编译器）</td>
<td>type promotion / conversion</td>
<td>递归</td>
<td>recursion</td>
</tr>
<tr>
<td>并发</td>
<td>concurrent</td>
<td>并行 / 并联</td>
<td>parallel</td>
<td>串行 / 串联</td>
<td>serial</td>
</tr>
<tr>
<td>演绎</td>
<td>deduction</td>
<td>归纳</td>
<td>induction</td>
<td>约简</td>
<td>reduction</td>
</tr>
<tr>
<td>分隔符</td>
<td>delimiter</td>
<td>字典序</td>
<td>lexicographic order</td>
<td>字面量</td>
<td>literal</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
  <entry>
    <title>2023 暑期阿里实习记录</title>
    <url>/2024/10/11/2023-%E6%9A%91%E6%9C%9F%E9%98%BF%E9%87%8C%E5%AE%9E%E4%B9%A0%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p>关于实习投递总结：<a
href="https://www.nowcoder.com/discuss/478477035904466944">牛客链接</a>。</p>
<h2 id="入职">入职</h2>
<ul>
<li>A区5个、B区3个食堂，每天午饭20元打到卡上，晚饭20元和夜宵10元（晚9点）以点券形式发放，周末均以点券发放；按出勤日发放工资（实习生统一工资），每月2000元房补，报销来回车票，赠送2周酒店和贝壳免费转租服务；</li>
<li>公司通讯工具为阿里钉，联网、会议工具为阿里郎，文档工具为语雀；</li>
<li>除公司福利外还有一年香、三年醇、五年陈、奶茶日等活动，一般由公司组织或mentor买单；每季度有P9和HRG组织的新人茶话会活动；</li>
<li>团队有热天轮流请甜筒、升职请全组吃饭、周末爬山等传统；平时会组团打篮球、健身等；</li>
<li>工作时间：10点~12点，14点~18点，19点~21点（10 9
5）；周五18点下班；</li>
<li>不看工作时长，只看任务完成情况；只要任务完成任何时候都能下班；</li>
<li>技术能力和工作完成情况是第一位；</li>
<li>对同事、老板直呼花名（阿里特色）或同学；男女比大概3:1；</li>
<li>关于工作：每周老板会给任务，没完成会批评，经常周末也会给任务；</li>
<li>组里有和我同期进入的硕士应届生，有在华为工作两年跳槽阿里的，有在阿里干了六七年的；有年轻的，也有刚抱小孩的，没有年纪更大的；</li>
<li>压力非常大，每周一开一次组会，还有各项业务基本一天一次小会对接任务；</li>
<li>沟通直接，交流高效，不回避矛盾；</li>
<li>同组负责的业务有：端智能、XR、AI引擎相关；技术栈：C++、C#、Objective-C、Unity、iOS、Android、VisionOS、前端；</li>
</ul>
<span id="more"></span>
<h2 id="见闻">见闻</h2>
<ul>
<li>关于招聘（仅针对阿里）：一个岗位有几千人投递，经过HR筛选后剩50+份，交给组内员工直接面试；一面、二面、三面分别为P7（师兄）、P8（mentor）、P9（团队大老板），最后选出两人入职；总体竞争很激烈。</li>
<li>我个人对岗位的划分：研究、技术（工程）、业务；算法岗学历要求较高（我所在团队算法岗的最低学历是华五硕士，最高有北大博士）；技术岗有较稳定的推进节奏，也需要接相应业务以维持重要性；业务岗特定节点附近会很忙，平时相对轻松，据说升职速度主要取决于接到项目的含金量；</li>
<li>2023年7月，阿里改组1+6+N后进行中层职级调整，将P4~P8大职级拆分为14~28小职级，连续两季度绩效考核3.75（三档：3.75、3.5、3.25）可以升一小职级；P8以上职级取消，由组织直接任命并决定薪酬；</li>
<li>阿里摩天轮曾发生P0级事故：一个测试包30天过期并提醒升级的逻辑被注入到正式发布版，直到双十一前半个月才被发现。最后紧急打补丁修复，摩天轮负责人离职；</li>
<li>身边案例（往年）：一般两年升P6，4年~8年升P7，6年~10年升P8；P8开始管理小组（即mentor）；P9和HRG人员共同管理整个团队；</li>
<li>国内大厂的通病：短视、赛马，不以产品质量为关键指标，能用就行，导致团队间合作效率低，员工归属感较弱；</li>
<li>KPI考核体系现已改为OKR体系；</li>
<li>每周一的周会：类Brainstorming讨论，语速快、无停顿、可以随意打断对方，不回避激烈态度和意见冲突（但坚持对事不对人）；有话直说，时刻以解决问题、提高效率为最高目标；</li>
<li>坚持任务驱动型学习，保持高效学习的能力比学习本身更重要；</li>
<li>组里有一个很摆的十二年
P6，从不加班，几乎也没有被裁风险，因为组内只有他负责这块业务，裁了很难补上；所以”建立技术和业务壁垒“也有用处，虽然大部分时候不是我们自己能控制的；</li>
<li>P7 及以下的人员变动一般由 P9 统一管理，P8 负责反馈和具体执行；</li>
<li>要求出活，几乎没有时间能沉淀技术；</li>
</ul>
<h2 id="团队工作">团队工作</h2>
<ul>
<li>新人茶话会（P9和HRG召开），Meta技术团队整体介绍；
<ul>
<li>P9个人经历：13年 ALL IN无线，设计手淘架构；目前负责端智能；</li>
<li>面向3D/XR，业务侧；3D内容离线生产，实时渲染；</li>
<li>使用软硬一体拍摄设备，几何重建与NeRF重建，业务应用；</li>
<li>细节清晰、模型小（5M以内）、实时渲染、低成本；渲染耗时：3秒用户留存率较高，5秒大幅降低；</li>
<li>资产工作流规范化，降本提效，规模应用；已做到5000+交付，33项业务覆盖；</li>
<li>3D模型 → 结构化网格（Mesh）→
材质贴图；网格固定：同款多SKU，网格生成：不同款式与不同SKU；</li>
<li>2D真人虚实融合：单视角0DoF；2.5D真人虚实融合：3DoF、360度多视角；3D：6DoF、有3D视频；</li>
<li>预处理 → 静态重建 → 动态稀疏重建 → 运动蒸馏 → 实时渲染；</li>
<li>行业首个手机端实时交互；大世界系统，流式加载，端云协同；初步落地：淘宝人生@手淘，日食记@手猫、手淘；</li>
<li>端3D引擎（渲染架构）：AceNNR
Runtime；云3D引擎：AceUSD模型格式、3D资产库；</li>
<li>离线引擎AceRay光线追踪（1min-1h），实时UE光栅化渲染（15ms-1s）</li>
<li>端智能：MNN-XRAppOS（终端非游戏应用研发模式）（实时AI交互算法PixelAI）-3D商品AR交互应用；3D大模型；为Vision
Pro做好规划；</li>
<li>人货场 - 一次编辑（UE Unity）- 二次编辑（电商3D内容编辑器）-
AceUSD模型（3D资产库）；</li>
</ul></li>
</ul>
<h2 id="个人工作">个人工作</h2>
<ul>
<li>实习期任务：完成 XRAppOS 远程真机调试插件，实现对端侧 3D/XR 场景的
Unity 实时场景部署和调试；
<ol type="1">
<li>在 XRAppOS 端侧构建调试 SDK，用于接收 Unity 发送过来的命令，和向
Unity 同步状态（主要技术栈: iOS/Android + C/C++/Objective-C++）；</li>
<li>在 Unity 中实现 XRAppOS 的 Debug
Server，用于和端侧进行实时通信和同步状态（主要技术栈: C#/C++）；</li>
<li>基于 XRAppOS 端侧和 Unity 插件为 3D/XR 开发/调试提效，实现 Unity
场景快速导出并推送到端侧、端侧场景与 Unity 场景双向状态同步的调试。</li>
</ol></li>
<li>第一阶段：插件环境搭建</li>
</ul>
<p><a href="/2023/08/12/Unity-远程真机调试插件开发/">Unity
远程真机调试插件开发</a></p>
<ul>
<li>第二阶段：插件架构设计
<ul>
<li>正式环境搭建</li>
<li>gRPC 接入 XRAppOS</li>
<li>完成 Unity 与 XRAppOS 环境相互调用</li>
<li>跑通 Unity 中创建一个 Cube，同步在 XRAppOS 中创建</li>
<li>架构设计，需要满足如下几个条件：
<ul>
<li>扩展性：能够以较低的成本新增功能，允许外部开发者扩展插件能力</li>
<li>分层设计：按照通道、协议、接入、业务等维度自底向上的分层设计出插件的架构，使得后续功能开发无需关注底层通道和实现，只需要专心实现功能</li>
<li>稳定性：需要在底层做好稳定性保证，通过断线重连、重连状态恢复等机制保证通道稳定性，提高代码的鲁棒性避免出现
Crash</li>
<li>高性能：插件传输的数据较多，需要通过数据压缩、网路优化等手段降低延迟，提高通信效率，同时尽可能降低对
App 本身运行的影响</li>
</ul></li>
<li>架构验证：
<ul>
<li>完成底层通道、协议层搭建</li>
<li>分别测试局域网和广域网下通道传输数据的延迟和吞吐量</li>
<li>完成接入层设计，并基于接入层实现 2 个接口并在 C/S 双端互调</li>
</ul></li>
<li>稳定性验证：通过 Address Sanitizer(ASan) 验证 C++
的稳定性，通过内存工具检查内存泄露，通过自测保证不发生 Crash</li>
</ul></li>
<li>第三阶段：场景结点树同步
<ul>
<li>完成两个场景的 Node 树相互同步的逻辑</li>
<li>完成 Node
的层级结构对应（经过服务端几何处理后，可能结点中间的某级结构会发生变化，需要支持配置映射规则）</li>
<li>完成 Node 的 TRS (Translation / Rotation / Scale) 双向同步</li>
<li>完成 Node 的增删、层级结构变更同步</li>
<li>完成 Node 的 Component 修改同步</li>
</ul></li>
<li>第四阶段（未来规划）：场景快速构建
<ul>
<li>在 Unity 端实现基于 AceNNR
的场景构造插件和模型上传接口的场景一键打包上传能力，并支持在 GUI
上实时查询上传状态、取消上传和查看上传结果</li>
<li>调通 AceNNR 插件接口调用</li>
<li>MTOP 接口调用，MTOP C++ SDK，Apply SecretKey</li>
<li>上传按钮、上传状态和结果的 GUI</li>
<li>（低优先级，先完成主线）与 XR 工程团队与 AceNNR
团队同学配合，搭建一条轻量级的本地场景处理通道，完成局域网的模型生成，并通过调试协议推送到端侧预览</li>
</ul></li>
<li>第五阶段（未来规划）设备信息管理
<ul>
<li>设备沙盒文件管理 (可复用已有三方插件能力)</li>
<li>设备日志输出（例如输出端上的 tlog 等信息）</li>
<li>设备配置管理（例如修改端侧 Orange 配置）</li>
</ul></li>
<li>逻辑开发调试（未来规划）
<ul>
<li>XRAppOS x Weex JS 工程调试打通</li>
</ul></li>
</ul>
<h2 id="项目">项目</h2>
<ul>
<li>编写基于 XR 端智能框架的远程真机调试插件，实现对端侧 3D/XR 场景的
Unity 实时场景部署和调试
<ul>
<li>使用 P/Invoke 实现在 Unity 3D 中 C# 与 C++ 的跨语言调用；</li>
<li>使用 gRPC + Protobuf 组合完成多客户端远程实时高性能通信与 C/S
双端互调；</li>
</ul></li>
<li>完成基于 Weex:binding 的模型渲染中间件，实现前端快速集成与部署
<ul>
<li>完成对 XR 渲染组件与前端框架的互操作的性能分析；</li>
</ul></li>
<li>全平台轻量级高性能深度学习引擎 MNN 开发，完成 Python
运行时性能调优组件
<ul>
<li>搭建端智能基础链路，实现在 PythonVM 运行时上运行 MNN-CV
分类算法进行实时极高性能（200 ms）当前帧物品识别；</li>
</ul></li>
<li>基于 iOS UIKit/AVFoundation 和 ARKit 的端侧 AR 页面适配，生成 SDK
测试包，并最终集成发布
<ul>
<li>设计 AR 互动帧投放放置类商品的通用页面与链接跳转协议；</li>
<li>基于 ARKit
在端智能框架中设计接口，为应用层提供获取点云地图能力；</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>工作</tag>
      </tags>
  </entry>
  <entry>
    <title>Swift &amp; SwiftUI 学习笔记</title>
    <url>/2024/10/11/Swift-SwiftUI-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>参考：</p>
<p><a
href="https://docs.swift.org/swift-book/documentation/the-swift-programming-language/">The
Swift Programming Language (6 beta)</a></p>
<p><a href="https://developer.apple.com/documentation/swiftui">SwiftUI
Documentation</a></p>
<p><a href="https://developer.apple.com/tutorials/swiftui/">SwiftUI
Tutorials</a></p>
<p><a href="https://developer.apple.com/tutorials/app-dev-training">App
Dev Tutorials</a></p>
<span id="more"></span>
<h2 id="swift-语法">Swift 语法</h2>
<h3 id="变量与常量">变量与常量</h3>
<ul>
<li>常量： <code>let a: Double = 0</code> ；变量使用 <code>var</code>
；默认类型推断为 Int 和 Double；</li>
<li>Swift 不会做任何隐式类型转换；可以用 <code>"\(name)\"</code>
表示转化成字符串；</li>
<li>类型别名： <code>typealias newname = type</code> ；</li>
<li>内置基本数据类型：Int（64位），UInt（一般不用），Float，Double（64位），Bool，String，Character（同样用双引号）；</li>
<li>集合数据类型：Array，Dictionary，Set；</li>
<li>引用类型：Class（Struct 是值类型），Closure，Function；</li>
<li>数组声明：<code>var someInts = [Int](repeating: 0, count: 3)</code>
；可以 <code>append()</code> ，可以用 <code>+</code> 合并；</li>
<li>字典：<code>var someDict:[Int:String] = [1:"One", 2:"Two", 3:"Three"]</code>
；</li>
<li>枚举：</li>
</ul>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">Student</span>&#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Name</span>(<span class="type">String</span>)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Mark</span>(<span class="type">Int</span>,<span class="type">Int</span>,<span class="type">Int</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> studMarks <span class="operator">=</span> <span class="type">Student</span>.<span class="type">Mark</span>(<span class="number">98</span>,<span class="number">97</span>,<span class="number">95</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">switch</span> studMarks &#123;</span><br><span class="line"><span class="keyword">case</span> .<span class="type">Name</span>(<span class="keyword">let</span> studName):</span><br><span class="line">	  <span class="built_in">print</span>(<span class="string">&quot;<span class="subst">\(studName)</span>。&quot;</span>)</span><br><span class="line"><span class="keyword">case</span> .<span class="type">Mark</span>(<span class="keyword">let</span> <span class="type">Mark1</span>, <span class="keyword">let</span> <span class="type">Mark2</span>, <span class="keyword">let</span> <span class="type">Mark3</span>):</span><br><span class="line">	  <span class="built_in">print</span>(<span class="string">&quot;<span class="subst">\(Mark1)</span>,<span class="subst">\(Mark2)</span>,<span class="subst">\(Mark3)</span>&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">Month</span>: <span class="title class_">Int</span> &#123; <span class="comment">// 若不写明为 Int，则不会默认为每个成员分配一个整型数值</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">January</span> <span class="operator">=</span> <span class="number">1</span>, <span class="type">February</span>, <span class="type">March</span>, <span class="type">April</span>, <span class="type">May</span>, <span class="type">June</span>, <span class="type">July</span>, <span class="type">August</span>, <span class="type">September</span>, <span class="type">October</span>, <span class="type">November</span>, <span class="type">December</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="optional-类型">Optional 类型</h3>
<ul>
<li>在声明的类型后添加 <code>?</code> 表示一个 Optional
类型值，当未赋值时，此值将为 <code>nil</code> ；</li>
<li>在声明的类型后添加 <code>!</code> 表示一个 Implicity Unwrapped
Optional （隐式解包可选类型）值，此后取值不再需要加 <code>!</code>
，如果取值时值为 <code>nil</code> 会直接运行错误，适合确定值永远不为
<code>nil</code> 时使用；</li>
<li>在确定不为空时使用 <code>!</code> 强制解包；显式类型转换会返回一个
Optional 已处理转换失败的情况；</li>
<li>可选绑定（Optional
Binding）：<code>if let name=optionalName &#123;&#125; else &#123;&#125;</code> ；
<code>guard let name=optionalName else &#123;&#125;</code> ；</li>
<li>合并空值运算符： <code>a ?? b</code> 在 a 有值时展开，a 为
<code>nil</code> 时返回 b；b 表达式返回值必须与 a 中存储值同类型；</li>
<li>可选链： <code>if let a = A.B?.C</code> ；</li>
</ul>
<h3 id="语句">语句</h3>
<ul>
<li>行末无需分号，但一行多个表达式间需要分号；判断子句无需小括号；</li>
<li><code>where</code> 子句与 <code>let</code>
配合，多个子句之间用逗号分分隔， <code>if</code>
语句中必须所有子句均满足， <code>switch</code>
子句中只需满足一个子句；</li>
</ul>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">let</span> hello <span class="operator">=</span> optionalHello <span class="keyword">where</span> hello.hasPrefix(&#x27;<span class="type">H</span>&#x27;), <span class="keyword">let</span> name <span class="operator">=</span> optionalName &#123;&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>范围（Range）： <code>0..&lt;10</code> 左闭右开，
<code>0...10</code> 全闭；</li>
<li>学习将不需要的循环变量设为 <code>_</code> ；</li>
</ul>
<h3 id="函数与闭包">函数与闭包</h3>
<ul>
<li>函数声明：<code>func doSomething() -&gt; returnType &#123;&#125;</code>
；</li>
<li>调用函数时，第一个参数无需写明形参名，其余参数均需写明，除非函数定义中使用
<code>_</code> 作为 argumentLabel（不指定的话默认使用 parameterName 作为
argumentLabel）；</li>
<li>函数签名可以作为类型：
<code>var addition: (Int, Int) -&gt; Int = sum</code> ；</li>
<li>闭包本质是代码块（A chunk of code），函数属于闭包：</li>
</ul>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line">&#123;(<span class="type">Int</span>, <span class="type">Int</span>) -&gt; <span class="type">Bool</span> <span class="keyword">in</span> <span class="operator">...</span> &#125;</span><br><span class="line"><span class="comment">// 闭包可以使用参数名称缩写并省略定义：</span></span><br><span class="line"><span class="keyword">var</span> reversed <span class="operator">=</span> names.sorted( by: &#123; <span class="variable">$0</span> <span class="operator">&gt;</span> <span class="variable">$1</span> &#125; )</span><br><span class="line"><span class="comment">// Swift 定义了对 &gt; 的“接受两个字符串并返回 bool” 的实现：</span></span><br><span class="line"><span class="keyword">var</span> reversed <span class="operator">=</span> names.sorted(by: <span class="operator">&gt;</span>)</span><br><span class="line"><span class="comment">// 尾随闭包作参数，支持将其作为最后一个参数调用：</span></span><br><span class="line"><span class="keyword">func</span> <span class="title function_">aFunc</span>(<span class="params">closure</span>: () -&gt; <span class="type">Void</span>) &#123; <span class="operator">...</span> &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>形参 inout：相当于变参，调用时传递 &amp;a；</li>
<li>泛型： <code>func swap&lt;T&gt; (_ a: inout T, _ b: inout T)</code>
，可以在尖括号中添加 T 需要继承的父类或遵循的协议；</li>
<li>关联类型：在协议中使用 <code>associatedtype Item</code> 定义一个
Item 类型，在实现时使用 <code>typealias Item = Int</code>
指定关联类型；</li>
<li>可变参数（Variadic Parameters）： <code>Double...</code> ，使用
for-in 遍历；</li>
<li>Trailing Closures：若函数最后一个参数是闭包，则可以写到 () 之后：
<code>aFunc()&#123; ... &#125;</code> ；</li>
<li>Completion Handler：函数末尾回调，通常使用 Trailing Closures
写；</li>
<li>逃逸闭包（Escaping
Closures）：闭包可能在函数返回后被调用，如异步操作或被存储在外部变量中，需要标注
<code>@escaping</code>
；此时闭包会被储存在堆中，所捕获的变量生命周期延长；</li>
<li>Modifier：一类函数，调用时返回另一个实例，从而允许链式调用：a.f1().f2().f3()；</li>
</ul>
<h3 id="类">类</h3>
<ul>
<li>只能单继承；同名函数必须使用 override
关键字，不使用将编译错误；不允许 overwrite；</li>
<li><code>lazy</code> 成员属性在第一次使用时才计算器初始值；</li>
<li>构造器（Initializer）：
<code>init(name:String) &#123; self.name = name &#125;</code>
；调用构造器时所有参数均需写明形参名；可失败构造器： <code>init?</code>
；析构器： <code>deinit &#123;...&#125;</code> ，没有小括号；</li>
<li>自定义构造器后便不再提供默认构造器，且要求所有属性均被初始化；</li>
<li>使用 <code>super.init(name: name)</code> 调用父类构造函数；
<code>final</code> 可防止 override；便利（
<code>conveience</code>）构造器指定部分初始值后调用其它构造函数；</li>
<li><code>if let square = shape as? Square</code> 使用 <code>as?</code>
实现向下转换可选解包，使用 <code>as!</code> 实现强制解包；使用
<code>is</code> 判断是否为某个子类；</li>
<li>使用 <code>[Any]</code> 定义可以存储任意不同引用类型的数组，使用
<code>[AnyObject]</code> 定义可以存储不同类类型的数组；</li>
<li>类比结构体增加了：继承，运行时类型判断，释放被分配的资源，多次引用；</li>
<li>struct 内的方法不能改变其属性，必须声明为 <code>mutating</code> ；而
class 内的方法可以改变其内部属性而无需 <code>mutating</code> ；</li>
<li>协议：类似虚函数 / 接口，定义一系列必须被遵循者实现的方法；使用
<code>get set</code>
定义可读写性；同时拥有父类和遵循协议的类，冒号后先写父类再写协议；函数名前
<code>required</code> 关键字要求遵循者必须 override 它（遵循者也应标明
<code>required</code> ，类似纯虚函数）；</li>
<li>计算属性（Calculated
Properties）：不直接存储值，每次通过计算得到；</li>
</ul>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">sample</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> no1 <span class="operator">=</span> <span class="number">0.0</span>, no2 <span class="operator">=</span> <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">var</span> length <span class="operator">=</span> <span class="number">300.0</span>, breadth <span class="operator">=</span> <span class="number">150.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">var</span> middle: (<span class="type">Double</span>, <span class="type">Double</span>) &#123;</span><br><span class="line">        <span class="keyword">get</span>&#123; <span class="keyword">return</span> (length <span class="operator">/</span> <span class="number">2</span>, breadth <span class="operator">/</span> <span class="number">2</span>); &#125;</span><br><span class="line">        <span class="keyword">set</span>(axis)&#123;</span><br><span class="line">            no1 <span class="operator">=</span> axis.<span class="number">0</span> <span class="operator">-</span> (length <span class="operator">/</span> <span class="number">2</span>)</span><br><span class="line">            no2 <span class="operator">=</span> axis.<span class="number">1</span> <span class="operator">-</span> (breadth <span class="operator">/</span> <span class="number">2</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">var</span> counter: <span class="type">Int</span> <span class="operator">=</span> <span class="number">0</span>&#123; <span class="comment">// 属性观察器</span></span><br><span class="line">        <span class="keyword">willSet</span>(newTotal)&#123; <span class="built_in">print</span>(<span class="string">&quot;<span class="subst">\(newTotal)</span>&quot;</span>); &#125;</span><br><span class="line">        <span class="keyword">didSet</span>&#123; <span class="built_in">print</span>(\(counter <span class="operator">-</span> oldValue)<span class="string">&quot;); &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>类型属性（Type Properties）： <code>static</code> 属性（Singleton
单例）；类型方法（Type Methods）： <code>static</code> 方法；</li>
<li>下标脚本（Subscripts）：类似 C++ 中重载 <code>[]</code>
；可以重载多个，会自动匹配；</li>
</ul>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">subexample</span> &#123;</span><br><span class="line">    <span class="keyword">let</span> decrementer: <span class="type">Int</span></span><br><span class="line">    <span class="keyword">subscript</span>(<span class="params">index</span>: <span class="type">Int</span>) -&gt; <span class="type">Int</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> decrementer <span class="operator">/</span> index</span><br><span class="line">        <span class="keyword">get</span> &#123;</span><br><span class="line">		        <span class="comment">// 用于下标脚本值的声明</span></span><br><span class="line">		    &#125;</span><br><span class="line">		    <span class="keyword">set</span>(newValue) &#123;</span><br><span class="line">		        <span class="comment">// 执行赋值操作</span></span><br><span class="line">		    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> division <span class="operator">=</span> subexample(decrementer: <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;100 除以 9 等于 <span class="subst">\(division[<span class="number">9</span>])</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>避免循环引用导致引用计数无法归零：可能为 <code>nil</code>
时使用弱引用（ <code>weak</code>），反之使用无主引用（
<code>unowned</code> ）；</li>
<li>通过扩展 <code>extension</code>
给类或协议增加新的属性、方法、构造器等；</li>
<li>Swift
的四种访问控制：public，internal（默认，同模块内可使用），fileprivate（仅当前源文件可使用），private；</li>
<li>属性包装器（Property Wrapper）：分离变量定义与存储，通过
<code>propertyWrapper</code>
注解定义变量行为和合法性判断（类似计算属性）；</li>
<li>ClassName.self() 代表类类型本身（元类型）；</li>
</ul>
<h3 id="其它">其它</h3>
<ul>
<li>Swift 采用 Unicode 编码，变量名可以为中文或 emoji 等；</li>
<li>Swift 对空格有要求；</li>
<li>Swift 3 后取消了 <code>++</code> 、 <code>--</code> 操作以及
switch-for（类似 C 中的 for） 循环；</li>
<li>Swift 检查变量使用前初始化、索引检查、整数溢出、Optional 处理
<code>nil</code> 值、内存管理；</li>
<li>Swift 的 <code>/*...*/</code> 注释可以嵌套；</li>
<li>使用 <code>do-throw-catch</code> 异常处理； <code>try?</code>
若抛出错误则返回 <code>nil</code> ， <code>try!</code>
若错误直接崩溃；</li>
<li><code>some</code> 用于声明隐式返回类型（Opaque Return Types），
<code>some Shape</code> 表示返回一个遵循 Shape
协议的对象，但不暴露具体对象；</li>
<li>Swift 提供指针类型，但不常用；</li>
<li>一些协议：
<ul>
<li>Encodable 协议确保能转成 JSON 等格式，Decodable 反之，Codable
是二者结合；</li>
<li>Hashable 协议使其能执行相等运算；</li>
<li>Identifiable 使其能被用于创建 Lists 和 ForEach（传入一个 List 和一个
trailing closure，对每个 List 元素执行闭包）；</li>
</ul></li>
<li>泛型（Generic Types）：类似 C++
的泛型；可以规定泛型服从的协议，有点类似 C++20 的 Concept；</li>
</ul>
<h2 id="swiftui">SwiftUI</h2>
<h3 id="框架">框架</h3>
<ul>
<li>SwiftUI 遵从
MVVM（Model-View-ViewModel）软件架构模式；声明式语言，用户不指定代码的具体实现；响应式更新，在被观察变量被改变后自动更新组件等状态；</li>
<li>原先的 MVC 架构：ViewController 创建 View 并将其显示，或使用
Outlet（ <code>@IBOutlet weak var myLabel: UILabel!</code> ）引用
storyboard 或 xib 界面组件，使用 Action（
<code>@IBAction func buttonClicked(_ sender: UIButton) &#123; myLabel.text = "1"; &#125;</code>
) 接收组件消息并控制组件行为；</li>
<li>MVC 架构初始默认文件：
<ul>
<li><code>AppDelegate.swift</code>
：应用代理类，用于处理应用的生命周期时间；方法有：启动前调用，进入后台后调用，进入前台前调用；</li>
<li><code>SceneDelegate.swift</code>
：用于显示和管理用户界面窗口，每个窗口对应一个 <code>UIWindows</code>
；方法有：设置初始 ViewController，场景进入后台后调用；</li>
<li><code>ViewController.swift</code>
：用于管理用户界面交互；方法有：视图初始化配置，处理用户输入与交互，管理视图生命周期（视图出现前调用，视图消失后调用）；</li>
</ul></li>
<li>MVVC：
<ul>
<li>View 负责显示组件并接收用户的交互（使用 Combine Framework）；
<ul>
<li>通过<code>@State</code>
声明视图内部（包括子视图）私有状态（不能是计算属性），一般为基本类型和结构体；</li>
<li>通过 <code>@StateObject</code>
自己创建和管理一个可观测对象（ObservableObject，往往是ViewModel）；</li>
<li>通过 <code>@ObservedObject</code>观察一个外部的遵循 ObservableObject
协议的实例；</li>
<li>通过 <code>@Published</code> 在 ObservableObject
实例中声明需要其它视图响应的变量；</li>
<li>SwiftUI 使用 <code>@State</code> 类型包装器来允许在 Struct
中修改值；使用此注解时，值被移出 struct，移入 SwiftUI
管理的共享存储中；</li>
<li>子视图 View 若想共享 <code>@State</code> 值，可以使用
<code>@Binding</code> （二者类似 <code>@StateObject</code> 与
<code>@ObservedObject</code>
的关系，一个声明一个使用）实现双向绑定，且声明子视图时在传递此值时前面加
$ 符号；</li>
</ul></li>
<li>ViewModel 充当连接 View 与 Model 的 Binder 角色；
<ul>
<li>ViewModel 的属性使用 <code>@Published</code> 标记以使 View
在这些属性改变时自动刷新；</li>
<li>ViewModel 引用 Model 并处理数据；</li>
</ul></li>
</ul></li>
</ul>
<h3 id="特性">特性</h3>
<ul>
<li><code>@Environment</code> 用于访问 SwiftUI
中由系统或其他视图提供的环境，通常为全局配置或状态，如颜色方案（亮暗模式）、字体、布局方向等。</li>
<li><code>@EnvironmentObject</code> 用于实现依赖注入，父类可以通过
<code>.environment()</code> modifier 指定子类使用
<code>@EnvironmentObject</code>
定义的可观测对象；类似传参，但会实时更新和共享（类似传指针）；</li>
<li>通过 modifier 增加定义的组件的属性和内容；自定义 View
时需要声明一个继承 View 的 struct，然后声明计算属性 body；</li>
<li>SwiftUI 使用 ViewBuilder
语法糖，通过重载静态方法等技术允许并列声明组件，更接近自然语言的效果：</li>
</ul>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyView</span>: <span class="title class_">View</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> body: <span class="keyword">some</span> <span class="type">View</span> &#123;</span><br><span class="line">        <span class="type">VStack</span> &#123;</span><br><span class="line">            <span class="type">Text</span>(<span class="string">&quot;Hello, World!&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="type">Bool</span>.random() &#123;</span><br><span class="line">                <span class="type">Text</span>(<span class="string">&quot;This is a random text!&quot;</span>) <span class="comment">// 并列声明两个 Text View，支持 if</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Desugar 后：</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">MyView</span>: <span class="title class_">View</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> body: <span class="keyword">some</span> <span class="type">View</span> &#123;</span><br><span class="line">        <span class="type">VStack</span> &#123;</span><br><span class="line">            <span class="keyword">let</span> content <span class="operator">=</span> <span class="type">ViewBuilder</span>.buildBlock(</span><br><span class="line">                <span class="type">Text</span>(<span class="string">&quot;Hello, World!&quot;</span>),</span><br><span class="line">                <span class="type">Bool</span>.random() <span class="operator">?</span> <span class="type">ViewBuilder</span>.buildBlock(<span class="type">Text</span>(<span class="string">&quot;This is a random text!&quot;</span>)) : <span class="type">ViewBuilder</span>.buildBlock(<span class="type">EmptyView</span>())</span><br><span class="line">            )</span><br><span class="line">            content</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Swift</tag>
      </tags>
  </entry>
  <entry>
    <title>圣经读书笔记</title>
    <url>/2024/10/02/%E5%9C%A3%E7%BB%8F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="概况">概况</h2>
<ul>
<li>本文为基督教圣经（the Holy Bible）笔记；</li>
<li>圣经由多部古希伯来语、亚拉姆语，通用希腊语所写书卷汇编选集而成；</li>
<li>犹太教圣经《塔纳赫》，基督教称为《旧约》，卷数认定不一致，主流认为共
39 卷（天主教和东正教版本则有 46
卷，包含了一些被称为“次经”的书卷）；塔纳赫（<strong>T</strong>a<strong>N</strong>a<strong>K</strong>h）源自三个希伯来字母
T/N/K，反映了犹太教圣经的三个部分，其中 T 代表妥拉，N 代表先知书，K
代表经录；</li>
<li>《新约》共 27 卷，记载耶稣基督及其宗徒言行；</li>
</ul>
<span id="more"></span>
<h2 id="旧约圣经old-testament">旧约圣经<strong>（Old
Testament）</strong></h2>
<h3 id="律法书摩西五经-pentateuch">律法书（摩西五经
<strong>Pentateuch</strong>）</h3>
<p>犹太教《希伯来圣经》最初五部。</p>
<p><strong>第一卷《创世纪》（Genesis）：</strong></p>
<ul>
<li><strong>上帝创世（1-2）：</strong>上帝（God，耶和华，主，独一真神）在六天内创造世界的过程。包括光、天与地、海洋与陆地、植物、日月星辰、鱼类和鸟类、陆地动物及人类。第七天，上帝休息，设立安息日。</li>
<li><strong>上帝造人（3-5）：</strong>上帝用尘土造人（<strong>亚当
Adam</strong>），并在<strong>伊甸园（Garden of
Eden）</strong>中为他设立了居所，创造了女人（夏娃
Eve）作为他的伴侣。亚当和夏娃的儿子该隐因嫉妒杀死了弟弟亚伯，开启了罪在世界中的蔓延。</li>
<li><strong>洪水毁灭（6-9）：</strong>随着人类的罪恶加剧，上帝决定用洪水毁灭世界。<strong>诺亚
Noah</strong>
因其公义，被选中建造方舟，带领家人和各种动物躲避洪水。洪水过后，上帝与诺亚立约，承诺不再用洪水毁灭世界，并以彩虹为这个约定的象征。</li>
<li><strong>巴别塔（10-11）：</strong>人类企图在示拿平原建造通天塔（<strong>巴别塔
Tower of
Babel</strong>），表达自大的愿望。上帝干预，混乱他们的语言，导致人类四散到地球各地。这一事件解释了语言的多样性。</li>
<li><strong>亚伯拉罕（12-25）：</strong>上帝呼召亚伯兰（后改名<strong>亚伯拉罕
Abraham</strong>）离开家乡，前往应许之地（<strong>迦南
Canaan</strong>）。上帝与他立约，承诺将赐给他的后裔为大国，并通过他使万族蒙福。亚伯拉罕的信心受到试炼，他被要求献祭独子以撒，最终上帝阻止了这场祭献，表彰了亚伯拉罕的信心。</li>
<li><strong>实玛利与以撒（12-25）</strong>：亚伯拉罕的两个儿子分别是以实玛利和<strong>以撒
Isaac</strong>。以实玛利是其妾夏甲所生，成为<strong>阿拉伯人</strong>的祖先，而以撒则是其妻撒拉所生，是上帝应许之子，成为<strong>以色列民族</strong>的祖先。</li>
<li><strong>雅各（25-36）：</strong>以撒娶妻利百加，生下双胞胎<strong>雅各
Jacob</strong>
和以扫。雅各通过诡计从哥哥以扫那里夺得了长子的祝福。雅各逃亡至舅舅拉班处，在那里娶了利亚和拉结，生了十二个儿子，这些儿子成为以色列十二支派的祖先。后来，雅各与上帝使者摔跤，被赐名为“<strong>以色列</strong>”。</li>
<li><strong>约瑟（37-50）：</strong>雅各最宠爱的儿子<strong>约瑟
Joseph</strong>
因受到兄弟们的嫉妒，被卖到埃及成为奴隶。在埃及，约瑟因解梦而受到法老的赏识，最终升任宰相。在饥荒期间，约瑟的兄弟们前往埃及求粮，约瑟揭示自己的身份，并宽恕了他们。最后，雅各全家移居埃及，约瑟保护并供养他们。</li>
</ul>
<p><strong>第二卷《出埃及记》（Exodus）：</strong></p>
<ul>
<li><strong>以色列人的奴役（1-2）：</strong>在约瑟去世后，埃及法老对以色列人产生了恐惧，认为他们人口增长迅速，可能威胁埃及的安全。法老因此将以色列人变为奴隶，并对他们施加繁重的劳役。</li>
<li><strong>摩西（1-2）</strong>：为了应对法老的杀婴命令，<strong>摩西
Moses</strong>
的母亲把他藏在河中，法老的女儿发现并收养了摩西。摩西在埃及的王宫中长大，但他杀死了一个虐待希伯来奴隶的埃及人后，被迫逃亡到米甸，在那里成为牧羊人。</li>
<li><strong>燃烧的荆棘（3-4）</strong>：上帝在米甸的何烈山（即西奈山）通过燃烧的荆棘向摩西显现，呼召他回到埃及，带领以色列人脱离奴役。摩西对自己的能力表示怀疑，但上帝应许会与他同在，并赐给他神迹的能力，以说服法老和以色列百姓。</li>
<li><strong>法老与十灾（5-11）：</strong>摩西回到埃及，向法老要求让以色列人离开，但法老拒绝，并加重了对以色列人的苦工。为了惩罚法老和埃及，上帝通过摩西和亚伦降下了<strong>十灾
Ten
Plagues</strong>：水变血、青蛙、虱子、苍蝇、瘟疫、疮、冰雹、蝗虫、黑暗以及最致命的第十灾——长子之死。最终，法老因第十灾失去了自己的长子，被迫同意释放以色列人。</li>
<li><strong>逾越节与出埃及（12-13）：</strong>在最后一灾（长子之死）之前，上帝命令以色列人宰杀羊羔，用血涂在门框上，以免灭命天使杀死他们的长子。此事件成为“逾越节”的起源，纪念上帝拯救以色列人。法老终于让步，允许以色列人离开埃及。摩西带领以色列人出发，开始了前往应许之地的旅程。</li>
<li><strong>红海神迹（14）：</strong>法老悔改，派遣军队追击以色列人。上帝通过摩西分开红海，让以色列人安全通过，而当埃及军队追赶时，海水复合，淹没了他们。</li>
<li><strong>旷野（15-18）：</strong>在旷野的旅程中，以色列人多次抱怨缺水、缺粮，但上帝供应他们玛哪和鹌鹑作为食物，并通过摩西为他们从磐石中取水。上帝展示了祂对他们的持续照顾。</li>
<li><strong>西奈山十诫（19-24）</strong>：以色列人在西奈山与上帝立约。上帝通过摩西向以色列人颁布了<strong>十诫
Ten Commandments</strong>
及其他律法，作为他们生活的道德和宗教指南。这些律法规定了他们作为上帝选民的义务与行为准则。摩西在山上停留四十天，接受律法，并获得了建造约柜和会幕的指示。</li>
<li><strong>背叛与赦免（32-34）：</strong>摩西在山上停留期间，百姓等候不及，要求亚伦造了一个金牛犊，作为他们的神明。摩西下山后，愤怒地摔碎了法版。摩西为百姓求情，上帝决定赦免他们，但惩罚了一部分人，并再次颁布了新的法版。摩西按照上帝的指示，开始组织以色列人建造<strong>会幕
Tabernacle</strong>，这个移动的圣所成为上帝与以色列人同在的象征。</li>
</ul>
<ol type="1">
<li><strong>除了我以外，你不可有别的神</strong> <em>You shall have no
other gods before Me.</em></li>
<li><strong>不可为自己雕刻偶像，也不可敬拜它们</strong> <em>You shall
not make for yourself a carved image, or any likeness of anything… You
shall not bow down to them or serve them.</em></li>
<li><strong>不可妄称耶和华你神的名</strong> <em>You shall not take the
name of the Lord your God in vain.</em></li>
<li><strong>当记念安息日，守为圣日</strong> <em>Remember the Sabbath
day, to keep it holy.</em></li>
<li><strong>当孝敬父母</strong> <em>Honor your father and your
mother.</em></li>
<li><strong>不可杀人</strong> <em>You shall not murder.</em></li>
<li><strong>不可奸淫</strong> <em>You shall not commit
adultery.</em></li>
<li><strong>不可偷盗</strong> <em>You shall not steal.</em></li>
<li><strong>不可作假见证陷害人</strong> <em>You shall not bear false
witness against your neighbor.</em></li>
<li><strong>不可贪恋别人的房屋、妻子、仆婢、牛驴并一切所有的</strong>
<em>You shall not covet your neighbor’s house, wife, male servant,
female servant, ox, donkey, or anything that is your
neighbor’s.</em></li>
</ol>
<p><strong>第三卷《利未记》（Leviticus）：</strong>关于上帝通过摩西向以色列人特别是祭司所颁布的律法和礼仪制度，尤其强调圣洁、祭祀、节日和敬拜的规定。</p>
<p><strong>第四卷《民数记》（Numbers）：</strong></p>
<ul>
<li>两次对以色列十二个支派的成人男性（20岁以上能上战场的人）的人口普查。</li>
<li>由于以色列人在迦南地边缘缺乏信心，害怕强大的当地居民，他们拒绝进入应许之地，违背了上帝的命令。上帝因此惩罚他们，让他们在旷野漂流40年，直到第一代出埃及的人（除了约书亚和迦勒）都死去。</li>
<li>在旷野的旅程中，以色列人不断抱怨和反叛。他们抱怨没有食物和水，上帝以吗哪（<strong>Manna</strong>）和鹌鹑供应他们。米利暗和亚伦一度质疑摩西的领导权。可拉领导了一次叛乱，最终被上帝惩罚，地裂开吞噬了叛军。</li>
<li>在一次水源危机中，上帝命令摩西用话语使磐石出水，但摩西在愤怒中击打磐石而不是按指示说话。因为这个过失，上帝告知摩西他将无法进入应许之地。</li>
<li>漂流结束后，新一代以色列人在摩押平原为进入迦南地做准备。上帝通过摩西重申律法，并指示他们如何分配应许之地的土地。迦勒和约书亚是唯一两个被允许进入应许之地的第一代探子。上帝命令他们对迦南的各族发动征战，清除外邦的偶像崇拜。</li>
<li>摩押王巴勒因惧怕以色列人的强大，召唤外邦先知巴兰来诅咒以色列。然而，在上帝的干预下，巴兰不但没能诅咒以色列，反而多次为他们祝福。以色列人在约旦河东击败了摩押人和亚摩利人，并开始分配这片土地给流便支派、迦得支派、以及玛拿西半支派。这一部分土地成为以色列应许之地的一部分。</li>
</ul>
<p><strong>第五卷《申命记》（Deuteronomy）：</strong>“申命记”意为“第二次颁布律法”，因为这卷书主要记录了摩西在以色列人即将进入应许之地之前，重申上帝的律法以及对他们的训诫和劝勉。包含了律法的复述，以及摩西对新一代以色列人的教导、警告和祝福。</p>
<h3 id="历史书">历史书</h3>
<p><strong>第六卷《约书亚记》（Joshua）：</strong>以色列人在摩西的继任者约书亚（<strong>Joshua</strong>）的领导下，进入并征服应许之地迦南；</p>
<p><strong>第七卷《士师记》（Judges）：</strong>以色列人在进入迦南地后，没有统一的王，而是由一群称为“士师”（<strong>Judges</strong>）的领袖来统治和拯救他们。该书主要记载了士师的兴起与衰落，以及以色列人在道德和宗教上的堕落。</p>
<p><strong>第八卷
《路得记》（Ruth）：</strong>讲述了一位摩押女子路得（Ruth）与以色列人之间的故事，体现了忠诚、爱情和神的救赎。该书在以色列历史中具有重要的地位，因为路得是<strong>大卫王（David）</strong>的曾祖母，也是耶稣基督的祖先之一。</p>
<p><strong>第九卷《撒母耳记上》（1
Samuel）：</strong>以色列的士师时代向君主制过渡的历史。该书围绕撒母耳、扫罗和大卫，描绘了以色列民族在信仰、领导和王权方面的重要变化。</p>
<p><strong>第十卷《撒母耳记下》（2
Samuel）：</strong>大卫在以色列王国的统治以及他所面临的挑战与成就、成功与罪行。</p>
<p><strong>第十一卷《列王纪上》（1
Kings）：所罗门王（Solomon）</strong>的统治、圣殿的建造，以及以色列王国的分裂和接下来的历史。它重点强调神的应许、王权的责任，以及信仰在以色列人生活中的重要性。</p>
<p><strong>第十二卷《列王纪下》（2
Kings）：</strong>以色列和犹大的历史，尤其是关于以色列的王国和犹大的王国的衰落。以色列王国在公元前
722 年被亚述征服，北国以色列灭亡。随后，南国犹大在公元前 586
年被巴比伦征服，<strong>耶路撒冷（Jerusalem）</strong>的圣殿被毁，百姓被掳。</p>
<p><strong>第十三卷《历代志上》（1
Chronicles）：</strong>记录了以色列的历史，特别是大卫王（King
David）的统治。</p>
<p><strong>第十四卷《历代志下》（2
Chronicles）：</strong>记录了犹大王国的历史，以强调神在犹大历史中的作为与圣殿崇拜的重要性。</p>
<p><strong>第十五卷《以斯拉记》（Ezra）：</strong>记录了以色列人在巴比伦被掳之后返回故土和重建耶路撒冷及圣殿的过程。</p>
<p><strong>第十六卷《尼希米记》（Nehemiah）</strong>：记录了尼希米作为一位领导者，在波斯帝国的支持下，带领以色列人重建耶路撒冷的城墙和恢复民族的宗教和社会生活。</p>
<p><strong>第十七卷《以斯帖记》（Esther）：</strong>讲述了犹太女子以斯帖在波斯帝国中的故事，以及她如何拯救自己的民族免于灭绝。</p>
<h3 id="智慧文学诗歌书">智慧文学（诗歌书）</h3>
<p><strong>第十八卷《约伯记》（Job）：</strong>讲述了一位义人约伯在遭遇<strong>撒旦
Satan</strong> 挑战时的信仰考验与思考。</p>
<p><strong>第十九卷《诗篇》（Psalms）：</strong>包含了一系列的赞美诗、祷告和抒情诗。</p>
<p><strong>第二十卷《箴言》（Proverbs）：</strong>主要包含智慧的教导和生活的箴言，大部分是所罗门所写。</p>
<p><strong>第二十一卷《传道书》（Ecclesiastes）：</strong>所罗门所写的一部智慧文学，探讨人生的意义和存在的目的。</p>
<p><strong>第二十二卷《雅歌》（Song of Solomon 或 Song of
Songs）：</strong>所罗门的作品之一，以诗歌的形式表达了爱与美，通常被解读为人类情感、爱情的颂歌，也被视为对神与以色列之间关系的隐喻。</p>
<h3 id="大先知书">大先知书</h3>
<p><strong>第二十三卷《以赛亚书》（Isaiah）：</strong>内容涉及预言、审判和救赎，包含了许多关于以色列的历史、神的公义以及对未来弥赛亚的预言。</p>
<p><strong>第二十四卷《耶利米书》（Jeremiah）：</strong>此书记录了耶利米在犹大王国的历史背景下，向以色列百姓传达的神的警告、审判与希望的信息。</p>
<p><strong>第二十五卷《耶利米哀歌》（Lamentations）：</strong>由五篇诗歌组成，主要表达了对耶路撒冷毁灭后的悲痛与哀悼。</p>
<p><strong>第二十六卷《以西结书》（Ezekiel）：</strong>探讨了神的审判、以色列的复兴以及对未来的希望。</p>
<p><strong>第二十七卷《但以理书》（Daniel）：</strong>涉及信仰、忠诚、异教文化的抵抗以及未来的神秘预言。</p>
<h3 id="小先知书">小先知书</h3>
<p><strong>第二十八卷《何西阿书》（Hosea）：</strong>先知何西阿生活在以色列北国的最后时期，见证了国家的衰落和即将到来的审判。</p>
<p><strong>第二十九卷《约珥书》（Joel）：</strong>先知约珥生活在以色列南国的时期，主题与神的审判和救赎密切相关。</p>
<p><strong>第三十卷《阿摩司书》（Amos）：</strong>先知阿摩司是来自犹大国的牧羊人和栽培无花果的农夫，活跃在以色列北国的时期。</p>
<p><strong>第三十一卷《俄巴底亚书》（Obadiah）：</strong>对以东国的审判。</p>
<p><strong>第三十二卷《约拿书》（Jonah）：</strong>记载了先知约拿与神的互动及其向尼尼微传道的经历。</p>
<p><strong>第三十三卷《弥迦书》（Micah）：</strong>对以色列和犹大的审判，对未来复兴和弥赛亚的预言。</p>
<p><strong>第三十四卷《那鸿书》（Nahum）：</strong>对亚述帝国的审判，对其首都尼尼微的预言。</p>
<p><strong>第三十五卷《哈巴谷书》（Habakkuk）：</strong>讨论了哈巴谷对神的质疑和神的回应，探讨了信仰、正义与神的计划。</p>
<p><strong>第三十六卷《西番雅书》（Zephaniah）：</strong>即将来临的审判、神的愤怒以及对悔改者的应许。</p>
<p><strong>第三十七卷《哈该书》（Haggai）：</strong>耶路撒冷重建圣殿的任务，时间背景是在以色列民被掳归回后，公元前520年左右。</p>
<p><strong>第三十八卷《撒迦利亚书》（Zechariah）：</strong>围绕以色列的复兴、重建和未来的希望，特别是在以色列人从巴比伦被掳回归后，时间背景大约在公元前520年至公元前518年之间。</p>
<p><strong>第三十九卷《马拉基书》（Malachi）：</strong>主要针对以色列人，特别是在他们从巴比伦被掳归回后重建圣殿和恢复信仰的背景下。</p>
<h2 id="新约圣经new-testament">新约圣经<strong>（New
Testament）</strong></h2>
<h3 id="四福音书">四福音书</h3>
<p><strong>第一卷《马太福音》（Gospel of Matthew）：</strong></p>
<p>所以，你们要去使万民作我的门徒，给他们施洗，奉父、子、圣灵的名，教导他们遵守我所吩咐你们的一切；我就常与你们同在，直到世界的末了。</p>
<p><em>Go therefore and make disciples of all nations, baptizing them in
the name of the Father and of the Son and of the Holy Spirit, teaching
them to observe all that I have commanded you. And behold, I am with you
always, to the end of the age.</em></p>
<ul>
<li><strong>降生：</strong>耶稣是亚伯拉罕和大卫的后裔。天使向<strong>玛利亚
Mary</strong> 显现，告知她将以<strong>圣灵 (Holy Spirit)</strong>
的能力怀孕，生下<strong>耶稣</strong>
(Jesus)。耶稣的名字意为“拯救”，表示他将拯救他的百姓脱离罪恶。</li>
<li><strong>洗礼与试探：</strong>耶稣在约旦河接受<strong>施洗约翰 (John
the Baptist)</strong>
的洗礼，洗礼象征悔改和归向神。在洗礼后，耶稣被圣灵引导到旷野，在那里经历了四十天的<strong>禁食</strong>和魔鬼的试探。在这段时间，魔鬼试图用食物、权力和奇迹来诱惑耶稣，但耶稣凭着神的话战胜了这些试探。</li>
<li><strong>山上宝训：</strong>耶稣开始传道并教导众人，他在山上发表了的山上宝训。在这个教导中，耶稣阐述了八福（<strong>Beatitudes</strong>）。他教导关于<strong>愤怒</strong>
(Anger)、<strong>婚姻</strong> (Marriage)、<strong>祷告</strong>
(Prayer) 和<strong>施舍</strong> (Giving)
的重要性，强调内心的动机和真正的义。</li>
<li><strong>神迹与教导：</strong>耶稣通过许多神迹 (Miracles)
来验证他的权威，包括治愈病人、使瘫子行走、让盲人复明、赶鬼等。这些神迹显示了他的慈爱与能力，同时也吸引了大量的跟随者。耶稣还通过<strong>比喻</strong>
(Parables) 教导众人，如“撒种的比喻”和“失落的羊”，传达天国的真理。</li>
<li><strong>争论
：</strong>耶稣与法利赛人和文士之间的紧张关系逐渐加剧。他们批评耶稣的教导和行为，耶稣则指责他们的虚伪和对律法的误解。耶稣在这些争论中明确表明自己是主的子，并强调对人的真正需求。</li>
<li><strong>受难：</strong>随着耶稣的影响力增加，宗教领袖们策划了对他的捕捉和审判。耶稣在客西马尼园中祷告，面对即将到来的痛苦与死，心中极为痛苦。在审判中，彼拉多不愿意判决耶稣，但最终还是将他钉在十字架上，成为人类的赎罪祭。</li>
<li><strong>复活与大使命：</strong>耶稣在死后第三天复活，向门徒显现，证实了他胜过死亡的能力。复活后，耶稣给了门徒大使命，命令他们去使万民作他的门徒，施洗并教导他们遵守所有的诫命。</li>
</ul>
<p><strong>八福（Beatitudes）：</strong></p>
<p>虚心的人有福了，因为天国是他们的。<em>Blessed are the poor in spirit,
for theirs is the kingdom of heaven.</em></p>
<p>哀恸的人有福了，因为他们必得安慰。<em>Blessed are those who mourn,
for they shall be comforted.</em></p>
<p>温柔的人有福了，因为他们必承受地土。<em>Blessed are the meek, for
they shall inherit the earth.</em></p>
<p>饥渴慕义的人有福了，因为他们必得饱足。<em>Blessed are those who
hunger and thirst for righteousness, for they shall be
satisfied.</em></p>
<p>怜恤人的人有福了，因为他们必蒙怜恤。<em>Blessed are the merciful, for
they shall receive mercy.</em></p>
<p>心里清洁的人有福了，因为他们必得见神。<em>Blessed are the pure in
heart, for they shall see God.</em></p>
<p>使人和睦的人有福了，因为他们必称为神的儿子。<em>Blessed are the
peacemakers, for they shall be called sons of God.</em></p>
<p>为义受逼迫的人有福了，因为天国是他们的。<em>Blessed are those who are
persecuted for righteousness’ sake, for theirs is the kingdom of
heaven.</em></p>
<p>第二卷《马可福音》（Gospel of Mark）</p>
<p>第三卷《路加福音》 (Gospel of Luke)</p>
<p>第四卷《约翰福音》 (Gospel of John)</p>
<ul>
<li><strong>最后的晚餐</strong>: 在最后的晚餐（The Last
Supper）上，耶稣预言犹大的背叛，指出“你所做的，快去做吧”（John
13:27）。</li>
</ul>
<p>四卷均为不同角度的见证；其中马太与约翰为耶稣十二门徒，马可和路加晚一代；</p>
<h3 id="使徒行传">使徒行传</h3>
<p><strong>第五卷《使徒行传》（The Acts of the
Apostles）：</strong>路加所作，记录了耶稣升天后的早期教会的历史，以及使徒们的事工和传播基督教的经历。包含：耶稣的升天与圣灵的降临、早期教会的生活、彼得与约翰的事工、使徒们的扩展事工 、使徒的神迹与逼迫等。</p>
<h3 id="保罗书信">保罗书信</h3>
<p>保罗书信涵盖了多封由使徒保罗写给不同教会或个人的信件。</p>
<p>第六卷《罗马书》（Romans）</p>
<p>第七卷《哥林多前书》（1 Corinthians）《哥林多后书》（2
Corinthians）</p>
<p>第八卷《哥林多后书》（2 Corinthians）</p>
<p>第九卷《加拉太书》（Galatians）</p>
<p>第十卷《以弗所书》（Ephesians）</p>
<p>第十一卷 《腓立比书》（Philippians）</p>
<p>第十二卷《歌罗西书》（Colossians）</p>
<p>第十三卷《帖撒罗尼迦前书》（1 Thessalonians）</p>
<p>第十四卷《帖撒罗尼迦后书》（2 Thessalonians）</p>
<p>第十五卷《提摩太前书》（1 Timothy）</p>
<p>第十六卷《提摩太后书》（2 Timothy）</p>
<p>第十七卷《提多书》（Titus）</p>
<p>第十八卷《腓利门书》（Philemon）</p>
<h3 id="大公书信">大公书信</h3>
<p>致大公教会书信（Catholic
Epistles），又名公函、普通书信、一般书信或其他书信（General
Epistles），指新约书信中的八卷作者非保罗的书信。</p>
<p>第十九卷《希伯来书》（Hebrews）</p>
<p>第二十卷《雅各书》（<strong>James</strong>）</p>
<p>第二十一卷《彼得前书》（1 Peter）</p>
<p>第二十二卷《彼得后书》（2 Peter）</p>
<p>第二十三卷《约翰一书》（1 John）</p>
<p>第二十四卷《约翰二书》（2 John）</p>
<p>第二十五卷《约翰三书》（3 John）</p>
<p>第二十六卷《犹大书》（Jude）</p>
<h3 id="启示录">启示录</h3>
<p><strong>第二十七卷启示录（Revelation）：</strong>由使徒约翰在拔摩岛上接收到的异象所记录，预示着末日的审判和基督的最终胜利。</p>
<p><strong>第1章：启示的引言与基督的显现：</strong>约翰自述在拔摩岛上，因着圣灵的感动，他看见了复活的基督并被命令将异象写下，传给小亚细亚的七个教会。基督被描绘为庄严的“人子”，以七星和七金灯台的象征形象出现。</p>
<p><strong>第2章：致七个教会的书信（第一部分）：</strong>约翰记录了基督写给以弗所、士每拿、别迦摩和推雅推喇四个教会的书信。每封信都包括对教会的表扬、批评、劝告，以及给得胜者的应许。例如，以弗所教会被赞扬为勤劳有忍耐，但失去了起初的爱心。</p>
<p><strong>第3章：致七个教会的书信（第二部分）：</strong>继续给撒狄、非拉铁非和老底嘉教会的书信。撒狄教会被批评为“名义上活着，实际上是死的”，老底嘉教会则因灵性上的冷漠被严厉斥责，但基督也为这些教会提供了悔改的机会。</p>
<p><strong>第4章：天上的敬拜：</strong>约翰在异象中看见了天上的宝座和围绕宝座的敬拜。天使和二十四位长老赞美神为创造者，天上的敬拜场景象征了神的全能和圣洁。</p>
<p><strong>第5章：揭开卷轴的羔羊：</strong>约翰看见一个书卷被神握在手中，书卷上有七个封印。没有人能揭开它，唯有“羔羊”——象征基督，因祂曾被杀而复活，配得揭开封印。天上众生向羔羊献上赞美，表明基督的救赎和权柄。</p>
<p><strong>第6章：揭开前六印：</strong>基督开始揭开卷轴上的七印。前四印引发了四位骑马者，分别象征征服、战争、饥荒和死亡。第五印显示了殉道者在天上呼求正义，第六印则引发了剧烈的地震、天体的变化和宇宙的灾难。</p>
<p><strong>第7章：封印选民与天上众生的敬拜：</strong>在揭开第七印之前，约翰看见了十四万四千以色列人被封印，象征神在大灾难中对选民的保护。然后约翰看见了大批从各国、各族、各方而来的群众，他们在天上敬拜神和羔羊，庆祝得救的荣耀。</p>
<p><strong>第8章：第七印与七号的准备：</strong>当第七印被揭开时，天上沉默了约半小时。接着七位天使准备吹响号角，每个号角都会带来新的审判。四个号吹响，导致了灾难性的自然现象，海洋、河流、天体都遭到了破坏。</p>
<p><strong>第9章：第五和第六号的灾祸：</strong>第五号释放了从无底坑中出来的蝗虫，它们折磨不信者。第六号释放了四位天使和他们的军队，杀死了三分之一的人类，然而幸存者仍然不悔改。</p>
<p><strong>第10章：天使与小书卷：</strong>约翰见到一位大能的天使手持小书卷，并听到天上的七雷发声。他被命令吃下小书卷，这卷书在口中甜美，但在肚子里发苦，象征神的话语既带来希望也带来审判。</p>
<p><strong>第11章：两位见证人和第七号：</strong>约翰看见了两位神的见证人在地上传道，并且因其忠心殉道，但他们复活升天。随后，第七号被吹响，天上宣告神的国度已经来临，基督即将统治全地。</p>
<p><strong>第12章：天上的妇人和龙：</strong>约翰见到了一个天上伟大的异象：一位妇人生下一个男孩，象征基督，而大红龙（撒但）试图吞吃孩子。妇人代表神的子民，龙被击败并从天上被驱逐，随后他开始迫害妇人的其他子孙。</p>
<p><strong>第13章：两只兽：</strong>约翰看到海中上来的兽象征政治的力量，代表敌基督者，它受龙的权柄并逼迫信徒。另有一只从地上来的兽，象征宗教的欺骗，它强迫所有人敬拜第一只兽，并且要求所有人接受“兽的印记”。</p>
<p><strong>第14章：羔羊与收割：</strong>约翰看到羔羊和十四万四千站在锡安山，随后出现了三位天使宣布神的审判。接着是地上的收割，象征神对义人和恶人的最后审判。</p>
<p><strong>第15章：七碗灾难的准备：</strong>约翰看到天上敬拜的场景，准备倒下七碗神的愤怒。七位天使拿着七碗，他们将要把最后的灾难倾倒在地上。</p>
<p><strong>第16章：七碗的灾难：</strong>七碗依次倒下，带来巨大的灾难，包括恶疮、海水变血、河水变血、烈日灼人、黑暗笼罩兽的国度、幼发拉底河干涸、以及空中的巨大地震。尽管灾难临到，世人仍然不悔改。<strong>第17章：大淫妇与兽：</strong>约翰见到了骑在兽上的大淫妇，象征世界性的邪恶和腐败，她与各国君王通奸。兽最终将反过来毁灭淫妇，象征世界的权势最终摧毁自己。</p>
<p><strong>第18章：巴比伦的沦陷：</strong>约翰看到大城巴比伦的毁灭，象征世界的罪恶和物质主义的崩溃。商人和国王因失去财富而哀悼，但天上为她的覆灭而欢喜。</p>
<p><strong>第19章：基督的再临：</strong>天上赞美神为巴比伦的审判。随后，约翰见到基督骑着白马降临，祂是忠信和真实的审判者，祂战胜了兽和其军队，敌基督和假先知被扔进了火湖。</p>
<p><strong>第20章：千禧年与最后的审判：</strong>撒但被捆绑一千年，基督和祂的圣徒在地上掌权。在千年结束后，撒但再次被释放，发动最后的叛乱，但被彻底击败。随后发生白色大宝座的审判，所有死人复活，接受他们的审判，凡名字未记在“生命册”上的人被扔进火湖。</p>
<p><strong>第21章：新天新地：</strong>约翰看到新天新地的到来，神与祂的百姓永远同住，痛苦、死亡、眼泪不再存在。新耶路撒冷从天而降，象征神的荣耀与祂子民的完美居所。</p>
<p><strong>第22章：生命的河与最后的劝勉：</strong>约翰看到生命的河和生命树，它们象征神永远的生命和福祉。基督宣告“看哪，我必快来！”。</p>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDA 编程笔记</title>
    <url>/2023/12/06/CUDA-%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>更新：</p>
<p><em>本文章部分内容（如硬件参数）已过时或有错误，请批判式阅读。</em></p>
<p>参考：</p>
<p><a
href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/contents.html">CUDA
C++ Programming Guide</a>；</p>
<p>《CUDA 编程：基础与实践》</p>
<p>《GPGPU 异构高性能计算》</p>
<h2 id="gpu-介绍">GPU 介绍</h2>
<ul>
<li>一个典型的 GPU 参数，以 NVIDIA H100 GPU 为例：
<ul>
<li>16896 FP32 CUDA cores；</li>
<li>66.9 TFLOPS (FP64 Tensor core)；</li>
<li>33.5 TFLOPS (FP64)；</li>
<li>3352 GB/s memory bandwidth；</li>
<li>700W TDP；</li>
<li>TSMC’s 4N customized for NVIDIA；</li>
</ul></li>
</ul>
<span id="more"></span>
<ul>
<li><p>GPU vs CPU：</p>
<p><img src="0.png" /></p></li>
<li><p>GPU 微体系结构层次（硬件层面）：</p>
<ul>
<li>其中 SM 为 Streaming MultiProcessor，SP 为 Streaming Processor；一个
GPU 通常有数百个 SM，每个 SM 有数百个 SP；</li>
</ul></li>
</ul>
<p><img src="1.png" /></p>
<p><img src="2.png" /></p>
<ul>
<li>GPU 程序层次（软件层面）：
<ul>
<li>一个程序 kernel 由多个 block 组成，一个 block 由多个 thread
组成；</li>
<li>数个 block 分配（映射）到一个 SM 中（block 与 SM 同等大小，某一时刻
SM 中仅存放一个 block）；</li>
<li>数个 thread 与一个 SP 对应（某一时刻 SP 中仅负责一个
thread），目前一个 block 中最多包含 1024 个 thread；</li>
<li>同一个 block 中编号相邻的 32 个 thread 组成一个
warp，被调度器集体调度，<em>通常</em>对程序员透明；</li>
</ul></li>
</ul>
<p><img src="3.png" /></p>
<p><img src="4.png" /></p>
<h2 id="cuda-入门">CUDA 入门</h2>
<ul>
<li>CUDA = Compute Unified Device Architecture，统一计算设备架构，由
NVIDIA 提出的通用并行计算平台和编程模型；Use parallelization to hide the
latency；</li>
<li>直接使用 <code>nvcc</code> 代替 <code>g++</code>
即可编译（需要后缀名为 .cu），Host Code 将调用 Host C
Compiler/Linker，Device Code 调用 Device Just-In-Time Compiler；</li>
<li>区分：SPMD 编程模型（CUDA、MPI、OpenMP），SIMD 编程模型（Intel
MMX、SSE、AVX）；</li>
<li>SPMD 是 GPU 的编程模型，SIMT 是 GPU 的执行方式，SIMD 是 GPU
计算单元的处理方式；</li>
<li>一个并行函数是一个 kernel，使用
<code>&lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt;</code> 指定 thread
数目与排布；</li>
<li>host 代表本机，device 代表并行计算设备（GPU）：
<ul>
<li>host 调用 device 执行，函数加上前缀
<code>__global__</code>（必须返回 <code>void</code>）；</li>
<li>host 调用 host 执行，函数加上前缀 <code>__host__</code> ；</li>
<li>device 调用 device 执行，函数加上前缀 <code>__device__</code>
，可以与 <code>__host__</code> 同时使用，但不能与
<code>__global__</code> 同时使用；</li>
</ul></li>
<li>内存布局：
<ul>
<li>每个 thread 有自己的寄存器和 local memory；</li>
<li>同一个 block 中的 thread 可以通过 shared memory 共享数据，速度类似
L1 Cache；</li>
<li>所有 thread 可以通过 global memory 共享数据；</li>
<li>另外还有只读的 texture memory 和 constant memory；</li>
<li>同一个 block 中 thread 可以通过 <code>__syncthreads()</code>
进行路障（Barrier）同步；</li>
</ul></li>
</ul>
<p><img src="5.png" /></p>
<ul>
<li>内存操作：
<ul>
<li>使用 <code>cudaMalloc((void**)&amp;addr, n * sizeof(float))</code>
在 device 的 global memory 中分配空间，其中 addr 为 <code>float*</code>
；</li>
<li>使用 <code>cudaFree(addr)</code> 释放空间；</li>
<li>使用
<code>cudaMemcpy(h_addr, d_addr, size, cudaMemcpyDeviceToHost)</code>
实现 device 与 host 之间的内存拷贝；参数可选
<code>cudaMemcpyHostToHost</code>、 <code>cudaMemcpyHostToDevice</code>
、 <code>cudaMemcpyDeviceToHost</code> 、
<code>cudaMemcpyDeviceToDevice</code> 、 <code>cudaMemcpyDefault</code>
，不符合实际情况将导致错误；</li>
<li>可以使用 <code>cudaMemcpyToSymbol()</code> 和
<code>cudaMemcpyToSymbol()</code>
在设备与设备静态内存区（定义在核函数之外，使用 <code>__device__</code>
前缀）之间交换数据，而不使用参数传递；</li>
<li>均返回一个 <code>cudaError_t</code> ，成功时值为
<code>cudaSuccess</code> ；</li>
</ul></li>
<li>核函数中可以使用的变量： <code>gridDim.x</code>、
<code>blockDim.x</code> 、 <code>blockIdx.x</code>、
<code>threadIdx.x</code> ；可以使用 <code>dim3 grid_size(3, 3)</code> 或
<code>dim3 grid_size(1, 2, 3)</code> 定义成二维或三维，此时可以使用相应
y 或 z；</li>
<li>变量声明默认在 register 中，放不下则在 local memory
中，生命周期与访问性均为 thread；加上 <code>__shared__</code> 、
<code>__device__</code> 、 <code>__constant__</code> 分别分配到 shared
memory（生命周期和访问性为 block）、global memory、constant memory
上；</li>
</ul>
<h2 id="cuda-进阶">CUDA 进阶</h2>
<ul>
<li>Memory Coalescing：一次性将同一时刻一个 warp
要访问的内存全部取出；因为这个技术，CPU 的 SIMD
往往一个线程处理的数据是相邻的，而 GPU 中往往不相邻，GPU
中相邻线程处理相邻数据；</li>
<li>一个共享内存被分为 32 个 bank，与内建变量 warpSize
值相等；同一线程束内多个线程不同时访问同一个 bank
中不同层的数据，则只需要一次内存事务（memory transaction）；</li>
<li>原子操作： <code>AtomicAdd(&amp;a, b)</code> ；</li>
<li>CUDA 在 host 使用固定内存（调用特殊系统 API，保证不会换出，
<code>cudaMemcpy()</code> 速度快一倍，不可过度使用），可以使用
<code>cudaHostAlloc(&amp;data, size, cudaHostAllocDefault)</code> 或
<code>cudaMallocHost(&amp;data, size)</code> 和
<code>cudaFreeHost(data)</code> 操作，与 <code>cudaMemcpyAsync()</code>
配合，才能达到异步数据传输效果；</li>
<li>默认流中 host 与 device 的运算是并行的（因此需要核函数结果时应执行
<code>cudaDeviceSynchronize()</code>
；使用非默认流实现多个核函数并行，以及核函数与数据传递的并行（良好设计下，流越多，并行度越高，直到达到硬件资源上限）：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cudaStream_t stream0, stream1;</span><br><span class="line"><span class="built_in">cudaStreamCreate</span>(&amp;stream0);</span><br><span class="line"><span class="built_in">cudaStreamCreate</span>(&amp;stream1);</span><br><span class="line"><span class="built_in">cudaMemcpyAsync</span>(d_A0, hA + i, SegSize * <span class="built_in">sizeof</span>(<span class="type">float</span>), stream1); <span class="comment">// 注意需要 Async，且不在同一个流</span></span><br><span class="line">vecAdd&lt;&lt;&lt;SegSize/<span class="number">256</span>, <span class="number">256</span>, <span class="number">0</span>, stream0&gt;&gt;&gt;(d_A0, d_B0);</span><br><span class="line"><span class="built_in">cudaStreamQuery</span>(stream0) <span class="comment">// 用于非阻塞地查询是否全部执行完毕</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cudaStreamSynchonize</span>(stream0); <span class="comment">// 或 cudaDeviceSynchronize(); 等待 device 所有流任务完成</span></span><br><span class="line"><span class="built_in">cudaStreamDestroy</span>(stream0);</span><br></pre></td></tr></table></figure>
<ul>
<li>进行非合并<em>只读</em>读取（即不连续只读读取）global memory
时，会自动使用 <code>__ldg()</code> 进行优化；</li>
<li>统一内存编程：CPU 与 GPU 均可访问，使用
<code>cudaMallocManaged(&amp;data, size, flags = cudaMemAttachGlobal)</code>
分配， <code>cudaFree()</code>
释放；静态统一内存：在核函数外定义，加上前缀
<code>__device__ __managed__</code> ；</li>
<li>统一内存数据预取 API：
<code>cudaMemPrefetchAsync(data, N * sizeof(int), myGpuId, stream)</code>
；</li>
<li>统一内存建议 API：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cudaMemAdvise</span>(data, N * <span class="built_in">sizeof</span>(<span class="type">int</span>), cudamemadvisesetreadmost, cudaCpuDeviceId);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 可用内存提示与取消：</span></span><br><span class="line">cudamemadvisesetreadmost / cudamemadviseunsetreadmost</span><br><span class="line">cudaMemAdviseSetPreferredLocation / cudaMemAdviseUnsetPreferredLocation</span><br><span class="line">cudaMemAdviceSetAccessedBy / cudaMemAdviceUnsetAccessedBy</span><br></pre></td></tr></table></figure>
<ul>
<li>若分支能写成 <code>c = flag ? a : b</code> 或
<code>if (condition) &#123;...&#125;</code> 的形式，则并行性良好，否则
<code>then</code> 与 <code>else</code> 的线程之间为串行执行；</li>
</ul>
<h2 id="cuda-并行计算模式">CUDA 并行计算模式</h2>
<ul>
<li>Tile 模式：每次从 global memory 中加载一段到 shared memory，使用
barrier synchronization 进行线程开始与结束同步，再进入下一个
Tile；以矩阵乘法为例，每个 block
负责结果矩阵中的一个子矩阵，每次将计算这个子矩阵需要的部分数据（两个乘数矩阵分别取一块）载入并计算（每个
thread 负责结果子矩阵的一格），下一个 Tile
再取下一批计算此结果子矩阵的部分数据，最后再累加得到最终此结果子矩阵；具体编码较为繁琐；</li>
<li>Convolution 卷积模式：正常计算，注意处理边界即可；可以使用
Tile；</li>
<li>Histogram 直方图模式： <code>for i bin[arr[i]]++;</code>
问题，加速技巧：
<ul>
<li>block_size 设为与 SM 内线程数相等，注意 coalescing；</li>
<li>shared memory 中做 Atomic 操作速度很快，但 global memory
中很慢；</li>
<li>胖内核、contiguous unrolling：循环展开；</li>
</ul></li>
<li>Reduction 规约模式：类 Map Reduce，使用规约树以 log(n) 步执行
Max、Min、Sum、Product 等满足交换结合律的运算；每次循环开始均需要
<code>__syncthreads()</code> ；</li>
<li>Scan 前缀和模式：每次迭代
<code>stride *= 2; a[i] += a[i - stride];</code>，需要
<code>__syncthreads()</code> ；更优秀的做法：使用树状数组；</li>
</ul>
<h2 id="其它">其它</h2>
<ul>
<li><code>gridDim</code>
要足够，通常上取整，因此可能出现最后超出范围的情况，需要判断；</li>
<li>尽量使用 shared memory，最后返回结果时再使用 global memory；</li>
<li>注意栅栏同步函数 <code>__syncthreads()</code> 仅能进行同一 block 中
threads 的同步；</li>
<li>一些常用 CUDA 库（应尽量使用）：
<ul>
<li>Thrust：类似 C++ STL；</li>
<li>cuBLAS：线性代数；</li>
<li>cuFFT：快速傅里叶变换；</li>
<li>cuSPARSE：稀疏矩阵；</li>
<li>cuRAND：随机数生成器；</li>
<li>cuSolver：稠密矩阵与稀疏矩阵；</li>
<li>cuDNN：深度神经网络；</li>
</ul></li>
<li>使用 cuda-gdb 调试，nvprof（nsight compute） 测速，nsight system
分析硬件资源占用情况；</li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>并行计算</tag>
      </tags>
  </entry>
  <entry>
    <title>Rust 笔记</title>
    <url>/2023/11/20/Rust-%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p><strong>参考</strong>：</p>
<p><em>《Rust Primer》</em></p>
<p><em>《Rust 编程之道》</em></p>
<p><em>《Rust Course》（Rust 语言圣经）</em></p>
<p>THU<em>《程序设计训练（Rust）》</em>课件</p>
<ul>
<li>裸指针（不安全）： <code>*const T</code> 和 <code>*mut T</code>
；</li>
<li>单字节字符 <code>b'H'</code> ，单字节字符串 <code>b'Hello'</code>
，仅限 ASCII 字符； <code>r#"..."#</code> 表示不转义字符串；</li>
<li><code>String</code> → <code>&amp;str</code>
很廉价，而反之涉及分配内存，代价相对更高；</li>
<li>即使结构体是公有的，成员仍然默认私有；枚举如果是公有的则其成员均为公有；</li>
<li>可以在 <code>match</code> 中通过 <code>ref</code> 和
<code>ref mut</code> 获取对应变量的引用；</li>
<li><code>try!</code> 宏在 <code>Ok</code> 时提取内部值，否则直接
<code>return</code> 期望返回的 Error 类型；现在可以直接使用
<code>?</code> ；</li>
<li>使用 <code>io::stdin.read_line(&amp;mut String)</code> 读入；</li>
<li>Rust 项目结构：</li>
</ul>
<span id="more"></span>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">Project/</span><br><span class="line">|-- cargo.toml</span><br><span class="line">|-- cargo.lock</span><br><span class="line">|-- src/</span><br><span class="line">|-- |-- main.rs</span><br><span class="line">|-- |-- lib.rs</span><br><span class="line">|-- |-- bin/</span><br><span class="line">|-- tests/</span><br><span class="line">|-- examples/</span><br></pre></td></tr></table></figure>
<ul>
<li><code>for (i, j) in (5..10).enumerate()</code> 使 <code>i</code>
为循环次数下标；</li>
<li>使用 <code>#derive[(...)]</code> 为类型自动添加一些 trait，常用：
<code>Clone</code> ， <code>Copy</code> ， <code>Debug</code> ，
<code>Default</code> ， <code>Eq</code> ， <code>PartiaEq</code> ，
<code>Ord</code> ， <code>PartialOrd</code> ， <code>Hash</code> ；</li>
<li><code>Eq</code> trait 表示任意两个值要么 <code>==</code> 要么
<code>!=</code> ，它不包含方法，仅用作标记； <code>PartialEq</code>
提供部分等价关系，包含一个 <code>eq</code> 方法；实现了 <code>Eq</code>
的必然实现了 <code>PartialEq</code> ； <code>&lt;</code> 、
<code>&gt;</code> 、 <code>&gt;=</code> 、 <code>&lt;=</code> 实现的是
<code>PartialOrd</code> ； <code>PartialEq</code> 满足对称性与传递性，
<code>Eq</code> 还满足自反性；</li>
<li>所有硬编码字符串均为 <code>&amp;'static str</code> ；</li>
<li><code>+</code> 、 <code>-</code> 、 <code>*</code> 、 <code>/</code>
、 <code>%</code> 分别实现在 <code>std::ops::Add/Sub/Mul/Div/Rem</code>
； <code>&amp;</code> 、 <code>|</code> 、 <code>^</code> 、
<code>&lt;&lt;</code> 、 <code>&gt;&gt;</code> 分别实现在
<code>std::ops::BitAnd/BitOr/BitXor/Shl/Shr</code>；</li>
<li>函数参数支持模式匹配：
<code>fn print_age((_, age): (&amp;str, i32));</code> ；</li>
<li>发散函数（Diverging function）不返回值，返回值处使用 <code>!</code>
；</li>
<li>trait 可以继承： <code>trait Son : Parent</code> ，之后实现
<code>Son</code> 的类型也要实现 <code>Parent</code> ；</li>
<li><code>Copy</code> trait 继承 <code>Clone</code> trait：
<code>pub trait Copy: Clone;</code> ；</li>
<li>Rust 为 <code>Vec</code> 、 <code>HashMap</code> 实现了
<code>IntoIterator</code> trait，从而支持直接 <code>for a in vec</code>
循环；无限迭代器： <code>let inf_seq = (1..).into_iter();</code> ；
<code>Vec</code> 、 <code>HashMap</code> 实现了
<code>FromIterator</code> trait，以支持 <code>(1..10).collect()</code>
等操作；</li>
<li><code>fold</code> 和 <code>reduce</code> 的区别：后者带初始值；取前
n 个：
<code>let v_take = v.iter().cloned().take(2).collect::&lt;Vec&lt;_&gt;&gt;();</code>
， <code>skip(n)</code> 跳过前 n 个；</li>
<li>Prelude 的一部分：</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">std::marker::&#123;<span class="built_in">Copy</span>, <span class="built_in">Send</span>, <span class="built_in">Sized</span>, <span class="built_in">Sync</span>&#125;</span><br><span class="line">std::ops::&#123;<span class="built_in">Drop</span>, <span class="built_in">Fn</span>, <span class="built_in">FnMut</span>, <span class="built_in">FnOnce</span>&#125;</span><br><span class="line">std::mem::drop</span><br><span class="line">std::boxed::<span class="type">Box</span></span><br><span class="line">std::borrow::<span class="built_in">ToOwned</span></span><br><span class="line">std::clone::<span class="built_in">Clone</span></span><br><span class="line">std::cmp::&#123;<span class="built_in">PartialEq</span>, <span class="built_in">PartialOrd</span>, <span class="built_in">Eq</span>, <span class="built_in">Ord</span>&#125;</span><br><span class="line">std::convert::&#123;<span class="built_in">AsRef</span>, <span class="built_in">AsMut</span>, <span class="built_in">Into</span>, <span class="built_in">From</span>&#125;</span><br><span class="line">std::default::<span class="built_in">Default</span></span><br><span class="line">std::iter::&#123;<span class="built_in">Iterator</span>, <span class="built_in">Extend</span>, <span class="built_in">IntoIterator</span>, <span class="built_in">DoubleEndedIterator</span>, <span class="built_in">ExactSizeIterator</span>&#125;</span><br><span class="line">std::option::<span class="type">Option</span>::&#123;<span class="keyword">self</span>, <span class="literal">Some</span>, <span class="literal">None</span>&#125;</span><br><span class="line">std::result::<span class="type">Result</span>::&#123;<span class="keyword">self</span>, <span class="literal">Ok</span>, <span class="literal">Err</span>&#125;</span><br><span class="line">std::slice::<span class="built_in">SliceConcatExt</span></span><br><span class="line">std::string::&#123;<span class="type">String</span>, <span class="built_in">ToString</span>&#125;</span><br><span class="line">std::vec::<span class="type">Vec</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>Into/From</code> trait 分别实现了 <code>U::from(T)</code> 和
<code>U::into(T)</code> ，会消耗所有权；实现了 <code>From</code>
会自动实现 <code>Into</code> ； <code>TryFrom</code> 和
<code>TryInto</code> 返回 <code>Result</code> ；同样还有
<code>ToString</code> 和 <code>FromStr</code> ；</li>
<li><code>AsRef&lt;U&gt;</code> 实现了将 <code>T</code> 类型对象
<code>a</code> 通过 <code>a.as_ref()</code> 得到 <code>&amp;U</code>
，不消耗所有权； <code>AsMut</code> 同理；</li>
<li>实现了 <code>Deref&lt;Target=U&gt;</code> 的类型 <code>T</code>
可以通过 <code>&amp;T</code> 传参给 <code>&amp;U</code>
；调用函数时，Rust 会提供任意多层自动解引用；</li>
<li>不可以使用 <code>i32/i64</code> 作为下标，需要 <code>as usize</code>
；</li>
<li>不同于 C++，Rust 的块注释 <code>/* */</code> 可以嵌套；</li>
<li>变量有引用存在时，不能移交其绑定数据的所有权；</li>
<li>结构体有域级的访问控制，但没有域级的可变性控制，因此可以对内部变量标记
<code>pub</code> 而不能标记 <code>mut</code>
；结构体的域访问控制是针对模块而非结构体本身的，即其私有成员可以被同模块的其它函数访问；</li>
<li>使用 <code>s.chars().nth(i)</code> 访问 <code>String</code> ；</li>
<li>常用 <code>Option&lt;T&gt;</code> 相关函数：</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">unwrap</span>&lt;T&gt;(<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> T &#123;</span><br><span class="line">	<span class="keyword">match</span> <span class="keyword">self</span> &#123;</span><br><span class="line">		<span class="literal">None</span> =&gt; <span class="built_in">panic!</span>(<span class="string">&quot;Called `Option::unwrap()` on a `None` value&quot;</span>),</span><br><span class="line">		<span class="title function_ invoke__">Some</span>(value) =&gt; value,</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">map</span>&lt;U, F&gt;(<span class="keyword">self</span>, f: F) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;U&gt;</span><br><span class="line">		<span class="keyword">where</span> F: <span class="title function_ invoke__">FnOnce</span>(T) <span class="punctuation">-&gt;</span> U &#123;</span><br><span class="line">	<span class="keyword">match</span> <span class="keyword">self</span> &#123;</span><br><span class="line">		<span class="literal">None</span> =&gt; <span class="literal">None</span>,</span><br><span class="line">		<span class="title function_ invoke__">Some</span>(x) =&gt; <span class="title function_ invoke__">Some</span>(<span class="title function_ invoke__">f</span>(x))</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">and_then</span>&lt;U, F&gt;(<span class="keyword">self</span>, f: F) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;U&gt;</span><br><span class="line">		<span class="keyword">where</span> F: <span class="title function_ invoke__">FnOnce</span>(T) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;U&gt; &#123;</span><br><span class="line">	<span class="keyword">match</span> <span class="keyword">self</span> &#123;</span><br><span class="line">		<span class="title function_ invoke__">Some</span>(x) =&gt; <span class="title function_ invoke__">f</span>(x),</span><br><span class="line">		<span class="literal">None</span> =&gt; <span class="literal">None</span>,</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T&gt; <span class="type">Option</span>&lt;T&gt; &#123;</span><br><span class="line">	<span class="keyword">fn</span> <span class="title function_">unwrap_or</span>&lt;T&gt;(<span class="keyword">self</span>, default: T) <span class="punctuation">-&gt;</span> T &#123;</span><br><span class="line">		<span class="keyword">match</span> <span class="keyword">self</span> &#123;</span><br><span class="line">			<span class="literal">None</span> =&gt; default,</span><br><span class="line">			<span class="title function_ invoke__">Some</span>(value) =&gt; value,</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T&gt; <span class="type">Option</span>&lt;T&gt; &#123;</span><br><span class="line">	<span class="keyword">fn</span> <span class="title function_">unwrap_or_else</span>&lt;T&gt;(<span class="keyword">self</span>, f: F) <span class="punctuation">-&gt;</span> T</span><br><span class="line">			<span class="keyword">where</span> F: <span class="title function_ invoke__">FnOnce</span>() <span class="punctuation">-&gt;</span> T &#123;</span><br><span class="line">		<span class="keyword">match</span> <span class="keyword">self</span> &#123;</span><br><span class="line">			<span class="literal">None</span> =&gt; <span class="title function_ invoke__">f</span>(),</span><br><span class="line">			<span class="title function_ invoke__">Some</span>(value) =&gt; value,</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">is_some</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">bool</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">is_none</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">bool</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">map_or</span>&lt;U, F&gt;(<span class="keyword">self</span>, default: U, f: F) <span class="punctuation">-&gt;</span> U <span class="comment">// U 类型的默认值</span></span><br><span class="line">		<span class="keyword">where</span> F: <span class="title function_ invoke__">FnOnce</span>(T) <span class="punctuation">-&gt;</span> U</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">map_or_else</span>&lt;U, D, F&gt;(<span class="keyword">self</span>, default: D, f: F) <span class="punctuation">-&gt;</span> U <span class="comment">// D 类型的闭包用于计算默认值</span></span><br><span class="line">		<span class="keyword">where</span> D: <span class="title function_ invoke__">FnOnce</span>() <span class="punctuation">-&gt;</span> U, F: <span class="title function_ invoke__">FnOnce</span>(T) <span class="punctuation">-&gt;</span> U</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">ok_or</span>(<span class="keyword">self</span>, err: E) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;T, E&gt;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">ok_or_else</span>(<span class="keyword">self</span>, default: F) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;T, E&gt; <span class="comment">// 与 unwrap_or 相似，用于错误处理。</span></span><br><span class="line">		<span class="keyword">where</span> F: <span class="title function_ invoke__">FnOnce</span>() <span class="punctuation">-&gt;</span> E</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">and</span>&lt;U&gt;(<span class="keyword">self</span>, optb: <span class="type">Option</span>&lt;U&gt;) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;U&gt; <span class="comment">// 如果 self 是 None，则返回 None，否则返回 optb。</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">or</span>(<span class="keyword">self</span>, optb: <span class="type">Option</span>&lt;T&gt;) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;T&gt; <span class="comment">// 如果 self 是 Some(_)，则返回 self，否则返回 optb。</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">xor</span>(<span class="keyword">self</span>, optb: <span class="type">Option</span>&lt;T&gt;) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;T&gt; <span class="comment">// 如果 self 和 optb 恰好有一个是 Some(_)，则返回这个 Some，否则返回 None。</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Rust 提供的容器： <code>Vec&lt;T&gt;</code> ，
<code>VecDeque&lt;T&gt;</code> ， <code>LinkedList&lt;T&gt;</code> ，
<code>HashMap&lt;K, V&gt;</code> ， <code>BTreeMap&lt;K, V&gt;</code> ，
<code>HashSet&lt;T&gt;</code> ， <code>BTreeSet&lt;T&gt;</code> ，
<code>BinaryHeap&lt;T&gt;</code> ；</li>
<li>Rust
的线程发生恐慌，和创建此线程的线程无关，其它线程能读取恐慌线程的信息；</li>
<li>所有不带内部可变性的类型和只包含 Sync 类型的复合类型会自动获得
Sync；</li>
<li>为一个结构体实现 <code>Hash</code> trait，会将 <code>name</code> 和
<code>age</code> 传播给一个实现了 Hasher
的对象的可变引用（state）中，state 将它们组合后算出对应哈希值：</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">Hash</span> <span class="keyword">for</span> <span class="title class_">Person</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">hash</span>&lt;H: Hasher&gt;(&amp;<span class="keyword">self</span>, state: &amp;<span class="keyword">mut</span> H) &#123;</span><br><span class="line">        <span class="keyword">self</span>.name.<span class="title function_ invoke__">hash</span>(state);</span><br><span class="line">        <span class="keyword">self</span>.age.<span class="title function_ invoke__">hash</span>(state);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>有时需要用大括号制造一个新域来使用某变量可变引用，从而不妨碍之后再获得某变量的其它引用；</li>
<li><code>for line in &amp;texts</code> 是
<code>for line in texts.iter()</code> 的语法糖；</li>
<li>Trait 对象隐式具有 <code>'static</code>
生命周期，但当闭包捕获的变量具有更短生命周期时，闭包生命周期也随之缩小；</li>
<li>编译器只考虑被调用函数的签名而不会深入函数体，因此改变函数实现而不改变签名不会影响编译结果；</li>
<li>迭代器的 <code>clone()</code>
仅拷贝一个栈上的引用，因此非常高效；</li>
<li>枚举成员占用的内存空间大小跟最大的成员对齐；</li>
<li><code>borrow</code> 得到的是 <code>Ref</code>
类型，其生命周期与调用者（可能是引用）的生命周期相同；它通过
<code>Deref</code> 实现和 <code>&amp;T</code>
相同效果的自动解引用；</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">borrow</span>&lt;<span class="symbol">&#x27;a</span>&gt;(&amp;<span class="symbol">&#x27;a</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> Ref&lt;<span class="symbol">&#x27;a</span>, T&gt;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">borrow_mut</span>&lt;<span class="symbol">&#x27;a</span>&gt;(&amp;<span class="symbol">&#x27;a</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> RefMut&lt;<span class="symbol">&#x27;a</span>, T&gt;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title>Pine 源码阅读笔记</title>
    <url>/2023/11/20/Pine-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Pine 是一个使用 C++17 编写的高并发框架，支持 Linux / MacOS
跨平台；它也是 <a
href="https://github.com/yuesong-feng/30dayMakeCppServer/tree/main">30
天自制 C++ 服务器</a>（目前更至第十六天）的配套代码。</p>
<p>本文为 <a href="https://github.com/yuesong-feng/pine">Github 源码</a>
阅读笔记。</p>
<p>前置技能：</p>
<ul>
<li>Modern C++ （包括并行库）；</li>
<li>网络编程基础
<ul>
<li><strong>《Linux 高性能服务器编程》——
游双</strong>：服务器编程必读；</li>
<li><strong>《Linux 多线程服务端编程：使用 muduo C++ 网络库》——
陈硕</strong>：经典网络库 muduo 作者，本框架采用类 muduo 架构；</li>
<li><strong>《C++ 服务器开发精髓》——
张远龙</strong>：类似以上两本书的组合，编写年份较新，对部分技术做了相应更新；</li>
<li><strong>《UNIX网络编程卷1：套接字联网API》、《UNIX网络编程卷2：进程间通信》</strong>：可以作为字典书；</li>
</ul></li>
</ul>
<span id="more"></span>
<h2 id="框架介绍">框架介绍</h2>
<ul>
<li>程序采用类 muduo 结构，one loop per thread，多 Reactor
多线程模式，支持同步 / 异步 Socket I/O（仅代表 Socket
无操作时是否立即返回，本质均为同步 IO，均在应用进程中占用 CPU
时间）；常使用 ET + 非阻塞 Socket IO 模式；</li>
<li>Server 是核心类，持有
main-Reactor、sub-Reactors、Acceptor、Connection、线程池；</li>
<li>Socket 为 socket 底层操作的封装，Poller 为对一系列 fd 及其 epoll
相关操作的封装（对每个管理的 fd 持有其对应的 Channel），Channel
为对每个文件描述符的具体操作的封装；Buffer 为 I/O 缓冲区的封装；</li>
<li>每个事件循环 EventLoop 与一个 Poller 对应，支持随时增删需要管理的
fd；</li>
<li>main-Reactor 对应 Acceptor，在主线程中执行；</li>
<li>每个 Connection 维护一个连接，随机将其分配给一个 sub-Reactor
持有的事件循环；</li>
<li>每个 Reactor 即一个事件循环；线程池中每个线程对应一个
sub-Reactor，从有锁任务队列中取出一个 task；每个 task
与一个事件循环对应；</li>
<li>可能存在某时刻一个线程恰好完成了它的事件循环维护的所有连接，也没有再给它分配新的连接；此时它可以再从有锁任务队列中取一个
task；但由于目前设计为一个线程对应一个
task，因此实际上它会立即返回；</li>
<li>任务、事件循环、Reactor、线程、Poller 在此框架中一一对应；</li>
</ul>
<h2 id="各模块分析">各模块分析</h2>
<h3 id="socket">Socket</h3>
<ul>
<li>直接持有一个文件描述符 fd；</li>
<li>支持设置 fd，获取 addr，设置 Socket I/O
阻塞模式，获取缓冲区中可读取字节数，socket()、bind()、listen()、accept()、connect()
的函数封装；</li>
</ul>
<h3 id="channel">Channel</h3>
<ul>
<li>直接持有
fd，监听事件功能二进制状态，准备事件功能二进制状态，是否存在，由
Acceptor 与 Connection
指定的读回调、写回调；以裸指针形式指向其所在事件循环；</li>
<li>支持对直接持有的成员进行设置；根据准备事件二进制状态执行对应回调；</li>
</ul>
<h3 id="poller">Poller</h3>
<ul>
<li>直接持有一个 fd 和一个 epoll_event 指针（Linux）或一个 kevent
指针（MacOS）；</li>
<li>支持创建 epoll，拉取 epoll 并相应设置 Channel
二进制状态（返回有更新的 Channel 序列），根据 Channel
注册、删除事件（同时删除 Channel）；</li>
</ul>
<h3 id="buffer">Buffer</h3>
<ul>
<li>直接持有一个 <code>std::string</code>
缓冲区，封装了对它的赋值、取长度、清空操作；</li>
</ul>
<h3 id="eventloop">EventLoop</h3>
<ul>
<li>以 <code>unique_ptr</code> 形式持有一个 Poller；</li>
<li>支持无限循环地执行 epoll 中有更新的各个 Channel
的回调，以及更新与删除某个 Channel；</li>
</ul>
<h3 id="threadpool">ThreadPool</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ThreadPool.h</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ThreadPool</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">DISALLOW_COPY_AND_MOVE</span>(ThreadPool);</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ThreadPool</span><span class="params">(<span class="type">unsigned</span> <span class="type">int</span> size = std::thread::hardware_concurrency())</span></span>;</span><br><span class="line">  ~<span class="built_in">ThreadPool</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">F</span>, <span class="keyword">class</span>... Args&gt;</span><br><span class="line">  <span class="function"><span class="keyword">auto</span> <span class="title">Add</span><span class="params">(F &amp;&amp;f, Args &amp;&amp;...args)</span> -&gt; std::future&lt;<span class="keyword">typename</span> std::invoke_result&lt;F, Args...&gt;::type&gt;</span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  std::vector&lt;std::thread&gt; workers_; <span class="comment">// 每个 worker 持有一个 lambda 函数，循环处理每个 task，某一时刻发现队列空则返回</span></span><br><span class="line">  std::queue&lt;std::function&lt;<span class="type">void</span>()&gt;&gt; tasks_; <span class="comment">// 每个 task 持有一个 package_task，在 worker 中的循环中被调用</span></span><br><span class="line">  std::mutex queue_mtx_; <span class="comment">// 对 task 队列的互斥锁</span></span><br><span class="line">  std::condition_variable queue_cv_; <span class="comment">// 对 task 队列的条件变量</span></span><br><span class="line">  std::atomic&lt;<span class="type">bool</span>&gt; stop_&#123;<span class="literal">false</span>&#125;; <span class="comment">// 是否停止该线程池运行，析构时直接设为 true 并逐个 worker 调用 join()</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 不能放在cpp文件，C++编译器不支持模版的分离编译</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">F</span>, <span class="keyword">class</span>... Args&gt;</span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">ThreadPool::Add</span><span class="params">(F &amp;&amp;f, Args &amp;&amp;...args)</span> -&gt; std::future&lt;<span class="keyword">typename</span> std::invoke_result&lt;F, Args...&gt;::type&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">using</span> return_type = <span class="keyword">typename</span> std::invoke_result&lt;F, Args...&gt;::type;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> task = std::make_shared&lt;std::packaged_task&lt;<span class="built_in">return_type</span>()&gt;&gt;(std::<span class="built_in">bind</span>(std::forward&lt;F&gt;(f), std::forward&lt;Args&gt;(args)...));</span><br><span class="line"></span><br><span class="line">  std::future&lt;return_type&gt; res = task-&gt;<span class="built_in">get_future</span>();</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(queue_mtx_)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// don&#x27;t allow enqueueing after stopping the pool</span></span><br><span class="line">    <span class="keyword">if</span> (stop_) &#123;</span><br><span class="line">      <span class="keyword">throw</span> std::<span class="built_in">runtime_error</span>(<span class="string">&quot;enqueue on stopped ThreadPool&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tasks_.<span class="built_in">emplace</span>([task]()&#123; (*task)(); &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">  queue_cv_.<span class="built_in">notify_one</span>();</span><br><span class="line">  <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ThreadPool.cpp</span></span><br><span class="line">ThreadPool::<span class="built_in">ThreadPool</span>(<span class="type">unsigned</span> <span class="type">int</span> size) &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">unsigned</span> <span class="type">int</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">    workers_.<span class="built_in">emplace_back</span>([<span class="keyword">this</span>]() &#123;</span><br><span class="line">      <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        std::function&lt;<span class="built_in">void</span>()&gt; task;</span><br><span class="line">        &#123;</span><br><span class="line">          std::unique_lock&lt;std::mutex&gt; <span class="built_in">lock</span>(queue_mtx_);</span><br><span class="line">          queue_cv_.<span class="built_in">wait</span>(lock, [<span class="keyword">this</span>]() &#123; <span class="keyword">return</span> stop_ || !tasks_.<span class="built_in">empty</span>(); &#125;);</span><br><span class="line">          <span class="keyword">if</span> (stop_ &amp;&amp; tasks_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          task = std::<span class="built_in">move</span>(tasks_.<span class="built_in">front</span>());</span><br><span class="line">          tasks_.<span class="built_in">pop</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">task</span>();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ThreadPool::~<span class="built_in">ThreadPool</span>() &#123;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(queue_mtx_)</span></span>;</span><br><span class="line">    stop_ = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  queue_cv_.<span class="built_in">notify_all</span>();</span><br><span class="line">  <span class="keyword">for</span> (std::thread &amp;th : workers_) &#123;</span><br><span class="line">    <span class="keyword">if</span> (th.<span class="built_in">joinable</span>()) &#123;</span><br><span class="line">      th.<span class="built_in">join</span>();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="acceptor">Acceptor</h3>
<ul>
<li>每个 Acceptor 以 <code>unique_ptr</code> 形式持有一个 Socket 和一个
Channel 用于管理监听端口行为，直接持有一个由 Server 指定的连接回调
new_connection_callback()；</li>
<li>构造时，构造一个新的 Socket 绑定到固定端口 127.0.0.1:1234
并开启监听，并为其构造一个对应 Channel，将自己的连接函数
AcceptConnection()（包含接受客户端连接操作和
new_connection_callback()）设为 Channel 的读回调；</li>
</ul>
<h3 id="connection">Connection</h3>
<ul>
<li>每个 Connection 以 <code>unique_ptr</code> 形式持有一个 Socket
和一个 Channel，以 <code>unique_ptr</code>
形式持有读缓冲和写缓冲；直接持有由 Server 指定的一个 delete_connection()
回调和一个 on_recv()
回调；持有一个状态：非法、连接中、已连接、已关闭四个之一；</li>
<li>构造时新建一个 Channel 并将 Server 指定的 fd 与 EventLoop 指定给新
Channel，开启 ET 读；</li>
<li>支持阻塞 / 非阻塞连接读 / 写；</li>
</ul>
<h3 id="tcpserver">TcpServer</h3>
<ul>
<li>以 <code>unique_ptr</code> 形式持有一个 main-Reactor（即
EventLoop）、多个 sub-Reactors、一个 Acceptor、一个 ThreadPool；</li>
<li>直接持有一个 map&lt;int,
unique_ptr<Connection>&gt;，以及由程序员指定的 on_connect() 与 on_recv()
回调；</li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title>Modern C++（11~26）笔记</title>
    <url>/2023/11/20/Modern-C-%EF%BC%8811-26%EF%BC%89%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="堆栈raii容器">堆、栈、RAII、容器</h2>
<ul>
<li><code>delete</code> 一个空指针是合法的，但不能多次
<code>delete</code>；</li>
<li>手写智能指针：先实现一个
<code>auto_ptr</code>（赋值为移动语义），再定义引用计数类；每个智能指针类包含两个类的指针：引用技术类和对象类；</li>
<li>异常安全的赋值函数：复制并交换；</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">T&amp; <span class="keyword">operator</span>= (T rhs) &#123;</span><br><span class="line">	rhs.<span class="built_in">swap</span>(*<span class="keyword">this</span>);</span><br><span class="line">	<span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>vector</code> 保证强异常安全性，如果没有 <code>noexcept</code>
的移动构造函数，会调用拷贝构造函数；</li>
<li><code>queue</code> 和 <code>stack</code>
依赖现有容器，因此称为容器适配器，默认均为 <code>deque</code>
实现；</li>
<li><code>less</code> 和 <code>greater</code> 均为通过重载同名结构体的
<code>bool operator() (const T&amp; x, const T&amp; y)</code>
得到的函数对象；它们继承的 <code>binary_function</code> 和
<code>unary_function</code> 已在 C++11 被废弃；</li>
</ul>
<span id="more"></span>
<h2 id="右值引用和移动语义">右值引用和移动语义</h2>
<ul>
<li>生命周期延长：若一个 prvalue
被绑定到一个引用上，其生命周期会被延长至引用变量的生命周期；</li>
<li>C++11 后的移动语义使
<code>string str = string("Hello") + name + "."</code> 这样的语句调用
<code>operator+(const string&amp;&amp;, const string&amp; / const char*)</code>
从而减少了拷贝次数；</li>
<li>实现五个特殊成员函数时应尽量带上 <code>noexcept</code> ；</li>
<li>右值引用类型的变量本身是左值；</li>
<li>返回值优化
NRVO：在一些简单条件下会直接在栈上构造对象，从而减少拷贝次数；</li>
<li><strong>xvalue</strong>
是一个可以被移动的值，并且与某个存储位置关联（如通过
<code>std::move</code> 生成的已命名对象）；<strong>prvalue</strong>
是一个纯粹的值，不与任何存储位置关联（如一个整数字面值或一个计算的结果）；<strong>glvalue
(generalized lvalue)</strong> 包括 lvalue 和
xvalue；<strong>rvalue</strong>: 包括 xvalue 和 prvalue。</li>
<li><code>decltype&lt;auto&gt;</code> 推导规则：
<ul>
<li><em>prvalue</em>（例如临时变量）推导出 <em>type</em>；</li>
<li><em>lvalue</em>（例如有名字的对象）推导出 <em>type&amp;</em>；</li>
<li><em>xvalue</em>（例如用 std::move()标记的对象）推导出
<em>type&amp;&amp;</em>；</li>
</ul></li>
</ul>
<h2 id="异常">异常</h2>
<ul>
<li>声明了 <code>noexcept</code> 的函数抛出异常会直接导致
<code>std::terminate</code> ；</li>
<li>特殊成员函数若内部调用的函数均为 <code>noexcept</code> ，则本身也为
<code>noexcept</code> ；</li>
<li>异常安全的四个等级：
<ul>
<li>无异常安全：抛出异常会进入未定义状态；</li>
<li>基本异常安全：抛出异常保证处于一致状态，但不保证保持原始状态（有副作用）；</li>
<li>强异常安全：抛出异常将回滚；</li>
<li>不抛异常安全：不抛异常；</li>
</ul></li>
</ul>
<h2 id="其它">其它</h2>
<ul>
<li>一个迭代器必然支持 <code>++</code> 和 <code>*</code> ，若支持
<code>*</code> 输出则为输出迭代器；若支持 <code>*</code>
读取则为输入迭代器，再可反复读取则为前向迭代器，再支持 <code>--</code>
则为双向迭代器，再支持跳跃和比较则为随机访问迭代器，若还保证对象在内存连续存放则为连续迭代器（C++20）；</li>
<li>C++11 会尽量使用移动返回对象，C++17
允许返回不可拷贝、不可移动的对象：直接构造于目标位置；新标准之后，应尽量使用返回值而非参数返回对象；</li>
<li>C++11 引入了 <code>char16_t</code> 和 <code>char32_t</code>
，分别代表 UTF-16 和 UTF-32；C++20 引入了用于存储 UTF-8 的
<code>char8_t</code> ；</li>
</ul>
<h2 id="自动类型推断字面量静态断言">自动类型推断、字面量、静态断言</h2>
<ul>
<li>C++17 之后 <code>array</code> 可以不带 <code>&lt;int, 3&gt;</code>
而使用自动推断了；也允许使用
<code>auto [lower, upper] = Map.equal_range("four");</code></li>
<li>C++11 允许使用大括号初始化列表在成员变量定义时默认初始化；</li>
<li>C++11 允许使用 <code>operator ""</code>
定义下划线开头的字面量；</li>
<li>C++14 支持 <code>0b</code> 表示二进制字面量，支持在数字中添加
<code>'</code> 使其更可读；</li>
<li>C++11 提供静态断言
<code>static_assert(condition, output_info)</code>
，可以直接在类定义中使用；</li>
</ul>
<h2 id="编译期多态泛型编程与模板">编译期多态、泛型编程与模板</h2>
<ul>
<li>模板元编程提供图灵完备的类型推导；</li>
<li>使用静态成员变量储存 value， <code>typedef</code> 储存 type；</li>
<li>使用替换失败非错（SFINAE）和 <code>enable_if</code>
实现条件编译；</li>
<li><code>declval&lt;T&gt;</code> 为类型 T
创建一个假设的右值引用，而不实际构造该类型的对象；它只有声明因此只能用于编译时上下文；</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// integral_constant</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>, T v&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">integral_constant</span> &#123;</span><br><span class="line">    <span class="type">static</span> <span class="keyword">constexpr</span> T value = v;</span><br><span class="line">    <span class="keyword">typedef</span> T value_type;</span><br><span class="line">    <span class="keyword">typedef</span> integral_constant type;</span><br><span class="line">    <span class="function"><span class="keyword">constexpr</span> <span class="keyword">operator</span> <span class="title">value_type</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">noexcept</span> </span>&#123; <span class="keyword">return</span> value; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">constexpr</span> value_type <span class="title">operator</span><span class="params">()</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">noexcept</span> </span>&#123; <span class="keyword">return</span> value; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> std::integral_constant&lt;<span class="type">bool</span>, <span class="literal">true</span>&gt; true_type;</span><br><span class="line"><span class="keyword">typedef</span> std::integral_constant&lt;<span class="type">bool</span>, <span class="literal">false</span>&gt; false_type;</span><br><span class="line"></span><br><span class="line"><span class="comment">// enable_if：仅当 B 为 true 时拥有 type；</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="type">bool</span> B, <span class="keyword">class</span> <span class="title class_">T</span> = <span class="type">void</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> enable_if &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">enable_if</span>&lt;<span class="literal">true</span>, T&gt; &#123; <span class="keyword">typedef</span> T type; &#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// IsIntegral</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> Enable = <span class="type">void</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> IsIntegral : std::false_type &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">IsIntegral</span>&lt;T, std::<span class="type">enable_if_t</span>&lt;std::is_integral&lt;T&gt;::value&gt;&gt; : std::true_type &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> = <span class="keyword">typename</span> std::enable_if&lt;std::is_integral&lt;T&gt;::value&gt;::type&gt;</span><br><span class="line"><span class="type">void</span> <span class="built_in">foo_integral</span>(T value) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> = <span class="keyword">typename</span> std::enable_if&lt;!std::is_integral&lt;T&gt;::value&gt;::type&gt;</span><br><span class="line"><span class="type">void</span> <span class="built_in">foo_not_integral</span>(T value) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// has_reserve</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> = <span class="type">void</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> has_reserve : std::false_type &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">has_reserve</span>&lt;T, <span class="keyword">typename</span> std::enable_if&lt;<span class="literal">true</span>, <span class="keyword">decltype</span>(std::<span class="built_in">declval</span>&lt;T&gt;().<span class="built_in">reserve</span>(<span class="number">1</span>))&gt;::type&gt;</span><br><span class="line">        : std::true_type &#123;&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="函数式编程可变模板和-tuple-的编译期技巧">函数式编程、可变模板和
<code>**tuple**</code> 的编译期技巧</h2>
<ul>
<li><code>[this]</code> 按引用捕获外围对象， <code>[*this]</code>
按值捕获，调用拷贝（C++17）；</li>
<li>lambda 表达式可以取代 <code>bind</code>；</li>
<li>Map 在 C++ 中对应 <code>transform</code> ，Reduce 在 C++ 中对应
<code>accumulate</code> （C++17 已有 <code>reduce()</code>
，要求归并操作的交换律和结合律，Filter 在 C++ 中对应
<code>copy_if</code> 和 <code>partition</code> ；</li>
<li>实现 Compose：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span>... Args&gt;</span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">compose</span><span class="params">(F f, Args... other)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> [f, other...](<span class="keyword">auto</span>&amp;&amp;... x) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="built_in">f</span>(<span class="built_in">compose</span>(other...)(forward&lt;<span class="keyword">decltype</span>(x)&gt;(x)...));</span><br><span class="line">	&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>简化版 <code>std::integer_sequence</code> 和
<code>index_sequence</code> （C++14）：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>, T... Ints&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">integer_sequence</span> &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">size_t</span>... Ints&gt;</span><br><span class="line"><span class="keyword">using</span> index_sequence = integer_sequence&lt;<span class="type">size_t</span>, Ints...&gt;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">size_t</span> N, <span class="type">size_t</span>... Ints&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">index_sequence_helper</span> &#123;</span><br><span class="line">	<span class="keyword">typedef</span> <span class="keyword">typename</span> index_sequence_helper&lt; N - <span class="number">1</span>, N - <span class="number">1</span>, Ints...&gt;::type type;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">size_t</span>... Ints&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">index_sequence_helper</span>&lt;<span class="number">0</span>, Ints...&gt; &#123;</span><br><span class="line">	<span class="keyword">typedef</span> index_sequence&lt;Ints...&gt; type;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">size_t</span> N&gt;</span><br><span class="line"><span class="keyword">using</span> make_index_sequence = <span class="keyword">typename</span> index_sequence_helper&lt;N&gt;::type;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">F</span>, <span class="keyword">class</span> <span class="title class_">Tuple</span>, <span class="type">size_t</span>... I&gt;</span><br><span class="line"><span class="function"><span class="keyword">constexpr</span> <span class="keyword">decltype</span>(<span class="keyword">auto</span>) <span class="title">apply_impl</span><span class="params">(F&amp;&amp; f, Tuple&amp;&amp; t, index_sequence&lt;I...&gt;)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">f</span>(<span class="built_in">get</span>&lt;I&gt;(forward&lt;Tuple&gt;(t))...);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">F</span>, <span class="keyword">class</span> <span class="title class_">Tuple</span>&gt;</span><br><span class="line"><span class="function"><span class="keyword">constexpr</span> <span class="keyword">decltype</span>(<span class="keyword">auto</span>) <span class="title">apply</span><span class="params">(F&amp;&amp; f, Tuple&amp;&amp; t)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">apply_impl</span>(forward&lt;F&gt;(f), forward&lt;Tuple&gt;(t),</span><br><span class="line">		make_index_sequence&lt;tuple_size_v&lt;<span class="type">remove_reference_t</span>&lt;Tuple&gt;&gt;&gt;&#123;&#125;</span><br><span class="line">	);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="c14-新特性">C++14 新特性</h2>
<p><a
href="https://github.com/AnthonyCalandra/modern-cpp-features#user-defined-literals-for-standard-library-types">C++11，14，17，20
特性总结（英文）</a></p>
<ul>
<li>放宽 <code>constexpr</code> 限制；</li>
<li>支持变量模板（ <code>constexpr T pi = T(3.14)</code>
）、别名模板（泛型关联：给模板定义类型起别名）与变参模板（参数个数可变）；</li>
<li>支持 <code>auto</code> 参数的泛型 lambda、lambda 初始化捕获；</li>
<li>支持返回类型推导、 <code>decltype&lt;auto&gt;</code> ；</li>
<li>聚合初始化（用初始化列表初始化结构体）、 <code>make_unique()</code>
；</li>
<li>二进制字面量 <code>0b110</code> 、整型字面量分隔符
<code>12'345</code>；</li>
<li>透明比较扩展：支持 <code>std::set</code> 和 <code>std::map</code>
两个比较数不是同一类型，从而可以用 <code>const char*</code> 查找
<code>std::set&lt;std::string&gt;</code> ；</li>
<li><code>std::shared_timed_mutex</code> 与
<code>std::shared_lock</code> 等；</li>
<li><code>[[deprecated]]</code> 、 <code>std::get</code> 获取元组元素、
使用移动语义的<code>std::exchange</code> ；</li>
</ul>
<h2 id="c17-新特性">C++17 新特性</h2>
<p><a
href="https://github.com/0voice/cpp_new_features/blob/main/%E6%80%BB%E7%BB%93%E5%BD%92%E7%BA%B3%EF%BC%9AC%2B%2B17%E6%96%B0%E7%89%B9%E6%80%A7.md">C++17
特性总结</a></p>
<ul>
<li>结构化绑定
<ul>
<li>可以使用 <code>auto [u, v] = myStruct</code> 、
<code>auto [u, v] &#123;myStruct&#125;</code> 或
<code>auto [u, v] (myStruct)</code> 解构对象；也可以用在
<code>for (const auto&amp; [key, val] : myMap)</code> 中；</li>
<li>本质上是匿名本地拷贝了 <code>myStruct</code> （假设为 <code>e</code>
）， <code>u</code> 和 <code>v</code> 分别是 <code>e</code>
的成员，若使用 <code>auto&amp;</code> ，则 <code>e</code>
为原对象引用，即修饰符并非作用于 <code>u</code> 和 <code>v</code>
；</li>
<li>结构化绑定同样也适用于原生数组、 <code>std::array</code> 、
<code>std::pair</code> 和 <code>std::tuple</code>
不会产生类型退化；</li>
</ul></li>
<li>属性
<ul>
<li><code>[[nodiscard]]</code>
：鼓励编译期在返回值未被使用时给警告；</li>
<li><code>[[maybe_unused]]</code>
：避免编译期在返回值未被使用时给警告；</li>
<li><code>[[fallthrough]]</code> ：避免编译期在 <code>switch</code>
语句某个标签缺少 <code>break</code> 时给警告；</li>
<li><code>[[deprecated]]</code> ：弃用；</li>
</ul></li>
<li>带初始化的 <code>if</code> 和 <code>switch</code> 语句：类似
<code>for</code> ，可以使用 <code>auto</code>
，定义变量仅在此语句中有效；</li>
<li>在头文件中使用 <code>inline static</code> <em>定义</em>
全局变量（必须直接初始化，且必须是字面类型）；现在
<code>static constexpr</code> 修饰符隐含 <code>inline</code> ；</li>
<li>聚合体可以拥有基类；C++17 中数组和满足一定条件的 <em>类类型</em>（
<code>class</code> 、 <code>struct</code> 、 <code>union</code>
）均被认为是 <em>聚合体</em>；</li>
<li>强制省略拷贝或传递未实质化（从 <em>prvalue</em> 转化为
<em>xvalue</em>）的对象：比具名返回值优化（NRVO）更强，可以在
<code>delete</code> 禁止拷贝和移动函数的情况下工作；</li>
<li>进一步放宽 lambda 和 <code>constexpr</code> 范围，支持
<code>constexpr</code> lambda；</li>
<li>嵌套命名空间；</li>
<li>解决了部分表达式求值顺序无保证的问题；</li>
<li>C++17 之后直接初始化 <code>auto a&#123;42&#125;</code> 会得到 <code>int</code>
，拷贝初始化 <code>auto a = &#123;42&#125;</code> 会得到
<code>initializer_list</code> ；</li>
<li><code>u8'6'</code> 表示 UTF-8 字符字面量；</li>
<li>异常声明将作为函数类型的一部分；</li>
<li>自动类模板参数推导；支持 <code>std::pair p(a, b)</code> 而不需
<code>make_pair</code> ；</li>
<li>使用编译期 <code>if</code> 语句 <code>if constexpr(...)</code>
在编译期决定生成 <code>then</code> 还是 <code>else</code> 的代码；</li>
<li>折叠表达式：有一些处理空参数包的规则；</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> (... + args);</span><br><span class="line"><span class="keyword">return</span> (args + ... + <span class="number">0</span>);</span><br><span class="line">(..., <span class="built_in">foo</span>(forward&lt;T&gt;args));</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> Node* <span class="title">traverse</span><span class="params">(T np, TP... paths)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> (np ‐&gt;* ... ‐&gt;* paths); <span class="comment">// np ‐&gt;* paths1 ‐&gt;* paths2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>对模板能力的进一步扩展，可以使用 <code>auto</code> 和
<code>decltype&lt;auto&gt;</code> 作模板参数；</li>
<li>类型擦出容器和代数数据类型：
<ul>
<li><code>std::optional&lt;T&gt;</code> 在空时为
<code>std::nullopt</code> ；</li>
<li><code>std::variant&lt;int, double, std::string&gt;</code> ，更安全的
<code>union</code> ；</li>
<li><code>std::any</code>
不需提前声明存储哪些类型，在取值时才通过模板参数指定，更安全的
<code>void*</code>；</li>
<li><code>std::any</code> 、 <code>std::optionalstd::variant</code>
均为值语义，赋值时执行深拷贝；</li>
</ul></li>
<li>字符串视图 <code>std::string_view</code>
：一段字符串的引用，不具有所有权，具备 <code>std::string</code>
所有只读接口；</li>
<li><code>std::apply(func, std::tuple(...))</code>
将容器值作为函数输入；</li>
<li>C++17 采纳了 Boost.Filesystem 提供文件系统库，在
<code>std::filesystem</code> 下；</li>
<li>支持类型特征后缀：可用 <code>_v</code> 代替 <code>::value</code>
；</li>
<li>支持使用 <code>std::execution::par</code> 调用并行 STL 能力，需要
<em>tbb</em> 库；</li>
<li>新增泛型辅助函数 <code>size()</code> 、 <code>empty</code> 、
<code>data()</code> ；</li>
<li><code>clamp()</code> 找到三个值中居中的那个； <code>sample()</code>
获取一个随机子集；</li>
<li><code>emplace()</code> 系函数现在返回新插入对象的引用；
<code>try_emplace(&#123;key, std::move(value)&#125;)</code> 在插入成功时才会移动；
<code>insert_or_assign()</code> 无则插入有则替换，必然移动；</li>
<li><code>std::vector</code> 、 <code>std::list</code> 和
<code>std::forward_list</code>
开始支持不完全类型（可以在一个类中声明本身类型的 <code>vector</code>
作为成员变量）；</li>
<li>提供 <code>std::scoped_lock&lt;&gt;</code>
同时锁住多个互斥量，<code>std::shared_mutex&lt;&gt;</code>
支持读写锁，是 C++14 的 <code>std::shared_timed_mutex&lt;&gt;</code>
的子集；</li>
<li><code>m.extract()</code>
提取一个容器（可以用迭代器或键值指定），返回一个
<code>std::map&lt;Key, T&gt;::node_type</code> ，此时 <code>m</code>
不再包含此值；</li>
<li><code>&lt;numeric&gt;</code> 中新增 <code>std::gcd()</code> 和
<code>std::lcm()</code> ；</li>
<li>大量新增算法 API、专家特性与辅助特性；</li>
<li>数字与字符串互转：C++11 有 <code>std::to_string()</code> 和
<code>std::stoi()</code> ，C++17 新增 <code>std::from_chars()</code> 和
<code>std::to_chars()</code> ；</li>
<li>C++14 兼容 C99，而 C++17 兼容 C11；</li>
<li>C++11 废除空异常声明 <code>throw()</code> ，C++17 废除动态异常声明
<code>throw(std::bad_alloc)</code> ；</li>
<li><code>register</code> C++17 起不再有语义，但关键字仍然保留；</li>
<li>禁止 <code>bool</code> 使用 <code>++</code> ，移除
<code>auto_ptr</code> ；移除 <code>random_shuffle()</code> ，使用
<code>std::shuffle()</code> 代替；</li>
<li>移除 <code>std::unary_function</code> 和
<code>std::binary_function</code> ；</li>
</ul>
<h2 id="c20-新特性">C++20 新特性</h2>
<p><a
href="https://github.com/0voice/cpp_new_features/blob/main/C%2B%2B%2020%E8%AF%AD%E8%A8%80%E7%89%B9%E6%80%A7.md">C++20
特性总结</a></p>
<ul>
<li>格式化输出：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">format(<span class="string">&quot;Hello &#123;1&#125; &#123;0&#125;&quot;</span>, <span class="string">&quot;second&quot;</span>, <span class="string">&quot;first&quot;</span>); <span class="comment">// Hello first second</span></span><br><span class="line">format(<span class="string">&quot;&#123;:.5&#125;, &#123;:.&lt;5&#125;&quot;</span>, <span class="number">3.14159</span>, <span class="number">42</span>); <span class="comment">// 3.1416, 42...</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>进一步放宽 <code>constexpr</code> 范围；</p></li>
<li><p><code>&lt;utility&gt;</code> 使用 <code>cmp_less()</code>
等比较两个不同类型的数；</p></li>
<li><p>“宇宙飞船” <code>&lt;=&gt;</code> ：</p>
<ul>
<li>返回一个 <code>&lt;compare&gt;</code> 中的对象，可以与 0
比较；若小于则返回值小于 0，大于则大于 0，等于则等于 0；</li>
<li>若操作数为整型，则返回
<code>strong_ordering::equal/less/greater</code> ；若为浮点型，返回
<code>partial_ordering::equivalent/less/greater/unordered</code> ；</li>
<li><code>&lt;=&gt;</code> 重载</li>
<li>C++20 后会将 <code>a &gt; b</code> 重写为
<code>b &lt;=&gt; a &lt; 0</code> ，因此可以直接通过重载
<code>auto operator&lt;=&gt;(const Num&amp;) const = default;</code>
省去列举每个比较操作符的重载（默认按定义顺序依次将每个变量作为关键字），而只需再重载
<code>==</code> ；</li>
</ul></li>
<li><p>协程（Coroutines）：</p>
<ul>
<li>无栈协程，使用 <code>co_return</code> 、 <code>co_await</code> 、
<code>co_yield</code> ；</li>
</ul>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// sample 1</span></span><br><span class="line"><span class="function">generator&lt;<span class="type">int</span>&gt; <span class="title">range</span><span class="params">(<span class="type">int</span> start, <span class="type">int</span> end)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (start &lt; end) &#123;</span><br><span class="line">    <span class="keyword">co_yield</span> start;</span><br><span class="line">    start++;</span><br><span class="line">  &#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// co_return;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> n : <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10</span>)) &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// sample 2</span></span><br><span class="line"><span class="function">task&lt;<span class="type">void</span>&gt; <span class="title">echo</span><span class="params">(socket s)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">auto</span> data = <span class="keyword">co_await</span> s.<span class="built_in">async_read</span>();</span><br><span class="line">    <span class="function"><span class="keyword">co_await</span> <span class="title">async_write</span><span class="params">(s, data)</span></span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// co_return;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>概念</strong>（Concepts）：</p>
<ul>
<li><code>requires Numeric&lt;T&gt;</code> 约束（任意）模板，其中
<code>concept Numeric = integral&lt;T&gt; || floating_point&lt;T&gt;;</code>
；运算数结果为 <code>bool</code> ，结果需要为 <code>true</code> ；</li>
<li>可以直接写 <code>template &lt;Numeric T&gt;</code> ，或写入参数
<code>auto func(Numeric auto &amp;arg);</code> ；</li>
<li>可以在函数、 <code>lambda</code>
中使用；三种约束的逻辑操作符：合取式（conjunctions）、析取式（disjunctions）、原子约束（atomic
constraints），使用短路；</li>
<li>以下代码可以一定程度代替虚函数，提供更好的 ABI 稳定性：</li>
</ul>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span></span><br><span class="line"><span class="keyword">concept</span> DerivedOfBaseClass = std::is_base_of_v&lt;BaseClass, T&gt;;</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">concept</span> Histogram = <span class="built_in">requires</span>(T h1, T h2) &#123;</span><br><span class="line">    h1.<span class="built_in">getMoments</span>();         <span class="comment">// 要求有getMoments接口</span></span><br><span class="line">    T::count;                <span class="comment">// 要求有静态变量count</span></span><br><span class="line">    h1.moments;              <span class="comment">// 要求有成员变量moments</span></span><br><span class="line">    h1 + h2;                 <span class="comment">// 要求对象能够进行+操作</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">typename</span> T::type;        <span class="comment">// 要求存在类型成员type</span></span><br><span class="line">    <span class="keyword">typename</span> std::vector&lt;T&gt;; <span class="comment">// 要求能够模板实例化并与std::vector组合使用</span></span><br><span class="line">    </span><br><span class="line">    &#123; h1.<span class="built_in">getSubHistogram</span>() &#125; -&gt; same_as&lt;T&gt;;    <span class="comment">// 要求接口返回类型与T一致</span></span><br><span class="line">    &#123; h1.<span class="built_in">getUnit</span>() &#125; -&gt; convertible_to&lt;<span class="type">float</span>&gt;; <span class="comment">// 要求接口返回类型能转换成float，本质上接口返回类型可能是double</span></span><br><span class="line">    &#123; h1 = std::<span class="built_in">move</span>(h2) &#125; <span class="keyword">noexcept</span>;          <span class="comment">// 要求表达式不能抛出异常</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">requires</span> <span class="title">sizeof</span><span class="params">(T)</span> &gt; 4</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>模块</strong>（Modules）：</p>
<ul>
<li>一个编译单元默认为普通单元，使用 <code>module</code>
则为模块单元；使用 <code>export module my_module</code>
的称为模块接口单元（对应传统头文件），使用 <code>module my_module</code>
称为模块实现单元（对应传统实现文件）；使用 <code>import my_module</code>
导入模块；</li>
<li>需要在函数签名、命名空间等前使用 <code>export</code> 对外公开；使用
<code>export import one_module</code> 重导出模块（类似 Rust 中的
<code>pub use</code> ）；</li>
<li>若模块单元需要 <code>#include&lt;&gt;</code>
，或其它全局代码段，则需要在开头写一句 <code>module;</code>
引入全局模块，然后写预处理指令，写完后立即声明一个标准模块
<code>export module my_module</code> ；</li>
<li>实现部分和接口部分可以放在同一个文件中，接口部分前使用
<code>export module my_module</code> ，实现部分前使用
<code>module: private</code> ；</li>
<li>模块分区： <code>module A:B;</code> ，导入时只需要指定分区名称：
<code>export import :A;</code> ；模块分区的所有声明均对模块本身公开，
<code>export</code>
使其<strong><em>可以</em></strong>对模块外公开，但最终还需要主模块接口单元决定，即模块分区单元中的符号必须通过主模块的接口单元使用
<code>export</code> 控制对外可见性；</li>
<li>可以使用 <code>A.B</code> 式模块名，但与 <code>A</code>
之间并没有父子模块关系；</li>
<li>Module 并没有解决符号冲突问题，仍然需要与 namespace
配合使用，二者保持正交设计；同样不能解决二进制分发与 ABI 对齐问题；</li>
</ul></li>
<li><p><strong>范围</strong>（Ranges）：</p>
<ul>
<li>Range 是一个 Concept，要求是可迭代对象的集合，且支持
<code>begin()</code> 和 <code>end()</code> 迭代器；</li>
<li><strong>视图</strong>是惰性迭代操作，从底层返回而不拥有任何数据，复杂度为
O(1)；</li>
<li>使用 <code>ranges::take_view(ranges, n)</code> 返回前 n
个元素的视图，支持只读操作，同时支持 <code>for (int i: tv)</code>
；</li>
<li>视图适配器对函数式编程的支持：视图管道
<code>auto ****result = nums | views::take(5) | views::reverse;</code>
获取 <code>nums</code> 前五个元素的翻转；</li>
<li><code>nums | views::filter(lambda)</code> ，
<code>nums | views::transform(lambda)</code> ；
<code>views::reverse()</code> ， <code>views::iota(1, 10)</code>
返回一系列递增值；</li>
<li><code>stack</code> 和 <code>queue</code> 没有 <code>begin()</code>
和 <code>end()</code> ；</li>
<li><code>ranges::sort(vec)</code> ， <code>views::drop(view)</code>
；</li>
</ul></li>
<li><p><code>std::span</code> ：C 数组的 <code>string_view</code>
；直接用 <code>std::span&lt;T&gt;</code> 传参将 C 数组升级为
<code>span</code> ，从而传递其长度，且支持 <code>begin()</code> 、
<code>front()</code> 、 <code>empty()</code>
等操作；注意它仍不检查越界；</p></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> remove_it = std::<span class="built_in">remove</span>(c.<span class="built_in">begin</span>(), c.<span class="built_in">end</span>(), v); <span class="comment">// 返回后面向前移动后的末尾下一个</span></span><br><span class="line">c.<span class="built_in">erase</span>(remove_it, c.<span class="built_in">end</span>()); <span class="comment">// 真正的删除</span></span><br></pre></td></tr></table></figure>
<ul>
<li>使用 <code>[[likely]]</code> 和 <code>[[unlikely]]</code>
标记某个分支走到的概率；</li>
<li>不建议隐式捕获 <code>[=]</code> 捕获 <code>this</code>
，已弃用；使用 <code>[=, this]</code> 显式捕获；</li>
<li><code>lambda</code> 中可以使用模板语法，可以捕获参数包；
<code>[&amp;...args = std::forward&lt;Args&gt;(args)] &#123;...&#125;</code>
；</li>
<li><code>&lt;bit&gt;</code> 头提供位操作； <code>&lt;numbers&gt;</code>
头中定义一些数学常量；</li>
<li><code>std::make_shared&lt;int[]&gt;(5)</code> 或
<code>std::make_shared&lt;int[5]&gt;()</code> 支持数组；</li>
<li><code>str.starts_with("foo")</code> 和 <code>ends_with()</code> ；
<code>map</code> 和 <code>set</code> 新增 <code>contains(key)</code>
；</li>
<li><code>std::midpoint(1, 3) == 2</code> 不溢出地计算两个值的中点；
<code>std::to_array</code> 将 array-like 对象转换为
<code>std::array</code> ；</li>
<li>新增一系列新库函数； <code>jthread</code> ；编译时源代码分析
<code>source_location</code> 库； <code>u8string</code> ；</li>
</ul>
<h2 id="c23-新特性">C++23 新特性</h2>
<ul>
<li>显式 <code>this</code> 参数： <code>this Self&amp; self</code>
，搭配模板实现同时定义函数的 const 和非 const 版本，也可以实现递归
lambda 函数；</li>
<li>多元 <code>operator[]</code>
：支持逗号分隔的多维下标，可以搭配参数包转发；同时提供多维数组视图
<code>mdspan</code> ，可以用于包装一维数组模拟多维数组；</li>
<li>标准模块 <code>std</code> 与 <code>std.compact</code> ；</li>
<li><code>unexpected()</code> 、 <code>and_then</code> 、
<code>or_else</code> 等借鉴自 Rust 等语言的函数，错误码类型类似
optional；</li>
<li>进一步扩展 Ranges：转换函数 <code>to</code> ；</li>
<li><code>print()</code> 和 <code>println()</code> ：配合
<code>format</code> 输出；</li>
<li>堆栈跟踪库 <code>stacktrace</code> ；</li>
<li>C++26 新特性（猜测）：
<ul>
<li>静态反射；</li>
<li>Executors：获取线程池对象，并分配任务；</li>
<li>Sender / Receiver：Sender 创建后不立即执行调度任务，传递给 Receiver
后在执行；支持使用通用异步算法实现链式调用；Scheduler 返回 Sender
工厂；</li>
<li>标准网络库 Network；</li>
<li>高性能计算（线性代数等）；</li>
<li>Coroutines 扩展： <code>std::lazy</code> ；</li>
<li>进一步扩展 Ranges；</li>
<li>Hive：Bucket Array
容器框架，用于高性能交易、游戏编程等场景的大量数据块操作；</li>
<li>多线程无锁内存模型；</li>
<li>CPO
定制点对象：若引入的命名空间中仅有一个此函数名则无需写命名空间前缀；</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>The Rust Programming Language 读书笔记</title>
    <url>/2023/10/21/The-Rust-Programming-Language-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p><a href="https://rustwiki.org/zh-CN/book/">The Rust Programming
Language 中译本</a></p>
<p>配套材料：<a href="https://rustwiki.org/zh-CN/book/">Rust By Example
中译本</a></p>
<h2 id="第零二章-rust-入门">第零~二章 Rust 入门</h2>
<ul>
<li>个人收集的几个国内比较流行的中文社区：
<ul>
<li><a href="https://github.com/rust-lang-cn">rust-lang-cn</a>：Rust
中文官网提到的“非官方翻译”由此组织提供，维护了目前最全的 <a
href="https://www.rustwiki.org.cn/docs/">中文 Wiki</a>；</li>
<li><a href="https://github.com/rustcc">rustcc</a>：维护了中文社区的
https://github.com/rustcc/awesome-rust，翻译了 <em>Rust Atomics and
Locks、Rust Primer、Write an OS in Rust</em>
等书籍，保存了一些国内大会讲义；</li>
<li><a
href="https://github.com/rustlang-cn">rustlang-cn</a>：维护了非常完善的
<em>锈书</em> https://github.com/rustlang-cn/rusty-book，以及
Rustt、rust-weekly、rust-algos、<em>Asynchronous Programming in
Rust</em> 翻译 等项目；</li>
<li><a href="https://github.com/sunface">sunface</a>：有 <a
href="https://course.rs/about-book.html">Rust 语言圣经</a> 和 <a
href="https://github.com/sunface/rust-by-practice">rust-by-practice</a>；</li>
</ul></li>
</ul>
<span id="more"></span>
<ul>
<li><strong>安装</strong>（MacOS）：VSCode 扩展：rust-analyzer，Sublime
Text 扩展：https://github.com/rust-lang/rust-enhanced</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ xcode-select --install</span><br><span class="line">$ curl --proto <span class="string">&#x27;=https&#x27;</span> --tlsv1.2 https://sh.rustup.rs -sSf | sh</span><br><span class="line">Rust is installed now. Great!</span><br><span class="line">$ rustup update</span><br><span class="line">$ rustup self uninstall</span><br><span class="line">$ rustc --version</span><br><span class="line">$ rustup doc</span><br></pre></td></tr></table></figure>
<ul>
<li>可以使用 <code>rustfmt</code>
格式化源码；标准写法大括号不换行（有空格）；</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> rand::Rng;</span><br><span class="line"><span class="keyword">use</span> std::cmp::Ordering;</span><br><span class="line"><span class="keyword">use</span> std::io;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Guess the number!&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">secret_number</span> = rand::<span class="title function_ invoke__">thread_rng</span>().<span class="title function_ invoke__">gen_range</span>(<span class="number">1</span>..<span class="number">101</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">loop</span> &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;Please input your guess.&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">guess</span> = <span class="type">String</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line"></span><br><span class="line">        io::<span class="title function_ invoke__">stdin</span>()</span><br><span class="line">            .<span class="title function_ invoke__">read_line</span>(&amp;<span class="keyword">mut</span> guess)</span><br><span class="line">            .<span class="title function_ invoke__">expect</span>(<span class="string">&quot;Failed to read line&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">guess</span>: <span class="type">u32</span> = <span class="keyword">match</span> guess.<span class="title function_ invoke__">trim</span>().<span class="title function_ invoke__">parse</span>() &#123;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>(num) =&gt; num,</span><br><span class="line">            <span class="title function_ invoke__">Err</span>(_) =&gt; <span class="keyword">continue</span>,</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;You guessed: &#123;&#125;&quot;</span>, guess);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">match</span> guess.<span class="title function_ invoke__">cmp</span>(&amp;secret_number) &#123;</span><br><span class="line">            Ordering::Less =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Too small!&quot;</span>),</span><br><span class="line">            Ordering::Greater =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Too big!&quot;</span>),</span><br><span class="line">            Ordering::Equal =&gt; &#123;</span><br><span class="line">                <span class="built_in">println!</span>(<span class="string">&quot;You win!&quot;</span>);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Rust 是<strong>静态强类型</strong>语言，<code>rustc main.rs</code>
得到可执行文件 <code>main</code> ；</li>
<li><strong>Cargo</strong>：
<ul>
<li><code>cargo new hello_cargo</code> 创建目录并自动生成 TOML
文件；</li>
<li><code>cargo build</code> 构建，<code>cargo run</code>
构建并运行，<code>cargo check</code> 确保能编译但不生成可执行文件；</li>
<li><code>cargo build --release</code>
发布；<code>cargo doc --open</code> 用网页打开项目依赖库的手册；</li>
</ul></li>
<li>在 Cargo.toml 中使用 <code>[dependencies]</code> 添加依赖
<code>rand = "0.8.3"</code> ，此时会寻找包含 0.8.3 但低于 0.9.0
的版本，若没有则从 <a href="https://crates.io/">Crates.io</a>
下载；Cargo.lock 会记录所有可用版本，此后出发更新 toml 文件，否则 Cargo
不会主动更新版本；</li>
</ul>
<h2 id="第三章-通用编程概念">第三章 通用编程概念</h2>
<ul>
<li><strong>可变性</strong>：
<ul>
<li><code>let</code>
变量默认<strong>不可变</strong>（immutable），可以用 <code>mut</code>
使其可变；</li>
<li>可以再次使用 <code>let</code>
<strong>遮蔽</strong>（shadow）前一个变量（两个变量完全独立，也不需要是同一类型），作用域的遮蔽与其它语言类似：更深一层作用域中的遮蔽在作用域结束后失效；</li>
<li><code>const</code> 声明编译期常量，变量名规范为
SCREAMING_SNAKE_CASE；</li>
</ul></li>
<li><strong>标量类型</strong>：
<ul>
<li>整型：i8/16/32（默认）/64/128/size，u8/16/32（默认）/64/128/size；
<code>isize</code> 和 <code>usize</code> 视 32/64 位系统而具有 32/64
位；字面量允许添加无效的 <code>_</code> 便于阅读；</li>
<li>浮点型：f32/64（默认），使用
<em>IEEE-754</em>；布尔类型：bool；字符类型：char（Unicode），字面量使用单引号；</li>
</ul></li>
<li><strong>复合类型</strong>：
<ul>
<li>元组：使用解构或索引形式访问元组元素，无值元组 <code>()</code>
称为<strong>单元类型</strong>，该值称为<strong>单元值</strong>，是不返回任何其它值的<em>表达式</em>的隐式返回值；</li>
<li>数组：<code>let a: [i32; 5] = [1, 2, 3, 4, 5];</code> ，包含 5 个 3
的数组： <code>let a = [3; 5]</code> ；超出索引范围时会
<em>panic</em>；</li>
</ul></li>
<li><strong>函数</strong>：函数和变量命名均使用小写蛇形；函数定义相互顺序没有影响；函数签名必须声明每个参数的类型；可以用尾置返回值；</li>
<li>Rust 是一门基于表达式的语言：
<ul>
<li><strong>语句</strong>（statement）：执行一些操作但不返回值；Rust
中没有连等，因为 <code>let</code> 是语句，无法再参与赋值；</li>
<li><strong>表达式</strong>（expression）：计算并产生一个值；函数调用、宏调用、创建新作用域的大括号（代码块）（最后一句无分号）均是表达式；</li>
</ul></li>
<li><strong>注释</strong>：双斜杠注释，一般置于需要解释的代码行上一行；块注释
<code>/*...*/</code> ；</li>
<li><strong>控制流</strong>：
<ul>
<li><code>if</code> 语句条件不需要括号，条件必须是一个 <code>bool</code>
，每个分支（arm）为一对大括号括起的语句或表达式（此时可以用于赋值）；短路求值；</li>
<li><code>loop</code> 语句支持使用循环标签 <code>'lable</code> 以供
<code>continue</code> 和 <code>break</code> 使用， <code>break</code>
还可以后跟一个值作为表达式的返回值；</li>
<li>另外两种循环：<code>while condition &#123;...&#125;</code> ，
<code>for element in a</code> ；</li>
</ul></li>
</ul>
<h2 id="第四章-认识所有权">第四章 认识所有权</h2>
<ul>
<li>Rust
中每个值有且仅有一个<strong>所有者</strong>（Owner）变量，所有者离开作用域时值被丢弃（调用特殊函数
<code>drop</code> ，类似于 C++ 中的 RAII）；</li>
<li>以 String 为例：可变、可增长字符串（存于堆中）；在
<code>let s2 = s1;</code> 赋值时使用移动语义， <code>s1</code>
不再可用；Rust 不会自动执行深拷贝，需要深拷贝时应使用 <code>clone</code>
方法；</li>
<li>实现了 <code>Copy</code> trait
的类型在赋值给其它变量后仍可使用，实现了 <code>Drop</code> trait
的类型不可使用 <code>Copy</code> trait；实现了 <code>Copy</code> trait
的类型：所有<em>标量类型</em>与仅包含标量类型的元组；</li>
<li>函数参数传递与赋值相似，会转移所有权，非引用形参离开函数作用域后（若没有被返回）会被
<code>drop</code> ，原函数中不再可用；</li>
<li>创建<strong>引用</strong>的行为称为<strong>借用</strong>，借用的变量不可修改；<strong>可变引用</strong>不可与同一变量的任何其它引用的作用域重叠；注意引用的作用域从声明处到最后一次使用为止；</li>
<li>编译器不允许悬垂引用（Dangling References）；</li>
<li><strong>切片</strong>（Slice）：
<code>let hello = &amp;s[0..5];</code>
；字符串字面量<code>let s = "Hello, world!";</code> 中 <code>s</code>
的类型是 <code>&amp;str</code> ，是指向二进制程序特此位置的
slice，因此为不可变引用；</li>
</ul>
<h2 id="第五章-使用结构体组织关联数据">第五章
使用结构体组织关联数据</h2>
<ul>
<li><strong>结构体</strong>（struct）：若 <code>user1</code> 中有未实现
<code>Copy</code> trait 的成员，则不能再使用 <code>user1</code>
；<strong>元组结构体</strong>：
<code>struct Color(i32, i32, i32);</code> ；</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">user2</span> = User &#123;</span><br><span class="line">        email: <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;another@example.com&quot;</span>),</span><br><span class="line">        ..user1 <span class="comment">// 其余成员直接从user1拷贝</span></span><br><span class="line">    &#125;;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>方法</strong>：
<ul>
<li>在 <code>impl</code> 块中定义，使用 <code>self</code>
访问结构体成员；</li>
<li><strong>getters</strong> 允许我们将字段变为私有而方法是公共的；</li>
<li>Rust 会自动为 <code>object</code> 添加 <code>&amp;</code> 、
<code>&amp;mut</code> 或 <code>*</code> 以与方法签名匹配；</li>
<li>在 <code>impl</code> 块中定义但不以 <code>self</code>
为第一参数的函数称为关联函数或静态方法，常被用作构造函数；</li>
<li><code>&amp;self</code> 是 <code>self: &amp;Self</code>
的语法糖；</li>
</ul></li>
<li><strong>自动引用和解引用</strong>（automatic referencing and
dereferencing）：使用 <code>obj.something()</code> 调用方法时，Rust
会自动为 <code>obj</code> 添加 <code>&amp;</code>、<code>&amp;mut</code> 或 <code>*</code> 以便使 <code>obj</code> 与方法签名匹配，可以自动添加任意多层；</li>
</ul>
<h2 id="第六章-枚举和模式匹配">第六章 枚举和模式匹配</h2>
<ul>
<li>枚举提供如下操作；<strong>Option&lt;T&gt;</strong>：用于处理空值的枚举，由编译器确保我们处理了空值的情况；</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">IpAddr</span> &#123;</span><br><span class="line">    <span class="title function_ invoke__">V4</span>(<span class="type">u8</span>, <span class="type">u8</span>, <span class="type">u8</span>, <span class="type">u8</span>),</span><br><span class="line">    <span class="title function_ invoke__">V6</span>(<span class="type">String</span>),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">home</span> = IpAddr::<span class="title function_ invoke__">V4</span>(<span class="number">127</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line"><span class="keyword">let</span> <span class="variable">loopback</span> = IpAddr::<span class="title function_ invoke__">V6</span>(<span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;::1&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">Option</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="title function_ invoke__">Some</span>(T),</span><br><span class="line">    <span class="literal">None</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>match</strong> 控制流运算符：
<ul>
<li>支持枚举类型， <code>=&gt;</code> 后跟表达式；</li>
<li>match 可以与 <code>Option&lt;T&gt;</code>
匹配，分支模式若为枚举可以带参数；</li>
<li>提供其它分支模式 <code>other</code>，模式按顺序依次匹配，因此
<code>other</code> 应置于最后；</li>
<li>通配符 <code>_</code> 可以匹配任意值而不绑定；</li>
</ul></li>
<li><strong>if let</strong> 是 <code>match</code>
的语法糖，当值匹配某一模式时执行代码而忽略其它值；</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">coin</span> = Coin::Penny;</span><br><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">count</span> = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">match</span> coin &#123;</span><br><span class="line">    Coin::<span class="title function_ invoke__">Quarter</span>(state) =&gt; <span class="built_in">println!</span>(<span class="string">&quot;State quarter from &#123;:?&#125;!&quot;</span>, state),</span><br><span class="line">    _ =&gt; count += <span class="number">1</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 等价于</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Coin</span>::<span class="title function_ invoke__">Quarter</span>(state) = coin &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;State quarter from &#123;:?&#125;!&quot;</span>, state);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    count += <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="第七章-使用包crate-和模块管理不断增长的项目">第七章
使用包、Crate 和模块管理不断增长的项目</h2>
<ul>
<li><strong>Crate</strong>：一个二进制项或者库；<strong>包</strong>（Package）：至多包含一个库
crate，可以包含任意多个二进制 crate；</li>
<li><strong>模块系统</strong>：
<ul>
<li>使用 <code>cargo new --lib lib_name</code> 新建库；</li>
<li>使用 <code>mod</code>
定义当前文件模块内容或引入同名文件/文件夹所定义的模块；</li>
<li>使用 <code>pub</code> 公开函数和成员，使用 <code>use</code>
引入模块路径，使用 <code>as</code> 给引入模块起别名；</li>
<li>使用 <code>pub use</code> 重导出；</li>
</ul></li>
<li>使用嵌套路径：<code>use std::io::&#123;self, Write&#125;;</code> ，通过 glob
运算符 <code>*</code> 引入所有公有定义（不推荐）；</li>
</ul>
<h2 id="第八章-常见集合">第八章 常见集合</h2>
<ul>
<li><strong>vector</strong>：
<ul>
<li>有些类似 C++； 使用 <code>push()</code> 和 <code>pop()</code> ，
<code>reserve()</code> 预留内存；</li>
<li><code>Vec&lt;T&gt;</code> 或使用 <code>vec!</code> 宏；</li>
<li><code>[]</code> 下标超出范围会 panic，但 <code>get()</code> 会返回
<code>None</code>；</li>
<li>可以使用枚举使 <code>vector</code> 存储不同的值；</li>
</ul></li>
<li><code>String</code> 及其 slice 均为 UTF-8 编码，
<code>let s3 = s1 + &amp;s2;</code> 会让 <code>s1</code>
失去所有权；不支持索引，因为 <code>String</code> 是
<code>Vec&lt;u8&gt;</code> 的封装，遍历时需要使用 <code>chars()</code>
（不能获得字形簇）；</li>
<li><strong>HashMap</strong>：</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> std::collections::HashMap;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">teams</span>  = <span class="built_in">vec!</span>[<span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;Blue&quot;</span>), <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;Yellow&quot;</span>)];</span><br><span class="line"><span class="keyword">let</span> <span class="variable">initial_scores</span> = <span class="built_in">vec!</span>[<span class="number">10</span>, <span class="number">50</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">scores</span>: HashMap&lt;_, _&gt; = teams.<span class="title function_ invoke__">iter</span>().<span class="title function_ invoke__">zip</span>(initial_scores.<span class="title function_ invoke__">iter</span>()).<span class="title function_ invoke__">collect</span>();</span><br><span class="line"><span class="comment">// 检查，若无此键则插入值。返回原值或新值的可变引用</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">count</span> = scores.<span class="title function_ invoke__">entry</span>(<span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;Yellow&quot;</span>)).<span class="title function_ invoke__">or_insert</span>(<span class="number">50</span>);</span><br><span class="line">*count += <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<h2 id="第九章-错误处理">第九章 错误处理</h2>
<ul>
<li><code>panic!</code>
宏使程序打印错误信息，展开并清理栈数据，然后退出；</li>
<li><code>unwrap</code> 和 <code>expect</code> 方便地提供错误信息，在
Result 返回 Err 时直接 panic；</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">Result</span>&lt;T, E&gt; &#123;</span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(T),</span><br><span class="line">    <span class="title function_ invoke__">Err</span>(E),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>通过传播（propagating）将错误传递给函数调用者；</li>
<li>使用 <code>?</code> 运算符调用 <code>from</code>
函数将收到的错误类型转换为由当前函数返回类型所指定的错误类型，并返回给上层调用者；</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">From</span>&lt;CreationError&gt; <span class="keyword">for</span> <span class="title class_">ParsePosNonzeroError</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">from</span>(err:CreationError) <span class="punctuation">-&gt;</span> ParsePosNonzeroError &#123;</span><br><span class="line">        ParsePosNonzeroError::<span class="title function_ invoke__">Creation</span>(err)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="第十章-泛型trait-与生命周期">第十章 泛型、trait 与生命周期</h2>
<ul>
<li>使用 <code>&lt;T&gt;</code> 定义函数或结构体泛型，使用
<code>impl&lt;T&gt; Point&lt;T&gt;</code> 定义泛型方法，使用
<code>impl Point&lt;f32&gt;</code> 定义具体类型方法；</li>
<li><strong>trait</strong>：
<ul>
<li>类似其它语言的接口，定义内部有多个函数签名；</li>
<li>使用 <code>impl MyTrait for MyStruct</code> 为结构体实现
trait，trait 可以定义默认实现；</li>
<li>只能实现本地作用域下的类型而不能实现引入的外部类型；</li>
<li>使用 <code>item: impl MyTrait</code> 传参实现了此 trait 的类型，通过
<code>+</code> 要求实现多个 trait；</li>
<li><strong>trait bound</strong>：trait 是 trait bound
的语法糖，后者可以强制函数传递的两个实现此 trait 的参数是同一类型；</li>
</ul></li>
<li><strong>借用检查器</strong>（borrow
checker）：被引用者的生命周期必须包含它的引用变量的生命周期；</li>
<li><strong>泛型生命周期</strong>：
<code>fn longest&lt;'a&gt;(x: &amp;'a str, y: &amp;'a str) -&gt; &amp;'a str;</code>
， <code>'a</code> 会对 <code>x</code> 和 <code>y</code>
的生命周期取<em>交集</em>，生命周期标注不改变任何生命周期；使用生命周期标注定义包含引用的结构体；</li>
<li>生命周期<strong>省略规则</strong>：
<ul>
<li>每个引用参数都有自己的生命周期；</li>
<li>如果只有一个输入生命周期参数，就将其赋予所有输出生命周期参数；</li>
<li>如果方法参数中有 <code>&amp;self</code> 或
<code>&amp;mut self</code>
，说明是对象方法，此时所有输出生命周期参数被赋予 <code>self</code>
的生命周期；</li>
</ul></li>
<li><code>'static</code> 拥有整个程序的生命周期；实现函数时可以加
<code>mut</code> 或不加，函数声明时不能添加pattern</li>
<li>阶乘的函数式写法： <code>(1..=num).product()</code> ；</li>
</ul>
<h2 id="第十一章-编写自动化测试">第十一章 编写自动化测试</h2>
<ul>
<li>编写测试：
<ul>
<li>使用 <code>#[cfg(test)]</code> 和 <code>#[derive(Debug)]</code>
开启调试能力；</li>
<li>使用 <code>#[test]</code> 与 <code>cargo test</code> 测试该函数是否
panic；</li>
<li>使用 <code>assert!</code> 宏使程序在条件为假时 panic，使用
<code>assert_eq!</code> 和 <code>assert_ne!</code> 测试相等（还需要
<code>derive(PartialEq)</code>），三种 <code>assert</code>
均支持附带一个显示出错信息参数；</li>
<li><code>Debug</code> trait 提供使用 <code>&#123;:?&#125;</code>
打印类型调试格式，使用 <code>&#123;:#?&#125;</code> 打印更美观的调试格式；</li>
<li>使用 <code>#[test]</code>后跟 <code>#[should_panic]</code> 使 panic
时通过测试，使用 <code>#[should_panic(expected = "...")]</code>
限定接收到的 panic 信息；</li>
</ul></li>
<li>运行测试：
<ul>
<li>默认为并行测试，使用 <code>cargo test -- --test-threads=1</code>
使用串行；</li>
<li>只有测试失败的函数会显示正常输出内容，测试通过的函数不会再显示其输出，使用
<code>cargo test -- --nocapture</code> 显示通过测试的值；</li>
<li>使用 <code>cargo test name</code> 测试所有函数名中包含 name
的函数；</li>
<li>使用 <code>#[test]</code> 后跟 <code>#[ignore]</code>
忽略此测试函数；</li>
</ul></li>
<li>集成测试：
<ul>
<li>在项目根目录创建 <em>tests</em> 目录，不再需要
<code>#[cfg(test)]</code> ；</li>
<li>使用 <code>cargo test --test name</code> 指定测试 name
文件中的测试函数；</li>
<li>将提供测试专用的公开函数的文件置于
<em>tests/common/mod.rs</em>；</li>
</ul></li>
</ul>
<h2 id="第十二章-一个-io-项目构建命令行程序">第十二章 一个 I/O
项目：构建命令行程序</h2>
<ul>
<li>二进制项目关注分离：将具体功能提取到 <em>lib.rs</em>
中，<em>main.rs</em> 仅处理程序运行；</li>
<li>使用 <code>Result</code> 而不是直接 panic，从 <code>main</code>
中提取 <code>run</code> 的逻辑，并捕获其返回的错误；</li>
<li>测试驱动开发（Test Driven Development,
TDD）：编写期望失败的测试，再编写代码使其通过，然后重构增加的代码；</li>
<li>使用 <code>eprintln!</code> 打印信息到标准错误流；</li>
<li><code>fmt::Debug</code>：使用 <code>&#123;:?&#125;</code> 或
<code>&#123;:#?&#125;</code> 标记，格式化文本以供调试使用，可以直接
derive；<code>fmt::Display</code>：使用 <code>&#123;&#125;</code> 标记，以更优雅和友好的风格来格式化文本，需要手动实现；</li>
</ul>
<h2 id="第十三章-rust-中的函数式语言功能迭代器与闭包">第十三章
<strong>Rust 中的函数式语言功能：迭代器与闭包</strong></h2>
<ul>
<li><p><strong>闭包</strong>（<em>closures</em>）：</p>
<ul>
<li>可以保存进变量或作为参数传递给其他函数的匿名函数，可以捕获调用者作用域中的值。</li>
<li>闭包不暴露给用户，因此可以没有参数和返回值类型标注，当然也可以标注：
<code>|num: u32| -&gt; u32</code>
；对于没有类型标注的闭包，在第一次调用后编译器会自动绑定上所有类型，后续不能再改变；</li>
<li>每个闭包实例有其自己独有的匿名类型；下面是一个值在第一次调用时确定的函数闭包实现：</li>
</ul>
<p><figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Cacher</span>&lt;T&gt;</span><br><span class="line">    <span class="keyword">where</span> T: <span class="title function_ invoke__">Fn</span>(<span class="type">u32</span>) <span class="punctuation">-&gt;</span> <span class="type">u32</span></span><br><span class="line">&#123;</span><br><span class="line">    calculation: T,</span><br><span class="line">    value: <span class="type">Option</span>&lt;<span class="type">u32</span>&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T&gt; Cacher&lt;T&gt;</span><br><span class="line">    <span class="keyword">where</span> T: <span class="title function_ invoke__">Fn</span>(<span class="type">u32</span>) <span class="punctuation">-&gt;</span> <span class="type">u32</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">new</span>(calculation: T) <span class="punctuation">-&gt;</span> Cacher&lt;T&gt; &#123;</span><br><span class="line">        Cacher &#123;</span><br><span class="line">            calculation,</span><br><span class="line">            value: <span class="literal">None</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">value</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, arg: <span class="type">u32</span>) <span class="punctuation">-&gt;</span> <span class="type">u32</span> &#123;</span><br><span class="line">        <span class="keyword">match</span> <span class="keyword">self</span>.value &#123;</span><br><span class="line">            <span class="title function_ invoke__">Some</span>(v) =&gt; v,</span><br><span class="line">            <span class="literal">None</span> =&gt; &#123;</span><br><span class="line">                <span class="keyword">let</span> <span class="variable">v</span> = (<span class="keyword">self</span>.calculation)(arg);</span><br><span class="line">                <span class="keyword">self</span>.value = <span class="title function_ invoke__">Some</span>(v);</span><br><span class="line">                v</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>闭包会捕获其环境，实现了 trait <code>Fn</code>
（获取不可变借用值）、 <code>FnMut</code> （获取可变借用值）或
<code>FnOnce</code> （获取环境所有权）中的至少一个；</li>
</ul></li>
<li><p><strong>迭代器</strong>：</p>
<ul>
<li><code>Iterator</code> trait 实现了
<code>fn next(&amp;mut self) -&gt; OptionSelf::Item;</code> ；
<code>iter</code> 产生不可变引用， <code>into_iter</code>
产生拥有所有权的迭代器， <code>iter_mut</code> 返回可变引用；</li>
<li>迭代器会提供一些消费迭代器自身的方法（称为<strong>消费适配器</strong>，如
<code>v1.iter().sum()</code> 、 <code>collect()</code> ），它们会调用
<code>next</code> ；</li>
<li><strong>迭代器适配器</strong>：
<code>v1.iter().map(|x| x + 1);</code> 、
<code>v1.into_iter().filter(|x| x &gt; 1);</code> ；</li>
<li>由于 Rust 的<em>零成本抽象</em>，鼓励使用迭代器代替循环；</li>
</ul></li>
</ul>
<h2 id="第十四章-更多关于-cargo-和-crates.io-的内容">第十四章 更多关于
Cargo 和 Crates.io 的内容</h2>
<ul>
<li>使用 <code>[profile.dev]</code> 后跟 <code>opt-level = 1</code>
开启优化，等级为 0~3；</li>
<li>使用 <code>///</code> 编辑文档注释，可以运行 <code>cargo doc</code>
使用 <em>rustdoc</em> 生成对应 HTML 文档并存入
<em>target/doc</em>；当文档注释中的例子与代码不同步或产生 panic 时
<code>cargo test</code> 会报错；</li>
<li>使用 <code>//!</code> 编辑包含此注释的 crate 或模块整体的文档；</li>
<li>使用 workspace 避免相互依赖的不同模块的重复构建；</li>
</ul>
<h2 id="第十五章-智能指针">第十五章 智能指针</h2>
<ul>
<li>智能指针实现了 <code>Deref</code> 和 <code>Drop</code>
trait，使用结构体和<strong>引用计数</strong>（reference counting）实现；
<ul>
<li><code>Rc&lt;T&gt;</code> 允许相同数据有多个所有者；<code>Box&lt;T&gt;</code> 和 <code>RefCell&lt;T&gt;</code> 有单一所有者。</li>
<li><code>Box&lt;T&gt;</code> 允许在编译时执行不可变或可变借用检查；<code>Rc&lt;T&gt;</code>仅允许在编译时执行不可变借用检查；<code>RefCell&lt;T&gt;</code> 允许在运行时执行不可变或可变借用检查。</li>
<li>因为 <code>RefCell&lt;T&gt;</code> 允许在运行时执行可变借用检查，所以我们可以在即便 <code>RefCell&lt;T&gt;</code> 自身是不可变的情况下修改其内部的值。</li>
</ul></li>
<li>使用 <code>Box::new()</code> 在堆上分配值；使用 <code>Box</code>
定义一个递归类型 cons list；</li>
<li>定义 <code>Deref</code> trait：</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> std::ops::Deref;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">MyBox</span>&lt;T&gt;(T); <span class="comment">// 元组结构体</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T&gt; Deref <span class="keyword">for</span> <span class="title class_">MyBox</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Target</span> = T;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">deref</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> &amp;T &#123;</span><br><span class="line">        &amp;<span class="keyword">self</span>.<span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>解引用强制转换</strong>（deref coercions）：实现了
<code>Deref</code> trait 的类型 A 可以根据实现内容，隐式转换为另一个类型
B 的引用；</li>
<li>Rust 在发现类型和 trait 实现满足三种情况时会进行解引用强制转换：
<ul>
<li>当 <code>T: Deref&lt;Target=U&gt;</code> 时从 <code>&amp;T</code> 到 <code>&amp;U</code>。</li>
<li>当 <code>T: DerefMut&lt;Target=U&gt;</code> 时从 <code>&amp;mut T</code> 到 <code>&amp;mut U</code>。</li>
<li>当 <code>T: Deref&lt;Target=U&gt;</code> 时从 <code>&amp;mut T</code> 到 <code>&amp;U</code>。</li>
</ul></li>
<li>使用 <code>Drop</code> trait 运行清理代码，但不能使用
<code>drop</code> 方法提前释放；应使用 <code>std::mem::drop</code>
，即使用 <code>drop(a)</code> 而非 <code>a.drop()</code> ；</li>
<li><code>Rc&lt;T&gt;</code> 允许使用 <code>Rc::clone(&amp;ptr)</code>
（仅增加引用计数而非深拷贝）共享所有权；可以通过
<code>strong_count</code> 和 <code>weak_count</code>
获得引用数；只允许不可变借用；</li>
<li><strong>内部可变性</strong>（Interior mutability）：允许使用
<code>unsafe</code> 代码模糊可变性和借用规则；</li>
<li><code>RefCell&lt;T&gt;</code>
代表数据的唯一所有权，但在运行时才检查借用规则，它和
<code>Rc&lt;T&gt;</code>
均只能用于单线程场景；<code>borrow</code> 方法返回 <code>Ref&lt;T&gt;</code> 类型的智能指针，<code>borrow_mut</code> 方法返回 <code>RefMut</code> 类型的智能指针</li>
<li>结合二者来拥有多个可变数据的所有者：</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">List</span> &#123;</span><br><span class="line">    <span class="title function_ invoke__">Cons</span>(Rc&lt;RefCell&lt;<span class="type">i32</span>&gt;&gt;, Rc&lt;List&gt;),</span><br><span class="line">    Nil,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>调用 <code>Rc::downgrade</code> 得到 <code>weak&lt;T&gt;</code> ；对
<code>weak&lt;T&gt;</code> 使用 <code>upgrade</code> 得到
<code>Option&lt;Rc&lt;T&gt;&gt;</code> ；</li>
<li><code>Cell&lt;T&gt;</code> 允许实现了 <code>Copy</code> trait
的类型的内部可变性（允许在持有不可变引用时修改其内容），使用编译期检查；</li>
</ul>
<h2 id="第十六章-无畏并发">第十六章 无畏并发</h2>
<ul>
<li>Fearless Concurrency：Rust 坚持几乎没有运行时，且支持调用 C
语言，因此语言线程与 OS 线程比为 1:1；</li>
<li>调用 <code>thread::spawn</code> 并传递闭包，返回一个拥有所有权的
<code>JoinHandle</code> ，调用其 <code>handle.join().unwrap()</code>
时会等待线程结束；</li>
<li>使用 <code>move</code> 闭包强制闭包获取使用的值的所有权；</li>
<li>使用<strong>通道</strong>（Channel，思想来源于
Go）实现消息传递：使用 <code>let (tx, rx) = mpsc::channel();</code> 创建多个生产者，单个消费者通道；</li>
<li>通道会传递所有权，使用 <code>tx.send()</code> 发送，
<code>rx.recv()</code> 或迭代器接收；使用 <code>tx.clone()</code>
获取多生产者；</li>
<li><code>mutex&lt;T&gt;</code> 使用 <code>lock()</code>
阻塞直到获取锁，返回一个 <code>MutexGuard</code> 智能指针；</li>
<li>锁的所有权无法移动到多个线程中，因此封装进 <code>Arc&lt;T&gt;</code>
原子引用计数类型中；</li>
<li>两个内嵌于语言中的并发概念： <code>std::marker</code> 中的
<code>Sync</code> （可以在多个线程中拥有其引用）和 <code>Send</code>
（所有权可以在线程间传递）trait；</li>
<li><code>Rc&lt;T&gt;</code> 不支持 <code>Send</code> 和
<code>Sync</code> trait，应使用 <code>Arc&lt;T&gt;</code> ；
<code>RefCell&lt;T&gt;</code> 和 <code>Cell&lt;T&gt;</code> 系列类型不是
<code>Sync</code> 的，而 <code>Mutex&lt;T&gt;</code> 是；</li>
</ul>
<h2 id="第十七章-rust-的面向对象特性">第十七章 Rust 的面向对象特性</h2>
<ul>
<li>Rust
支持抽象、封装（但不使用对象的概念，数据和行为定义也是分开的），不支持完整的继承，使用
trait 实现多态；</li>
<li>trait 实现的继承的不完全替代：
<code>pub components: Vec&lt;Box&lt;dyn Draw&gt;&gt;</code> ，这里实现了
<code>Draw</code> trait
的类型可以有多种，而非与泛型一样只代表一种；trait 对象通过虚函数表
vtable 实现；</li>
<li>trait 对象需要使用<strong>动态分发</strong>；返回值不为
<code>Self</code> 且方法没有泛型参数的 trait 才能组成 trait
对象，这称为<strong>对象安全</strong>（因为运行时已经忘记具体类型）；</li>
<li>例：使用 trait 实现<em>状态模式</em>；</li>
</ul>
<h2 id="第十八章-模式和匹配">第十八章 模式和匹配</h2>
<ul>
<li><code>match</code> 、 <code>if let</code> 、 <code>while let</code>
、 <code>for</code> 、 <code>let</code> 、函数传参均会使用模式；</li>
<li><em>refutable</em>：匹配可能失效，<em>irrefutable</em>：不可能失败，如
<code>let</code> 定义；</li>
<li><code>match</code> 中 <code>1..=5</code> 等同于
<code>1 | 2 | 3 | 4 | 5</code> ；</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">p</span> = Point &#123; x: <span class="number">0</span>, y: <span class="number">7</span> &#125;;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">Point</span> &#123; x: a, y: b &#125; = p; <span class="comment">// 定义了a, b</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">Point</span> &#123; x, y &#125; = p; <span class="comment">// 定义了 x, y</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>id: id_variable @ 3..=7</code> 匹配的同时绑定到变量上；</li>
</ul>
<h2 id="第十九章-高级特征">第十九章 高级特征</h2>
<ul>
<li>不安全的 Rust：
<ul>
<li>解引用裸指针；</li>
<li>调用不安全函数或方法：创建不安全代码的安全抽象、使用
<code>extern</code> 调用外部代码；</li>
<li>访问或修改可变静态变量；</li>
<li>实现不安全 trait；</li>
<li>访问 <code>union</code> （一般用于和 C 交互）中的字段；</li>
</ul></li>
<li><strong>关联类型</strong>：用于类型占位，在实现时指定真正类型；</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">Iterator</span> <span class="keyword">for</span> <span class="title class_">Counter</span> &#123;</span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Item</span> = <span class="type">u32</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">next</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="keyword">Self</span>::Item&gt; &#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>默认泛型类型参数和运算符重载：实现 <code>+</code>
重载的方式举例：</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">trait</span> <span class="title class_">Add</span>&lt;RHS=<span class="keyword">Self</span>&gt; &#123;</span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Output</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">add</span>(<span class="keyword">self</span>, rhs: RHS) <span class="punctuation">-&gt;</span> <span class="keyword">Self</span>::Output;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Add</span>&lt;Meters&gt; <span class="keyword">for</span> <span class="title class_">Millimeters</span> &#123;</span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Output</span> = Millimeters;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">add</span>(<span class="keyword">self</span>, other: Meters) <span class="punctuation">-&gt;</span> Millimeters &#123;</span><br><span class="line">        <span class="title function_ invoke__">Millimeters</span>(<span class="keyword">self</span>.<span class="number">0</span> + (other.<span class="number">0</span> * <span class="number">1000</span>))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>调用不同 trait 的同名方法时需要同时指定
<code>trait::func()</code>；调用关联函数语法 <code>struct::func()</code>
；通过完全限定语法调用结构体的 trait
<code>&lt;Dog as Animal&gt;::func()</code> ；父 trait 使用了其它 trait
的功能： <code>trait OutlinePrint: fmt::Display</code> ；</li>
<li>newtype 模式：在想添加功能的类型外套一层 wrapper类型：
<code>struct Wrapper(Vec&lt;String&gt;)</code> ，可以再通过实现
<code>Deref</code> trait 返回内部类型实现和对待原类型一样对待此
wrapper；</li>
<li>类型别名： <code>type Kilometers = i32;</code> ，
<code>type Thunk = Box&lt;dyn Fn() + Send + 'static&gt;;</code></li>
<li>从不返回的 never type： <code>!</code>
，可以强转为其它任何类型，continue、panic 等均为此类型，可以用于
<code>match</code> ；</li>
<li><code>str</code> 是动态大小类型 DST（unsized types），
<code>&amp;str</code> 存储两个值：地址和长度，因此它的大小是 2 *
<code>usize</code> ；可以使用 <code>&amp;str</code> 、
<code>Box&lt;str&gt;</code> 或 <code>Rc&lt;str&gt;</code>
，但不能直接使用 <code>str</code> ，trait 对象同样如此；</li>
<li><code>?Sized</code> trait bound 与 <code>Sized</code> 相对，读作
“<code>T</code> 可能是也可能不是 <code>Sized</code> 的”，博人的泛型参数均为
<code>Sized</code> ；</li>
<li><code>fn(i32) -&gt; i32</code>
表示一个函数指针，函数指针实现了所有三个闭包
trait（<code>Fn</code>、<code>FnMut</code> 和 <code>FnOnce</code>）；函数指针可以作为返回值，闭包不能直接作为返回值，因为它表现为
trait，是 unsized 的，可以将其封装进 <code>Box</code> 返回，或通过 impl
trait 返回：</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">create_fn</span>() <span class="punctuation">-&gt;</span> <span class="keyword">impl</span> <span class="title class_">Fn</span>() &#123; <span class="comment">// 也可以写为 impl Fn(i32) -&gt; i32</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">text</span> = <span class="string">&quot;Fn&quot;</span>.<span class="title function_ invoke__">to_owned</span>();</span><br><span class="line">    <span class="keyword">move</span> || <span class="built_in">println!</span>(<span class="string">&quot;This is a: &#123;&#125;&quot;</span>, text)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>宏（Macros）：</p>
<ul>
<li>声明宏 <code>macro_rules!</code> ： <code>#[macro_export]</code>
使我们能够使用引入的 crate 中定义的宏（否则默认为私有）；多个模式使用
<code>;</code> 分隔，例： <code>vec![1, 2, 3]</code> 的宏：</li>
</ul>
<p><figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="meta">#[macro_export]</span></span><br><span class="line"><span class="built_in">macro_rules!</span> vec &#123;</span><br><span class="line">    ( $( $x:expr ),* ) =&gt; &#123;</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">temp_vec</span> = <span class="type">Vec</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">            $(</span><br><span class="line">                temp_vec.<span class="title function_ invoke__">push</span>($x);</span><br><span class="line">            )*</span><br><span class="line">            temp_vec</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>过程宏：</li>
</ul>
<p><figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> proc_macro;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[some_attribute]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">some_name</span>(input: TokenStream) <span class="punctuation">-&gt;</span> TokenStream &#123; ... &#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="附录">附录：</h2>
<ul>
<li>加上 <code>r#</code> 前缀后可以使用 Rust 的关键字；</li>
<li>使用 <code>_i</code> 表明一个变量不会被使用（如循环变量）；</li>
<li>turbofish： <code>basket.values().sum::&lt;u32&gt;()</code>
明确指定泛型参数；</li>
<li><code>cargo clippy</code> 是一系列 lint
的集合，能更智能地观察代码；</li>
<li><code>Default</code> trait 允许使用 <code>Struct::default()</code>
构造默认结构体；</li>
<li><code>AsRef</code> 允许引用间的转换，最常见的是对
<code>&amp;String</code> 使用 <code>as_ref()</code> 转换成
<code>&amp;str</code> 以同时兼容二者；</li>
<li><code>AsMut</code> 从调用者取一个可变引用，如获取：
<ul>
<li><code>Box&lt;T&gt;</code> 中的 <code>&amp;mut T</code>；</li>
<li><code>Vec&lt;T&gt;</code> 中的 <code>&amp;mut [T]</code> ；</li>
<li><code>String</code> 中的 <code>&amp;mut str</code> ；</li>
<li><code>Rc&lt;RefCell&lt;T&gt;&gt;</code> 中的
<code>RefMut&lt;T&gt;</code> ；</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title>Go 语法笔记</title>
    <url>/2023/09/23/Go-%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<ul>
<li>Go 是静态、强类型语言；</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main <span class="comment">// 定义包名</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span> <span class="comment">// 引入包</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 没有 init() 时的程序入口，可执行程序必须包含</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123; <span class="comment">// 注意大括号不能换行</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 当标识符以一个大写字母开头，就可以被外部包的代码所使用（public），</span></span><br><span class="line"><span class="comment">	 否则对包外不可见（protected）</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	fmt.Println(<span class="string">&quot;Hello, World!&quot;</span>) <span class="comment">// 不需要分号，除非一行多条语句</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<ul>
<li><strong>运行</strong>：
<ul>
<li>使用 <code>go run main.go</code> 直接执行，或使用
<code>go build main.go</code> 生成可执行文件 ；</li>
</ul></li>
<li><strong>数据类型</strong>：
<ul>
<li><code>bool</code> 、 <code>int</code> 、 <code>uint</code> 、
<code>float32</code> 、 <code>float64</code> 、 <code>complex64</code>
、 <code>complex128</code> 、 <code>string</code> （UTF-8）等；</li>
<li>指针、数组、 <code>struct</code> 、 <code>Channel</code>
、函数、切片、接口、 <code>Map</code> ；</li>
<li>类似 Java，基础类型为值类型，高级类型为引用；</li>
<li>交换值： <code>a, b = b, a</code> ；</li>
</ul></li>
<li><strong>变量声明</strong>：
<ul>
<li><code>var identifier1, identifier2 [type] [= value1, value2]</code>
（不赋初值自动赋零值），可以根据赋初值自动判定类型；</li>
<li>可以用 <code>a := 50</code> 直接声明（只能在函数体内）；</li>
</ul></li>
<li><strong>表达式</strong>：
<ul>
<li>基本类似于 C
语言；自增自减运算只能单独作为表达式，不能用于赋值语句；</li>
</ul></li>
<li><strong>常量定义</strong>：
<ul>
<li><code>const identifier [type] = value</code> ；</li>
</ul></li>
<li><strong>条件、循环语句</strong>：
<ul>
<li>基本相当于 C 语言删去条件括号；</li>
<li><strong>范围（range）</strong>： for-each 型循环：
<code>for key, value := range oldMap</code></li>
</ul></li>
<li><strong>函数声明</strong>：
<ul>
<li><code>func myFunction(a, b int, s *string) (int, string) &#123;&#125;</code>
，无返回值则省略；</li>
<li>传参均为传值（包括数组等，切片为传引用），想传引用只能
<code>s *string</code> ，调用 <code>*s</code> ；</li>
</ul></li>
<li><strong>匿名函数作闭包</strong>：
<ul>
<li><code>func add(x int) func(x int)(string, int) &#123; return func(x int)(string, int) &#123; ... &#125; &#125;</code>
；</li>
</ul></li>
<li><strong>方法</strong>：
<ul>
<li>包含了接受者的函数；</li>
<li><code>func (c Circle) getArea() float64 &#123; ... &#125;</code> ，调用
<code>c.getArea()</code> ；</li>
<li>没有 <code>this</code> 指针，直接使用参数名 <code>c</code> ；</li>
</ul></li>
<li><strong>数组</strong>：
<ul>
<li><code>var value = [3][2]int&#123;&#123;1, 2&#125;, &#123;3, 4&#125;, &#123;5, 6&#125;&#125;</code> ；</li>
<li>可以用 <code>[...]</code> 自动获取初始化列表个数；</li>
</ul></li>
<li><strong>指针</strong>：
<ul>
<li>类似 C，输出为一个整数，空值为 <code>nil</code> ；</li>
<li>类型声明从左往右读，右侧是左侧的定语（与 C 相反）；</li>
</ul></li>
<li><strong>struct 类型</strong>：
<ul>
<li>不包含方法，可以转换为 JSON；</li>
<li>指向 <code>struct</code> 的指针获取成员变量可以不带星号：
<code>ptr.a</code>
，但这个自动解引用只做了一级，多级需要手动解引用到一级；</li>
</ul></li>
<li><strong>切片（slice）</strong>：
<ul>
<li><code>var identifier []type</code> ，可以使用
<code>make([]T, length, [capacity])</code> ，length 为实际长度（即
r-l），capacity 为最大容量（即数组长度-l） ，对应有 <code>len()</code>
和 <code>cap()</code> 函数；</li>
<li>使用 <code>s := arr[:]</code>
创建数组<strong><em>引用</em></strong>，左闭右开类似 Python Numpy；</li>
<li>未初始化时为 <code>nil</code> ；</li>
<li>直接修改切片会影响它相关联的其余切片或原数组，但 <code>append</code>
会让切片和与它相关的切片和数组脱钩，而地址不变；</li>
<li>切片的 capacity 增长<strong><em>大致</em></strong>为每次两倍；</li>
</ul></li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">slices = <span class="built_in">append</span>(slices, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>); </span><br><span class="line">slices1 = <span class="built_in">make</span>([]<span class="type">int</span>, <span class="built_in">len</span>(slices), <span class="built_in">cap</span>(slices) * <span class="number">2</span>)</span><br><span class="line"><span class="built_in">copy</span>(slices1, slices) <span class="comment">// slices 拷贝进 slices1</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>集合（Map）</strong>：无序键值对集合，</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">v1 := m[<span class="string">&quot;apple&quot;</span>]</span><br><span class="line">v2, ok := m[<span class="string">&quot;pear&quot;</span>]  <span class="comment">// 如果键不存在，ok 的值为 false，v2 的值为该类型的零值</span></span><br><span class="line">m[<span class="string">&quot;apple&quot;</span>] = <span class="number">5</span> <span class="comment">// 插入/修改</span></span><br><span class="line"><span class="keyword">for</span> key, value := <span class="keyword">range</span> m &#123;</span><br><span class="line">	<span class="built_in">delete</span>(m, key) <span class="comment">// 删除</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>接口</strong>：
<ul>
<li>一个类型实现了一个接口包含的所有函数，它就实现了这个接口，从而可以实现多态；</li>
<li>本质是一个指针，可以指向任何实现了它的类对象；</li>
</ul></li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> interface_name <span class="keyword">interface</span> &#123;</span><br><span class="line">   method_name1 [return_type]</span><br><span class="line">   ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(struct_name_variable struct_name)</span></span> method_name1() [return_type] &#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Phone <span class="keyword">interface</span> &#123; call() &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> NokiaPhone <span class="keyword">struct</span> &#123; &#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(nokiaPhone NokiaPhone)</span></span> call() &#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> IPhone <span class="keyword">struct</span> &#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(iPhone *IPhone)</span></span> call() &#123; ... &#125; <span class="comment">// 修改 iphone 内属性</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> phone Phone</span><br><span class="line"></span><br><span class="line">phone = <span class="built_in">new</span>(NokiaPhone)</span><br><span class="line">phone.call()</span><br><span class="line"></span><br><span class="line">phone = <span class="built_in">new</span>(IPhone)</span><br><span class="line">phone.call()</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>异常</strong>：
<ul>
<li>是一个接口， <code>type error interface &#123; Error() string &#125;</code>
，实现了 <code>Error()</code> 的类即可抛出异常；</li>
<li>可通过 <code>return errors.New("...")</code> 生成错误信息；</li>
<li><code>panic-recover</code> 机制：类似
<code>try-catch</code>，发生异常时立即向上逐层返回并执行
<code>defer</code>（ <code>defer</code> 中也可以抛出
<code>panic</code>），直到被 <code>recover</code>
捕获或退出到最外层；</li>
<li><code>defer</code> 可以多次声明（需要在 <code>panic</code>
之前声明），在发生异常或正常结束时执行，按先进后出（后声明的先执行）；</li>
</ul></li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 以下代码执行输出 three</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> err := <span class="built_in">recover</span>() ; err != <span class="literal">nil</span> &#123;</span><br><span class="line">            fmt.Println(err)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line">    <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span>&#123; <span class="built_in">panic</span>(<span class="string">&quot;three&quot;</span>) &#125;()</span><br><span class="line">    <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span>&#123; <span class="built_in">panic</span>(<span class="string">&quot;two&quot;</span>) &#125;()</span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">&quot;one&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>并发（Goroutine）</strong>：
<ul>
<li><code>go func(params)</code> 开启轻量级线程；</li>
<li><strong>通道（Channel）</strong>： <code>ch &lt;- v</code> 把
<code>v</code> 送给通道 <code>ch</code> ，
<code>v[, ok] := &lt;- ch</code> 从通道接收数据给 <code>v</code> ；</li>
<li>通道声明： <code>ch := make(chan int[, 100])</code>
，默认无缓冲区；发送方在缓冲区满时会阻塞，接收方在缓冲区为空时会阻塞；</li>
<li><code>close(c)</code> 关闭通道（缓冲区仍然存在）后接收方的
<code>ok</code> 会得到 <code>false</code> ，否则会一直阻塞，据此可使用
<code>for i := range c</code> ；</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Go语言</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ Concurrency in Action - SECOND EDITION</title>
    <url>/2023/09/22/C-Concurrency-in-Action-SECOND-EDITION/</url>
    <content><![CDATA[<p>本文为此书中文译本前四章的读书笔记。</p>
<p><a
href="https://github.com/xiaoweiChen/CPP-Concurrency-In-Action-2ed-2019">https://github.com/xiaoweiChen/CPP-Concurrency-In-Action-2ed-2019</a></p>
<h2 id="pthread.h">&lt;pthread.h&gt;</h2>
<p>&lt;pthread.h&gt;是贴近底层的 POSIX 线程接口：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">pthread_create</span>()：创建一个新的线程。</span><br><span class="line"><span class="built_in">pthread_join</span>()：等待指定的线程退出，并回收其资源。</span><br><span class="line"><span class="built_in">pthread_detach</span>()：将指定的线程设置为分离状态，使其资源在退出时自动回收。</span><br><span class="line"><span class="built_in">pthread_exit</span>()：使当前线程退出，并返回指定的状态值。</span><br><span class="line"><span class="built_in">pthread_mutex_init</span>()：初始化互斥锁。</span><br><span class="line"><span class="built_in">pthread_mutex_destroy</span>()：销毁互斥锁。</span><br><span class="line"><span class="built_in">pthread_mutex_lock</span>()：尝试获取互斥锁，如果已经被其他线程占用，则阻塞等待。</span><br><span class="line"><span class="built_in">pthread_mutex_unlock</span>()：释放互斥锁。</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="thread">&lt;thread&gt;</h2>
<p>C++11 提供<code>#include &lt;thread&gt;</code>
头文件支持多线程，对C语言的<code>&lt;pthread.h&gt;</code>
（POSIX线程接口）做了进一步的抽象和封装。新标准 <code>std::thread</code>
提供了更高级的线程实现，使用面向对象、RAII 技术，在对象销毁时自动调用
<code>join()</code> 和 <code>detach()</code>
方法，避免手动管理线程资源和状态，且支持更好的可移植性：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">explicit</span> <span class="title">thread</span><span class="params">( Callable&amp;&amp; f, Args&amp;&amp;... args )</span></span>; <span class="comment">// 构造函数，参数可以是lambda函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">join</span><span class="params">()</span></span>; <span class="comment">// 阻塞等待线程退出并回收资源</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">detach</span><span class="params">()</span></span>; <span class="comment">// 将线程对象与线程执行状态分离，使其独立执行</span></span><br><span class="line"><span class="function"><span class="type">unsigned</span> <span class="type">int</span> <span class="title">hardware_concurrency</span><span class="params">()</span> <span class="keyword">noexcept</span></span>; <span class="comment">// 返回当前系统支持的线程并发数</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">joinable</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">noexcept</span></span>; <span class="comment">// 判断线程是否可被加入</span></span><br><span class="line"><span class="function">thread::id <span class="title">get_id</span><span class="params">()</span> <span class="keyword">noexcept</span></span>; <span class="comment">// 获取当前线程 id，等同于在线程内调用 std::this_thread::get_id()，无线程时返回默认值 std::thread::type</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">yield</span><span class="params">()</span> <span class="keyword">noexcept</span></span>; <span class="comment">// 让出当前线程时间片</span></span><br><span class="line"><span class="comment">// 休眠指定时间或到指定时间点</span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt; <span class="keyword">class</span> Rep, <span class="keyword">class</span> Period &gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">sleep_for</span><span class="params">( <span class="type">const</span> std::chrono::duration&lt;Rep, Period&gt;&amp; sleep_duration )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt; <span class="keyword">class</span> Clock, <span class="keyword">class</span> Duration &gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">sleep_until</span><span class="params">( <span class="type">const</span> std::chrono::time_point&lt;Clock, Duration&gt;&amp; sleep_time )</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>向函数传递指针或引用参数时应注意，线程的运行长度可能会超过参数的生命周期；</li>
<li>若 <code>std::thread</code> 对象销毁之前仍未决定 <code>join()</code>
或 <code>detach()</code>，程序会执行 <code>std::terminate()</code>
终止；</li>
<li>线程不可加入 / 分离的情况（均为 <code>joinable()</code>
）：已经加入/分离、未绑定函数启动；</li>
<li>有可能主线程已经结束，新线程构造函数还没执行完，因此可以用
<code>std::ref()</code> 表示左值引用参数，使用 <code>std::move()</code>
移动右值参数；</li>
<li>通过 <code>std::move()</code> 转移线程所有权；</li>
<li>执行的任务不能有返回值，需要返回值应使用 <code>future</code> ；</li>
<li>给一个已绑定线程的变量赋值新线程会造成 <code>std::terminate()</code>
；</li>
<li>C++17 标准建议但未纳入标准的 RAII 的线程类型封装（C++20 中的
<code>std::jthread</code> ）：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">joining_thread</span> &#123;</span><br><span class="line">	std::thread t;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">joining_thread</span>() <span class="keyword">noexcept</span> = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Callable,<span class="keyword">typename</span> ... Args&gt;</span></span><br><span class="line"><span class="function">	<span class="keyword">explicit</span> <span class="title">joining_thread</span><span class="params">(Callable&amp;&amp; func, Args&amp;&amp; ... args)</span>:</span></span><br><span class="line"><span class="function">	t(std::forward&lt;Callable&gt;(func), std::forward&lt;Args&gt;(args)...) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">explicit</span> <span class="title">joining_thread</span><span class="params">(std::thread t_)</span> <span class="keyword">noexcept</span>:</span></span><br><span class="line"><span class="function">	t(std::move(t_))&#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">joining_thread</span>(joining_thread&amp;&amp; other) <span class="keyword">noexcept</span>:</span><br><span class="line">	<span class="built_in">t</span>(std::<span class="built_in">move</span>(other.t))&#123;&#125;</span><br><span class="line"></span><br><span class="line">	joining_thread&amp; <span class="keyword">operator</span>=(joining_thread&amp;&amp; other) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">		<span class="keyword">if</span>（<span class="built_in">joinable</span>()）<span class="built_in">join</span>();</span><br><span class="line">		t = std::<span class="built_in">move</span>(other.t);</span><br><span class="line">		<span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	joining_thread&amp; <span class="keyword">operator</span>=(std::thread other) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> (<span class="built_in">joinable</span>()) <span class="built_in">join</span>();</span><br><span class="line">		t = std::<span class="built_in">move</span>(other);</span><br><span class="line">		<span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	~<span class="built_in">joining_thread</span>() <span class="keyword">noexcept</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> (<span class="built_in">joinable</span>()) <span class="built_in">join</span>();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">swap</span><span class="params">(joining_thread&amp; other)</span> <span class="keyword">noexcept</span> </span>&#123; t.<span class="built_in">swap</span>(other.t); &#125;</span><br><span class="line">	std::<span class="function">thread::id <span class="title">get_id</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">noexcept</span></span>&#123; <span class="keyword">return</span> t.<span class="built_in">get_id</span>(); &#125;</span><br><span class="line">	<span class="function"><span class="type">bool</span> <span class="title">joinable</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">noexcept</span> </span>&#123; <span class="keyword">return</span> t.<span class="built_in">joinable</span>(); &#125;</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">join</span><span class="params">()</span> </span>&#123; t.<span class="built_in">join</span>(); &#125;</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">detach</span><span class="params">()</span> </span>&#123; t.<span class="built_in">detach</span>(); &#125;</span><br><span class="line">	<span class="function">std::thread&amp; <span class="title">as_thread</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123; <span class="keyword">return</span> t; &#125;</span><br><span class="line">	<span class="function"><span class="type">const</span> std::thread&amp; <span class="title">as_thread</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">noexcept</span> </span>&#123; <span class="keyword">return</span> t; &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="chrono">&lt;chrono&gt;</h2>
<p><code>&lt;chrono&gt;</code>提供了一系列时间相关类型和函数：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> std::chrono::time_point&lt;std::chrono::system_clock&gt; system_time_point;</span><br><span class="line"><span class="keyword">typedef</span> std::chrono::time_point&lt;std::chrono::high_resolution_clock&gt; high_res_time_point;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> std::chrono::duration&lt;<span class="type">int</span>, std::ratio&lt;<span class="number">1</span>, <span class="number">1000</span>&gt;&gt; milliseconds;</span><br><span class="line"><span class="keyword">typedef</span> std::chrono::duration&lt;<span class="type">double</span>&gt; seconds;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> std::chrono::system_clock system_clock;</span><br><span class="line"><span class="keyword">typedef</span> std::chrono::steady_clock steady_clock;</span><br><span class="line"><span class="keyword">typedef</span> std::chrono::high_resolution_clock high_res_clock;</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> start = std::chrono::system_clock::<span class="built_in">now</span>(); <span class="comment">// 获取当前时间点</span></span><br><span class="line">std::chrono::milliseconds duration = std::chrono::<span class="built_in">milliseconds</span>(<span class="number">1000</span>); <span class="comment">// 定义一个时间段</span></span><br><span class="line">std::this_thread::<span class="built_in">sleep_for</span>(duration); <span class="comment">// 线程休眠指定的时间段</span></span><br><span class="line"><span class="keyword">auto</span> end = std::chrono::system_clock::<span class="built_in">now</span>(); <span class="comment">// 获取当前时间点</span></span><br><span class="line">std::chrono::duration&lt;<span class="type">double</span>&gt; elapsed_seconds = end - start; <span class="comment">// 计算时间点之间的差值</span></span><br><span class="line">std::cout &lt;&lt; elapsed_seconds.<span class="built_in">count</span>() &lt;&lt; <span class="string">&quot;s\n&quot;</span>; <span class="comment">// 输出时间间隔</span></span><br><span class="line"></span><br><span class="line">std::chrono::seconds s = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::seconds&gt; (ms); <span class="comment">// 有截断的显式类型转换</span></span><br><span class="line"></span><br><span class="line">std::chrono::hours <span class="comment">// 小时</span></span><br><span class="line">std::chrono::minutes <span class="comment">// 分钟</span></span><br><span class="line">std::chrono::seconds <span class="comment">// 秒</span></span><br><span class="line">std::chrono::milliseconds <span class="comment">// 毫秒</span></span><br><span class="line">std::chrono::microseconds <span class="comment">// 微秒</span></span><br><span class="line">std::chrono::nanoseconds <span class="comment">// 纳秒</span></span><br></pre></td></tr></table></figure>
<h2 id="mutex">&lt;mutex&gt;</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::mutex::<span class="built_in">lock</span>() <span class="comment">// 尝试获得锁，若被占用则阻塞</span></span><br><span class="line">std::mutex::<span class="built_in">try_lock</span>() <span class="comment">// 尝试获得锁，若被占用则立即返回 false</span></span><br><span class="line">std::mutex::<span class="built_in">unlock</span>() <span class="comment">// 释放锁</span></span><br><span class="line"><span class="comment">// 不建议使用以上成员函数，因为需要手动保证任何情况下结束都unlock()，以下是标准库提供的 RAII 的模板类</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用 lock_guard 对象进行对参数对象的加锁解锁，不需要再手动调用对象的lock()和unlock()</span></span><br><span class="line"><span class="comment">// lock_guard 析构时会自动调用对应对象的解锁，常与 mutex 一同私有定义在加锁类中</span></span><br><span class="line"><span class="comment">// adopt_lock 表示此锁已经被外部线程或外部代码锁定，以便接管它并在该线程退出作用域时自动释放锁</span></span><br><span class="line"><span class="comment">// defer_lock 表示不立即锁定</span></span><br><span class="line">std::<span class="built_in">lock</span>(lhs.m, rhs.m);</span><br><span class="line"><span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock_a</span><span class="params">(lhs.m,std::adopt_lock)</span></span>;</span><br><span class="line"><span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock_b</span><span class="params">(rhs.m,std::adopt_lock)</span></span>;</span><br><span class="line"><span class="comment">// C++17 支持自动模板类参数推导，以及可以同时为多个互斥量上锁的 scoped_lock</span></span><br><span class="line"><span class="function">std::scoped_lock <span class="title">lock</span><span class="params">(mutex1, mutex2, ...)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// unique_lock 可以手动 lock() 和 unlock()，也可以使用 std::lock(ul1, ul2)</span></span><br><span class="line"><span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(std::mutex)</span></span></span><br><span class="line"><span class="function"><span class="comment">// 占用空间稍多，稍慢，但还提供：try_lock(),</span></span></span><br><span class="line"><span class="function"><span class="comment">// release() 释放所有权但不解锁互斥量, reset() 释放所有权且自动解锁互斥量</span></span></span><br><span class="line"><span class="function"><span class="comment">// try_lock_for(), try_lock_until() 尝试获得锁，等待一定时间或等到特定时间</span></span></span><br><span class="line"><span class="function"><span class="comment">// owns_lock()返回是否持有互斥量所有权</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">template</span> &lt;<span class="keyword">class</span> Callable, <span class="keyword">class</span>... Args&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">call_once</span><span class="params">(std::once_flag&amp; flag, Callable&amp;&amp; f, Args&amp;&amp;... args)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">// C++17 引入的“读者-写者”锁 shared_mutex，支持 lock() 和 try_lock()</span></span><br><span class="line"><span class="comment">// 使用 shared_lock 获取多个共享锁（读锁），使用 unique_lock 获取一个独占锁（写锁）</span></span><br><span class="line"><span class="comment">// C++14 引入的 shared_timed_lock</span></span><br></pre></td></tr></table></figure>
<ul>
<li>在需要多个互斥量时，按固定顺序上锁，最好使用 <code>lock</code>
同时上锁；</li>
<li>避免将被保护量暴露给外界传入的可调用对象，避免在持有锁时调用外部代码；</li>
<li>C++11 已保障 <code>static</code> 变量的线程安全；</li>
<li>嵌套锁 <code>recursive_mutex</code>
支持多次上锁，同等次数解锁后方可使用；</li>
<li>C++17 引入的“读者-写者”锁 <code>shared_mutex</code>，支持
<code>lock()</code> 和 <code>try_lock()</code>，使用
<code>shared_lock</code> 获取多个共享锁（读锁），使用
<code>unique_lock</code> 获取一个独占锁（写锁）；</li>
<li>C++14 引入的 shared_timed_lock 在 shared_mutex 基础上还支持了
<code>try_lock_for()</code> 和 <code>try_lock_until()</code>；</li>
<li><code>std::time_mutex</code> 和
<code>std::recursive_timed_mutex</code> 支持 <code>try_lock_for()</code>
和 <code>try_lock_until()</code> ；</li>
</ul>
<h2 id="condition_variable">&lt;condition_variable&gt;</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 一般持有一个 unique_lock，先 unlock()，然后 wait() 阻塞，在被其它线程唤醒后判断 Callable 是否为真</span></span><br><span class="line"><span class="comment">// 若为真，wait() 返回，重新 lock() 并继续执行；否则 wait() 继续阻塞或等待</span></span><br><span class="line"><span class="comment">// 伪唤醒次数不可知，故 Callable 不应有副作用</span></span><br><span class="line">std::condition_variable.<span class="built_in">wait</span>(lock, Callable)</span><br><span class="line">std::condition_variable.<span class="built_in">notify_one</span>() <span class="comment">// 随机唤醒一个等待的线程</span></span><br><span class="line">std::condition_variable.<span class="built_in">notify_all</span>() <span class="comment">// 唤醒所有等待线程</span></span><br></pre></td></tr></table></figure>
<ul>
<li>一般持有一个 <code>unique_lock</code>，先
<code>unlock()</code>，然后 <code>wait()</code>
阻塞，在被其它线程唤醒后判断 <code>Callable</code>
是否为真。若为真，<code>wait()</code> 返回，重新 <code>lock()</code>
并继续执行；否则 <code>wait()</code> 继续阻塞或等待；</li>
</ul>
<h2 id="future">&lt;future&gt;</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::future&lt;<span class="type">int</span>&gt; answer = std::<span class="built_in">async</span>(func);</span><br><span class="line">cout &lt;&lt; answer.<span class="built_in">get</span>(); <span class="comment">// 阻塞直到得到结果</span></span><br><span class="line"></span><br><span class="line"><span class="function">std::package_task&lt;<span class="title">int</span><span class="params">(<span class="type">int</span>, <span class="type">int</span>)</span>&gt; <span class="title">task</span><span class="params">(func)</span></span>;</span><br><span class="line">std::future&lt;<span class="type">int</span>&gt; result = task.<span class="built_in">get_future</span>();</span><br><span class="line"><span class="type">int</span> sum = result.<span class="built_in">get</span>();</span><br><span class="line"></span><br><span class="line">std::promise&lt;<span class="type">int</span>&gt; p;</span><br><span class="line">std::future&lt;<span class="type">int</span>&gt; f = p.<span class="built_in">get_future</span>();</span><br><span class="line"><span class="function">std::thread <span class="title">t</span><span class="params">(func, std::ref(p))</span></span>;</span><br><span class="line"><span class="type">int</span> result = f.<span class="built_in">get</span>(); <span class="comment">// 等待到 func() 函数执行 p.set_value(int) 或 p.set_exception(std::current_exception())</span></span><br><span class="line">t.<span class="built_in">join</span>();</span><br><span class="line"><span class="comment">// 对应的函数写法：</span></span><br><span class="line"><span class="keyword">try</span>&#123; p.<span class="built_in">set_value</span>(<span class="built_in">func</span>()); &#125; <span class="built_in">catch</span> (...) &#123; p.<span class="built_in">set_exception</span>(std::<span class="built_in">copy_exception</span>(std::<span class="built_in">logic_error</span>(<span class="string">&quot;func&quot;</span>))); &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 可拷贝 future</span></span><br><span class="line"><span class="function">std::shared_future&lt;<span class="type">int</span>&gt; <span class="title">sf</span><span class="params">(std::move(f))</span></span>; <span class="comment">// 或 p.get_future() 或 f.share()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 锁存器，位于 &lt;experimental/latch&gt;，当 count_down() 到 0 之后就绪</span></span><br><span class="line">std::<span class="function">experimental::latch <span class="title">done</span><span class="params">(thread_count)</span></span>;</span><br><span class="line">std::vector&lt;std::future&lt;<span class="type">void</span>&gt;&gt; <span class="built_in">threads</span>(thread_count);</span><br><span class="line">threads[i] = std::<span class="built_in">async</span>(std::launch::async, []&#123; done.<span class="built_in">count_down</span>(); &#125;);</span><br><span class="line">done.<span class="built_in">wait</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 栅栏，位于 &lt;experimental/barrier&gt;，当所有线程到达后会就绪</span></span><br><span class="line"><span class="comment">// 锁存器不可复用，栅栏可复用，故可用于循环</span></span><br><span class="line">std::<span class="function">experimental::barrier <span class="title">sync</span><span class="params">(num_threads)</span></span>;</span><br><span class="line"><span class="function">std::vector&lt;thread&gt; <span class="title">threads</span><span class="params">(num_threads)</span></span>;</span><br><span class="line">threads[i] = <span class="built_in">thread</span>([]&#123; sync.<span class="built_in">arrive_and_wait</span>(); <span class="built_in">do_something</span>(); sync.<span class="built_in">arrive_and_wait</span>(); &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>可以在 <code>async</code> 的 第一个参数中选择
<code>std::launch::async</code> 使其在独立线程运行或
<code>std::launch::deferred</code> 使其延迟至 <code>wait()</code> 或
<code>get()</code> 时再运行，默认为二者的或；</li>
<li><code>flex_barrier</code>
有一个额外的构造函数，传入一个函数和线程数量。当所有线程都到达栅栏处，这个函数就由其中一个线程运行。</li>
</ul>
<h2 id="atomic">&lt;atomic&gt;</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">std::atomic&lt;<span class="type">int</span>&gt; <span class="title">cnt</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br><span class="line"><span class="built_in">load</span>(), <span class="built_in">store</span>() <span class="comment">// 以原子方式读写</span></span><br><span class="line"><span class="built_in">exchange</span>() <span class="comment">// 交换原子该值与给定的值，返回之前的值</span></span><br><span class="line"><span class="comment">// 以原子方式比较对象值和 expected 值，相等则设置为 desired 并返回 true，否则将 expected 设为当前对象的值并返回 false</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">compare_exchange_weak</span><span class="params">(T&amp; expected, T desired,</span></span></span><br><span class="line"><span class="params"><span class="function">	std::memory_order success = std::memory_order_seq_cst,</span></span></span><br><span class="line"><span class="params"><span class="function">	std::memory_order failure = std::memory_order_seq_cst)</span></span>;</span><br><span class="line"><span class="comment">// 参数与 weak 相同，若比较和交换操作失败，则直接将 expected 设为当前对象值以保证强一致性</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">compare_exchange_strong</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="keyword">operator</span> <span class="title">T</span><span class="params">()</span> <span class="comment">// 类型转换函数</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">// atomic_flag 只有 true 和 false 两种状态，用于实现自旋锁</span></span></span><br><span class="line"><span class="function">std::atomic_flag flag </span>= ATOMIC_FLAG_INIT; <span class="comment">// 特定宏定义方式初始化</span></span><br><span class="line"><span class="keyword">while</span> (flag.<span class="built_in">test_and_set</span>(std::memory_order_acquire)); <span class="comment">// 若对象被设置，则返回 true，否则设置之并返回 false</span></span><br><span class="line"><span class="built_in">do_something</span>();</span><br><span class="line"><span class="built_in">clear</span>() <span class="comment">// 将值设置为 false</span></span><br></pre></td></tr></table></figure>
<ul>
<li>本章底层高级操作较多，暂略</li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title>Unity 远程真机调试插件开发</title>
    <url>/2023/08/12/Unity-%E8%BF%9C%E7%A8%8B%E7%9C%9F%E6%9C%BA%E8%B0%83%E8%AF%95%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<p><strong>项目目标</strong>：完成远程真机调试插件，实现对端侧 3D/XR
场景的 Unity 实时场景部署与调试；</p>
<p><strong>具体内容</strong>：</p>
<ol type="1">
<li>在端侧构建调试 SDK，用于接收 Unity 发送的命令，和向 Unity
同步状态；</li>
<li>在 Unity 中基于插件实现Debug Server，用于和端侧进行实时通信（Unity
场景快速导出并推送到端侧）和同步状态（Unity
场景双向状态同步调试）；</li>
<li>PC端：MacOS，移动端：iOS；</li>
</ol>
<span id="more"></span>
<p>阶段任务概要：</p>
<ul>
<li>端侧 DebugSDK 技术选型 - Unity / <strong>C++</strong>，Unity
插件技术选型 - OC / <strong>C++</strong></li>
<li>通信协议选型：Socket Raw Packet / <strong>gRPC + Protobuf</strong> /
Hybrid (Raw Packet + RPC)</li>
<li>基础 Socket 通道搭建：Unity Socket Server (nc test)、Socket
Client</li>
<li>RPC 通道搭建：Unity RPC、iOS gRPC、C/S 双端互调</li>
</ul>
<h2 id="unity-c插件开发基础">Unity C++插件开发基础</h2>
<p>参考：</p>
<ul>
<li>官网介绍：<a
href="https://learn.microsoft.com/en-us/dotnet/fundamentals/">.NET</a>，<a
href="https://docs.unity.cn/2023.2/Documentation/Manual/Plugins.html">Plugin，</a><a
href="https://learn.microsoft.com/zh-cn/dotnet/standard/managed-code">托管代码，</a><a
href="https://learn.microsoft.com/zh-cn/dotnet/standard/native-interop/pinvoke">P/Invoke</a>，<a
href="https://www.mono-project.com/docs/advanced/pinvoke/">Mono
Runtime官网对P/Invoke的介绍</a>；</li>
<li>P/Invoke：<a href="https://www.jacksondunstan.com/articles/3938">C++
Scripting: Part 1 – C#/C++ Communication</a>，<a
href="https://www.cnblogs.com/herenzhiming/articles/6688804.html">C#与C/C++的交互（PInvoke）</a>，<a
href="https://www.jianshu.com/p/06db6d0109db">Create A Native Plugin For
Unity</a>，<a
href="https://kyochow.github.io/articles/2020/10/12/1602495480321.html">关于Unity
Native插件的开发</a>，<a
href="https://www.jianshu.com/p/65bb18513f19">Unity与C++交互入门(1)</a>，<a
href="https://rafalwilinski.medium.com/tutorial-create-c-c-plugins-for-unity3d-dbde7f67454#.hqsjain5e">Tutorial
— Create C/C++ plugins for Unity3D</a>，<a
href="https://rustcc.cn/article?id=3b8241d0-c4ca-4f49-8e07-0a5142b00f59">Rust
FFI 编程 - FFI 概述</a></li>
<li>插件开发：<a href="https://www.jianshu.com/p/183695196f02">Unity
3D编辑器插件开发</a>，<a
href="https://www.cnblogs.com/yzx885059439/p/14497026.html">Unity3D插件开发教程</a>，<a
href="https://developer.aliyun.com/article/69190">开发unity插件——一次搞定unity编辑器常用功能</a></li>
</ul>
<p>.NET使用CIL作为高级语言与机器语言的中间层以实现跨平台，且使用公共语言运行时CLR（支持提前AOT和实时JIT类型），无论使用的是Mono、.NET
Framework还是.NET
Core。将执行过程交由运行时管理（如自动内存管理、安全边界、类型安全等）的代码称为托管代码（Managed
Code）；直接运行编译出的机器语言而不依赖运行时的代码称为原生代码（Native
Code）。二者各有优势和局限性，具体见官网介绍。Unity最常用的托管代码形式插件使用C#语言，原生插件可以使用C/C++/Objective-C等。.NET中，C#与C++的互操作（Interop）可以通过P/Invoke实现（也可以使用C++/CLI作为中间层，但Mono不支持）。</p>
<p>Unity native 插件开发流程：C++ → C API → 打包 → C# 封装接口。</p>
<p>在 Safe Mode 下 C# 与 C++ 无法直接交互，C++ 需要包装成 C API，由 C#
调用 C API。 插件包：Android 打包成 <code>so</code>，IOS 打包成
framework 或者 <code>.a</code>，macOS 打包成
<code>.bundle</code>，Windows 打包成 dll。Windows 放在
<code>Plugins/x86(x64)</code> 目录下，Mac 直接放在 <code>Plugins</code>
目录下，iOS 放在 <code>Plugins/iOS</code> 目录下，Android 放在
<code>Plugins/Android/libs/armeabi-v7a</code>
目录下。如果修改了本地插件，需要将 dll 或者 bundle 覆盖了之后重启 Unity,
不然还是会使用老的 Native Plugin。</p>
<p>CMakeLists.txt：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cmake_minimum_required</span>(VERSION <span class="number">3.5</span>)</span><br><span class="line"><span class="built_in">project</span>(UnityPlugin)</span><br><span class="line"></span><br><span class="line"><span class="built_in">aux_source_directory</span>(. src) # 搜索当前目录下所有.cpp文件放入$&#123;src&#125;</span><br><span class="line"><span class="built_in">aux_source_directory</span>(channel.cpp lib) # 需要编成.dylib的文件</span><br><span class="line"></span><br><span class="line"># C++编译标准</span><br><span class="line"><span class="built_in">set</span>(CMAKE_CXX_STANDARD <span class="number">11</span>)</span><br><span class="line"><span class="built_in">set</span>(CMAKE_CXX_STANDARD_REQUIRED ON)</span><br><span class="line"># 添加编译选项</span><br><span class="line"><span class="built_in">set</span>(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -fms-extensions&quot;</span>)</span><br><span class="line"></span><br><span class="line"># 生成可执行文件</span><br><span class="line"></span><br><span class="line"><span class="built_in">add_executable</span>(main $&#123;src&#125;)</span><br><span class="line"></span><br><span class="line"># 生成.bundle文件</span><br><span class="line"></span><br><span class="line"># <span class="built_in">add_library</span>(project1 MODULE $&#123;lib&#125;) #编译为程序资源包 *.bundle</span><br><span class="line"># <span class="built_in">set_target_properties</span>(project1 PROPERTIES BUNDLE TRUE)</span><br><span class="line"></span><br><span class="line"># 设置生成.bundle文件的相关参数</span><br><span class="line"><span class="built_in">set</span>(MACOSX_BUNDLE_BUNDLE_NAME <span class="string">&quot;ChannelPlugin&quot;</span>)</span><br><span class="line"><span class="built_in">set</span>(MACOSX_BUNDLE_BUNDLE_VERSION <span class="string">&quot;1.0.0&quot;</span>)</span><br><span class="line"></span><br><span class="line"># 添加源文件生成共享库</span><br><span class="line"><span class="built_in">add_library</span>(ChannelPlugin SHARED channel.cpp)</span><br><span class="line"></span><br><span class="line"># 设置.bundle文件的输出路径</span><br><span class="line"><span class="built_in">set_target_properties</span>(ChannelPlugin PROPERTIES</span><br><span class="line">  OUTPUT_NAME ChannelPlugin</span><br><span class="line">  LIBRARY_OUTPUT_DIRECTORY <span class="string">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/bundles&quot;</span></span><br><span class="line">  ARCHIVE_OUTPUT_DIRECTORY <span class="string">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/bundles&quot;</span></span><br><span class="line">  RUNTIME_OUTPUT_DIRECTORY <span class="string">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/bundles&quot;</span></span><br><span class="line">  BUNDLE_OUTPUT_DIRECTORY <span class="string">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/bundles&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 设置.bundle文件的资源文件</span><br><span class="line"><span class="built_in">set_source_files_properties</span>(</span><br><span class="line">  <span class="string">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/bundles&quot;</span></span><br><span class="line">  PROPERTIES MACOSX_PACKAGE_LOCATION <span class="string">&quot;/&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>channel.h头文件：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> CHANNEL_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CHANNEL_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EXTERN_C extern <span class="string">&quot;C&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EXTERN_C</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> EXPORT_API</span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> UNITY_METRO </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EXPORT_API EXTERN_C __declspec(dllexport) __stdcall </span></span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> UNITY_WIN </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EXPORT_API EXTERN_C __declspec(dllexport) </span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span> </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EXPORT_API EXTERN_C</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* EXPORT_API*/</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">EXPORT_API <span class="type">int</span> <span class="title">func</span><span class="params">(<span class="type">int</span> x)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* CHANNEL_H*/</span></span></span><br></pre></td></tr></table></figure>
<p>在所有出现 <code>func</code> 声明或定义的时候都要带
<code>EXPORT_API</code> ；将 /bundles 中的 .dylib
文件复制到Unity的Assets/Plugins下，将 C#
插件放入Assets/Editor下即可。</p>
<p>注意：Unity
改变C#脚本后会实时重编译，但在移入新.dylib文件并不会，需要退出重新进入
Unity 项目。</p>
<h2 id="rpc-协议选型与通道搭建">RPC 协议选型与通道搭建</h2>
<p>参考：<a
href="https://doc.oschina.net/grpc">gRPC官方文档中文版</a>，<a
href="https://grpc.io/docs/">gRPC官方文档</a>，<a
href="https://protobuf.dev/overview/">Protocol Buffer官方文档</a></p>
<p>gRPC是一个高性能、通用的开源RPC框架，其由Google
2015年主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf序列化协议开发，且支持众多开发语言。</p>
<p>RPC
的主要目的是让客户端可以像调用函数一样直接与服务端通信，尽可能使网络交互过程变得透明。使用时，首先需要在
.proto
文件中定义各个函数原型与数据结构（将作为函数参数传递，也就是网络传输的数据），然后
Protobuf 会根据 .proto 生成桩程序 demo.pb.cc 和
demo.pb.h（这两个文件不应被用户修改），gRPC 再生成 demo.grpc.pb.cc 和
demo.grpc.pb.h（这两个文件也一般无需修改），最后用户在自定义程序
demo.client 和 demo.server 中自定义需要的操作和传递的信息。</p>
<p>具体安装使用方法：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">brew install autoconf automake libtool pkg-config <span class="comment"># 安装依赖库</span></span><br><span class="line">brew install protobuf grpc</span><br><span class="line"><span class="built_in">export</span> MY_INSTALL_DIR=<span class="variable">$HOME</span>/.local/share <span class="comment"># 自定义安装路径</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;<span class="variable">$MY_INSTALL_DIR</span>/bin:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line">git <span class="built_in">clone</span> --recurse-submodules -b v1.56.0 --depth 1 --shallow-submodules https://github.com/grpc/grpc</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> grpc</span><br><span class="line"><span class="built_in">mkdir</span> -p cmake/build</span><br><span class="line"><span class="built_in">pushd</span> cmake/build</span><br><span class="line">cmake -DgRPC_INSTALL=ON -DgRPC_BUILD_TESTS=OFF -DCMAKE_INSTALL_PREFIX=<span class="variable">$MY_INSTALL_DIR</span> ../..</span><br><span class="line">make -j 4</span><br><span class="line">make install</span><br><span class="line"><span class="built_in">popd</span></span><br></pre></td></tr></table></figure>
<p>重新生成gRPC代码：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> examples/cpp/helloworld/cmake/build</span><br><span class="line"><span class="comment"># 重新生成 helloworld.pb.&#123;h,cc&#125; 和 helloworld.grpc.pb.&#123;h,cc&#125;</span></span><br><span class="line">make helloworld.grpc.pb.o</span><br><span class="line"><span class="comment"># 实际运行的是以下两条命令：</span></span><br><span class="line">protoc -I ../../protos --grpc_out=. --plugin=protoc-gen-grpc=`<span class="built_in">which</span> grpc_cpp_plugin` ../../protos/helloworld.proto</span><br><span class="line">protoc -I ../../protos --cpp_out=. ../../protos/helloworld.proto</span><br><span class="line"><span class="comment"># 用户自行修改my_project/下的.cc代码</span></span><br><span class="line">make -j 4</span><br><span class="line">./greeter_server</span><br><span class="line">./greeter_client</span><br></pre></td></tr></table></figure>
<p>目录结构：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cpp/</span><br><span class="line">	my_project/</span><br><span class="line">		cmake/</span><br><span class="line">			build/</span><br><span class="line">		greeter_client.cc</span><br><span class="line">		greeter_server.cc</span><br><span class="line">proto/</span><br><span class="line">	my_project.proto</span><br></pre></td></tr></table></figure>
<p>调通后，同样依照官方手册调通 Objective-C 语言的 gRPC
（仅支持客户端）。然后修改 CMakeLists.txt 文件以得到 .dylib
文件，从而导入到 Unity 中被插件调用。</p>
<p>至此，我们已经能够实现在 Unity 上通过 C#
脚本实时获取场景树信息（Unity 序列化方案目前采用<a
href="https://kuroha.vip/unity/unity_jsonutility.html">JsonUtility</a>），并通过跨语言互操作将信息传递给
C++ gRPC，再通过 gRPC 实时传输至客户端（可以由客户端每 0.1
秒发送一次请求），最后客户端拿到 Unity 场景树信息后在本地重建场景。</p>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ 部分心得总结</title>
    <url>/2023/08/12/C-%E9%83%A8%E5%88%86%E5%BF%83%E5%BE%97%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="代码书写">代码书写</h2>
<ul>
<li>代码书写规范基本遵循 <a
href="https://github.com/google/styleguide">谷歌代码书写规范</a>，<a
href="https://zh-google-styleguide.readthedocs.io/en/latest/">中文版</a>；</li>
<li>不使用<code>using namespace std</code>，不使用<code>goto</code>，不使用<code>vector&lt;bool&gt;</code>，使用<code>using</code>代替<code>typedef</code>；</li>
<li>谨慎使用宏定义（尽可能使用<code>const</code>代替宏），<code>#</code>代表将宏参数内容转换成字符串，<code>##</code>代表将两个参数内容连接成为一个字符串；</li>
<li>一个可参考的 C++
工程目录结构：https://github.com/hattonl/cpp-project-structure</li>
<li>一些常见的注释约定：<code>// TODO</code>（待办），<code>// FIXME</code>（待修复），<code>// HACK</code>（临时解决方案），<code>// NOTE</code>（备注），<code>// OPTIMIZE</code>（待优化），<code>// REVIEW</code>（待审查），<code>// DEPRECATED</code>（已过时）；</li>
</ul>
<span id="more"></span>
<h2 id="errormessage.h">ErrorMessage.h</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> ERRORMESSAGE_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ERRORMESSAGE_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// The total length of message should not exceed 2047 bytes.</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> make_error_message(message) make_error_message_raw(__FILE__, __FUNCTION__, __LINE__, (message))</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> std::string <span class="title">make_error_message_raw</span><span class="params">(std::string file, std::string function, <span class="type">int</span> line, std::string message)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> file + <span class="string">&quot;:\n|\n|----&quot;</span> + function + <span class="string">&quot; (line &quot;</span> + std::<span class="built_in">to_string</span>(line) + <span class="string">&quot;): \n     |\n     |---- error: &quot;</span> + message + <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> die_if_error(condition_true, output_message) \</span></span><br><span class="line"><span class="meta">     ((condition_true) ? 0 : (std::cerr &lt;&lt; (output_message), exit(1), 1))</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// ERRORMESSAGE_H</span></span></span><br></pre></td></tr></table></figure>
<h2 id="pimpl">pImpl</h2>
<p><a href="https://en.cppreference.com/w/cpp/language/pimpl">Pointer to
implementation</a> 是一种编程技巧。</p>
<p>场景一：某个头文件定义了一个类的各项成员与虚函数，如果此后这个头文件被修改，其对应的
ABI
将改变，从而只能重新编译此头文件及其依赖项。我们希望不将类的具体定义放在头文件中，从而加速编译，并获得更好的
ABI 稳定性；</p>
<p>场景二：在某个头文件中，一个类声明了另一个文件定义的类的指针作为其成员变量。当我们不希望引入对应头文件（可能造成头文件泄露）时，我们需要使用前向声明<code>class Type;</code>
，但是 C++11
之后的智能指针<code>unique_ptr</code>不支持不完整类型（因为需要对应类型的各项信息才能帮助释放），因此我们不希望将类成员变量定义直接放入头文件中；</p>
<p>在这两个情形中，我们都不希望在头文件中定义类的具体信息。于是我们在头文件的类中定义一个嵌套类，所有原先类的成员变量和函数，都放入嵌套类中。头文件仅声明一个指向该嵌套类的<code>unique_ptr</code>，具体嵌套类的成员变量和函数均放入
.cpp 源文件中实现。</p>
<p>为了实现这一点， <code>unique_ptr</code>
要求我们在头文件中显式声明外层类的特殊成员函数（构造、析构、拷贝构造、拷贝赋值、移动构造、移动赋值），并且如果不禁用某函数（即希望自定义函数或使用<code>= default</code>，不使用<code>= delete</code>），则必须在源文件中定义（无法直接在头文件中定义一个不完全类型的成员函数）。具体实现见上方官方链接。</p>
<p>在官方示例中，使用了目前还未标准化的<code>std::experimental::propagate_const&lt;std::unique_ptr&lt;impl&gt;&gt; pImpl;</code>
，它能够向内传递指针对象的常量性。通常情况下，无法通过一个指向常量的指针（pointer
to
const）修改它指向对象的成员变量，也无法调用它的变量成员函数。但使用嵌套类后，可以通过调用
此指针指向的对象 内的 指向嵌套类对象的指针 指向的对象 的 成员函数
间接修改那个嵌套类。举例：<code>object_ptr-&gt;pImpl-&gt;var_func()</code>。也就是说，嵌套类不传递常量性，因此必须通过此方法实现常量性的正确传递。</p>
<h2 id="c-实现多客户端-tcp-通信">C++ 实现多客户端 TCP 通信</h2>
<p>参考：</p>
<p><a
href="https://developer.aliyun.com/article/721543">C++并发编程（C++11到C++17）</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/405416697">Socket
编程详解</a></p>
<p>服务端：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;netdb.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/socket.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;netinet/in.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;arpa/inet.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> IP_PORT = <span class="number">8888</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> MAX_CLIENTS = <span class="number">10</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> BUFFER_SIZE = <span class="number">1024</span>;</span><br><span class="line"></span><br><span class="line">std::mutex mtx;</span><br><span class="line">std::vector&lt;<span class="type">int</span>&gt; clients;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">handle_client</span><span class="params">(<span class="type">int</span> client_socket)</span> </span>&#123;</span><br><span class="line">    <span class="type">char</span> buffer[BUFFER_SIZE];</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;------------------------------&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        <span class="comment">// 接收数据</span></span><br><span class="line">        <span class="built_in">memset</span>(buffer, <span class="number">0</span>, BUFFER_SIZE);</span><br><span class="line">        <span class="type">int</span> bytes_read = <span class="built_in">recv</span>(client_socket, buffer, BUFFER_SIZE, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (bytes_read &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            std::cerr &lt;&lt; <span class="string">&quot;Failed to receive data from client&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">            <span class="built_in">close</span>(client_socket);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        buffer[bytes_read] = <span class="string">&#x27;\0&#x27;</span>;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Received &quot;</span> &lt;&lt; bytes_read &lt;&lt; <span class="string">&quot; bytes: &quot;</span> &lt;&lt; buffer &lt;&lt; std::endl;</span><br><span class="line">        <span class="comment">// 发送数据</span></span><br><span class="line">        <span class="function">std::string <span class="title">message</span><span class="params">(buffer)</span></span>;</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mtx)</span></span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;client: clients) &#123;</span><br><span class="line">                <span class="type">int</span> num_bytes_sent = <span class="built_in">send</span>(client, message.<span class="built_in">c_str</span>(), message.<span class="built_in">length</span>(), <span class="number">0</span>);</span><br><span class="line">                <span class="keyword">if</span> (num_bytes_sent &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                    std::cerr &lt;&lt; <span class="string">&quot;Failed to send data to client&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">                    <span class="built_in">close</span>(client_socket);</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                std::cout &lt;&lt; <span class="string">&quot;Sent &quot;</span> &lt;&lt; message.<span class="built_in">length</span>() &lt;&lt; <span class="string">&quot; bytes: &quot;</span> &lt;&lt; message &lt;&lt; std::endl;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">close</span>(client_socket);</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mtx)</span></span>;</span><br><span class="line">        clients.<span class="built_in">erase</span>(std::<span class="built_in">remove</span>(clients.<span class="built_in">begin</span>(), clients.<span class="built_in">end</span>(), client_socket), clients.<span class="built_in">end</span>());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建一个套接字</span></span><br><span class="line">    <span class="type">int</span> server_socket = <span class="built_in">socket</span>(AF_INET, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (server_socket &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;Failed to create socket&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 绑定套接字到本地地址和端口</span></span><br><span class="line">    sockaddr_in server_address&#123;&#125;;</span><br><span class="line">    server_address.sin_family = AF_INET; <span class="comment">// IPv4</span></span><br><span class="line">    server_address.sin_addr.s_addr = <span class="built_in">htonl</span>(INADDR_ANY); <span class="comment">// 0.0.0.0 即本机</span></span><br><span class="line">    server_address.sin_port = <span class="built_in">htons</span>(IP_PORT);</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">bind</span>(server_socket, (sockaddr *)&amp;server_address, <span class="built_in">sizeof</span>(server_address)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;Failed to bind socket to local address and port&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        <span class="built_in">close</span>(server_socket);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 监听套接字，等待连接请求</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">listen</span>(server_socket, MAX_CLIENTS) &lt; <span class="number">0</span>) &#123; <span class="comment">// 可同时排队的客户端最大连接个数</span></span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;Failed to listen on socket&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        <span class="built_in">close</span>(server_socket);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Listening on 0.0.0.0:&quot;</span> &lt;&lt; IP_PORT &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="comment">// 接受连接请求，返回一个新的套接字</span></span><br><span class="line">        sockaddr_in client_address&#123;&#125;;</span><br><span class="line">        <span class="type">socklen_t</span> client_address_size = <span class="built_in">sizeof</span>(client_address);</span><br><span class="line">        <span class="type">int</span> client_socket = <span class="built_in">accept</span>(server_socket, (sockaddr*)&amp;client_address, &amp;client_address_size);</span><br><span class="line">        <span class="keyword">if</span> (client_socket &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            std::cerr &lt;&lt; <span class="string">&quot;Error: Failed to accept client connection.&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">            <span class="built_in">close</span>(server_socket);</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Accepted client connection from &quot;</span> &lt;&lt; <span class="built_in">inet_ntoa</span>(client_address.sin_addr) &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; <span class="built_in">ntohs</span>(client_address.sin_port) &lt;&lt; std::endl;</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mtx)</span></span>;</span><br><span class="line">            clients.<span class="built_in">push_back</span>(client_socket);</span><br><span class="line">        &#125;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;New client connected: &quot;</span> &lt;&lt; <span class="built_in">inet_ntoa</span>(client_address.sin_addr) &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; <span class="built_in">ntohs</span>(client_address.sin_port) &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">        std::<span class="built_in">thread</span>(handle_client, client_socket).<span class="built_in">detach</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">close</span>(server_socket);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>客户端：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/socket.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;netinet/in.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;arpa/inet.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> IP_PORT = <span class="number">8888</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> BUFFER_SIZE = <span class="number">1024</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建一个套接字</span></span><br><span class="line">    <span class="type">int</span> client_socket = <span class="built_in">socket</span>(AF_INET, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (client_socket &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;Failed to create socket&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 连接到服务器</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">sockaddr_in</span> server_address;</span><br><span class="line">    std::<span class="built_in">memset</span>(&amp;server_address, <span class="number">0</span>, <span class="built_in">sizeof</span>(server_address));</span><br><span class="line">    server_address.sin_family = AF_INET;</span><br><span class="line">    server_address.sin_addr.s_addr = <span class="built_in">inet_addr</span>(<span class="string">&quot;127.0.0.1&quot;</span>);</span><br><span class="line">    server_address.sin_port = <span class="built_in">htons</span>(IP_PORT);</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">connect</span>(client_socket, (<span class="keyword">struct</span> sockaddr *)&amp;server_address, <span class="built_in">sizeof</span>(server_address)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;Failed to connect to server&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        <span class="built_in">close</span>(client_socket);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Connected to server at &quot;</span> &lt;&lt; <span class="built_in">inet_ntoa</span>(server_address.sin_addr) &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; <span class="built_in">ntohs</span>(server_address.sin_port) &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>)&#123;</span><br><span class="line"></span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;------------------------------&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    	std::string request_message; <span class="comment">// 注意读入数据需要小于1024 Bytes</span></span><br><span class="line">    	std::cout &lt;&lt; <span class="string">&quot;Input the message you want to send to server&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    	std::<span class="built_in">getline</span>(std::cin, request_message);</span><br><span class="line">    	<span class="keyword">if</span> (request_message == <span class="string">&quot;exit&quot;</span>)&#123;</span><br><span class="line">    		std::cout &lt;&lt; <span class="string">&quot;Bye&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    		<span class="keyword">break</span>;</span><br><span class="line">    	&#125;</span><br><span class="line"></span><br><span class="line">    	<span class="comment">// 发送数据</span></span><br><span class="line">	    <span class="type">int</span> num_bytes_sent = <span class="built_in">send</span>(client_socket, request_message.<span class="built_in">c_str</span>(), request_message.<span class="built_in">length</span>() , <span class="number">0</span>);</span><br><span class="line">	    <span class="keyword">if</span> (num_bytes_sent &lt; <span class="number">0</span>) &#123;</span><br><span class="line">	        std::cerr &lt;&lt; <span class="string">&quot;Failed to send data to server&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">	        <span class="built_in">close</span>(client_socket);</span><br><span class="line">	        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	    &#125;</span><br><span class="line">	    std::cout &lt;&lt; <span class="string">&quot;Sent &quot;</span> &lt;&lt; num_bytes_sent &lt;&lt; <span class="string">&quot; bytes: &quot;</span> &lt;&lt; request_message &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">	    <span class="comment">// 接收数据</span></span><br><span class="line">	    <span class="type">char</span> buffer[BUFFER_SIZE];</span><br><span class="line">	    <span class="type">int</span> num_bytes_received = <span class="built_in">recv</span>(client_socket, buffer, <span class="built_in">sizeof</span>(buffer), <span class="number">0</span>);</span><br><span class="line">	    <span class="keyword">if</span> (num_bytes_received &lt; <span class="number">0</span>) &#123;</span><br><span class="line">	        std::cerr &lt;&lt; <span class="string">&quot;Failed to receive data from server&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">	        <span class="built_in">close</span>(client_socket);</span><br><span class="line">	        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	    &#125;</span><br><span class="line">	    buffer[num_bytes_received] = <span class="string">&#x27;\0&#x27;</span>;</span><br><span class="line">	    std::cout &lt;&lt; <span class="string">&quot;Received &quot;</span> &lt;&lt; num_bytes_received &lt;&lt; <span class="string">&quot; bytes: &quot;</span> &lt;&lt; buffer &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 关闭套接字</span></span><br><span class="line">    <span class="built_in">close</span>(client_socket);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ Primer读书笔记</title>
    <url>/2023/07/21/C-Primer%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>文中标明【11】的为C++11新增标准。</p>
<h2 id="第零部分">第零部分</h2>
<h3 id="第一章-开始">第一章 开始</h3>
<ul>
<li>C++是静态（编译时检查变量类型）、弱类型（会自动做隐式类型转换）；</li>
<li><code>cin &gt;&gt;</code>和<code>cout &lt;&lt;</code>
运算顺序均为从左至右，运算结果为一个istream/ostream对象；</li>
<li><code>while (cin &gt;&gt; a)</code> 在读到<code>EOF</code>
时跳出循环；</li>
<li>由于<code>/* */</code> 注释的判定为遇到第一个<code>*/</code>
结束，因此该注释不能嵌套。一般只用它来写注释，需要注释掉代码时使用多行<code>//</code>；</li>
<li><code>cerr</code>不可重定向，不通过缓冲区；<code>endl</code>会刷新缓冲区；</li>
<li>Windows下文件结束符为<code>Ctrl+Z</code>后<code>Enter</code>，Linux下为<code>Ctrl+D</code>；</li>
<li>用户自定义的标识符不能连续出现两个下划线，也不能以下划线紧连大写字母开头，定义在函数体外的标识符不能以下划线开头；</li>
</ul>
<span id="more"></span>
<h2 id="第一部分-c基础">第一部分 C++基础</h2>
<h3 id="第二章-变量和基本类型">第二章 变量和基本类型</h3>
<ul>
<li>不同编译器字长和实现方式均不同，不要混用有符号和无符号变量；</li>
<li>赋给带符号类型一个超出其表示范围的值是ub（未定义行为）；</li>
<li>字面值常量：编译期可以直接得到结果的常量，如整数<code>1</code>、字符<code>’a’</code>、字符串<code>”a”</code>、布尔<code>true</code>、指针<code>nullptr</code>等；</li>
<li>【11】初始化和赋值不一样；C++11支持列表初始化，可以初始化类或数组等，在可能造成数据丢失时会警告；</li>
<li>全局变量会被默认初始化，而函数体内置类型变量不会；</li>
<li>作为静态类型语言，且为了支持分离式编译，C++区分了声明和定义；允许多次声明（当然声明必须一样），但定义只能有一次；</li>
<li>复合类型（引用、指针）由基本数据类型（如int）和声明符（*和&amp;）列表组成；</li>
<li><code>int *a，b</code>此时b为整型，因此声明时建议将声明符列表紧挨变量名；</li>
<li>【11】C++11用<code>nullptr</code>（字面值）带出原先的预处理变量<code>NULL</code>，以防止函数重载后无法分清参数是0还是NULL；</li>
<li><code>void *</code>指针没有对象类型信息，不能解引用；</li>
<li>常量引用<code>const &amp;</code>必须在声明时初始化；</li>
<li>顶层const表示指针本身是常量（const
pointer）：<code>int * const</code>；底层const表示指针所指对象为常量（pointer
to
const）：<code>const int *</code>；此处国内叫法（常量指针）似乎不一致，建议直接使用英文；</li>
<li>读声明时可以从右向左读，左边是右边的定语；</li>
<li>【11】<code>constexpr</code>表示编译时常量，即可以直接由字面值简单运算得到；相应地有运行时常量，如用一个变量初始化常量；</li>
<li>【11】C++11规定了新方法：别名声明<code>using new_type_name = old_type_name;</code></li>
<li>不应将<code>typedef</code>后的类型简单带入到新声明中，如<code>typedef char * pstring; const pstring cstr;</code>中<code>cstr</code>的基本数据类型为指针，此为const
pointer，而简单带入成<code>const char * cstr</code>后基本数据类型变为<code>const char</code>，<code>*</code>成为声明符的一部分，变为pointer
to const；</li>
<li>【11】定义<code>auto</code>类型时必须初始化，否则编译期无法推导类型；<code>auto</code>一般会忽略顶层const，若需要应写明<code>const auto</code>；</li>
<li>【11】<code>decltype(f()) sum = x;</code>
用<code>f()</code>的返回值类型作为<code>sum</code>的推导类型，但不实际计算<code>f()</code>，<code>sum</code>由<code>x</code>初始化；</li>
<li>设<code>int i = 42, *p = &amp;i, &amp;r = i;</code>则<code>decltype(*p)</code>的结果是<code>int&amp;</code>而非<code>int</code>，<code>decltype(r)</code>结果为<code>int&amp;</code>，<code>decltype(r + 0)</code>的结果为<code>int</code>；<code>decltype</code>的表达式若是加上括号的变量，结果将是引用，如<code>decltype((i))</code>会得到引用；其余情况均会将引用理解为变量别名，除了<code>decltype</code>的时候；</li>
<li>头文件保护符：在代码首尾分别加上<code>#ifndef A_H    #define A_H</code>和<code>#endif</code>；</li>
<li><code>typedef int i1, *i2;</code>定义了一个<code>int</code>类型和一个<code>int*</code>类型；</li>
</ul>
<h3 id="第三章-字符串向量和数组">第三章 字符串、向量和数组</h3>
<ul>
<li>头文件不应包含using声明；</li>
<li>若用=号初始化则为拷贝初始化，否则为直接初始化；</li>
<li><code>getline(cin, s)</code>会读到一个<code>'\n'</code>为止（包括此<code>'\n'</code>但<code>s</code>中不存）；</li>
<li>【11】范围（range）for语句：<code>for (declaration: expression)</code>
如<code>for (auto &amp;c: str)</code>；</li>
<li>有些老式编译器要求<code>vector&lt;vector&lt;int&gt; &gt;</code>此处必须有空格；</li>
<li><code>const_iterator</code> 是pointer to
const；<code>auto it = v.cbegin();</code>
会得到一个<code>const_iterator</code>；</li>
<li>但凡使用了迭代器的循环体都不要向所属容器添加元素；</li>
<li>迭代器可以和整数相加减；两个同容器的迭代器也可以相减，得到二者的距离，结果为有符号整型<code>difference_type</code>；两个指向同一数组中元素的指针相减的结果为有符号整型<code>ptrdiff_t</code>；</li>
<li>引用不是对象，故不存在引用的数组；</li>
<li>读数组的声明：由内而外，优先右结合，其次左结合；</li>
<li>数组下标为无符号整型<code>size_t</code>；数组定义的维度必须是编译期常量；</li>
<li>当使用数组名时往往会被编译器转换为数组首地址（<code>decltype</code>时不会），如<code>string *p = arr;</code>等价于<code>string *p = &amp;arr[0];</code></li>
<li>多维数组使用范围for语句时需要所有外层都使用引用<code>for (auto &amp;i: arr)</code>，否则会被编译器理解为数组首地址；</li>
<li>指针也是迭代器；尾后迭代器<code>end()</code>
没有实际含义，不能被递增或解引用；</li>
<li>【11】C++11支持数组的<code>begin(arr)</code>和<code>end(arr)</code>函数；</li>
<li>指向数组元素的指针也可以当数组用：<code>int *p = &amp;arr[2]; p[-1];</code></li>
<li><code>strlen(str)</code>会一直找到空字符为止，所以可能产生缓冲区错误；</li>
<li><code>string::c_str()</code>返回一个<code>const char *</code>，不保证一直有效；</li>
<li>用数组初始化vector：<code>vector&lt;int&gt; ivec(begin(arr), end(arr));</code></li>
<li>优先使用string和vector而减少使用C风格的字符串和数组；</li>
</ul>
<h3 id="第四章-表达式">第四章 表达式</h3>
<ul>
<li>【11】C++11允许直接使用初始化列表赋值、传参、作函数返回值；</li>
<li>新版C++正负均向零舍入；</li>
<li>赋值运算符具有右结合律；非必要不使用后置递增递减算符，因为会对迭代器产生较大不必要运算；</li>
<li><code>,</code> 运算符从左至右运算，并只返回最后一项；</li>
<li>无符号类型与带符号类型的运算会进行依赖于编译器的算数转换，故不要使用；</li>
<li><code>static_cast</code>为不报警告的强制类型转换，如<code>void* p = &amp;d; double *dp = static_cast&lt;double*&gt;(p);</code></li>
<li><code>const_cast</code>改变运算对象的底层const，转换本身是常量的对象是ub；示例用法：<code>const char *pc; char *p = const_cast&lt;char*&gt;(pc);</code></li>
<li><code>reinterpret_cast</code>重新解释位模式，示例：<code>int *ip; char *pc = reinterpret_cast&lt;char*&gt;(ip);</code>
尽量不要使用此强制转换；</li>
<li>尽量使用C++风格的类型转换而非C风格的(type)var；</li>
<li>提倡使用<code>*p++</code>，递增运算符优先级高于解引用；</li>
</ul>
<h3 id="第五章-语句">第五章 语句</h3>
<ul>
<li><code>else</code>默认匹配最近的没有<code>else</code>的<code>if</code>；</li>
<li><code>case</code>的值必须是整型常量表达式（字符算整型）；<code>case</code>语句会一直执行直至遇到<code>break</code>；</li>
<li>异常类只有一个成员函数<code>what()</code>，返回<code>const char *</code>，提供异常文本信息；</li>
</ul>
<h3 id="第六章-函数">第六章 函数</h3>
<ul>
<li>函数调用的这对括号叫调用运算符；局部变量、形参等离开作用域自动销毁的变量称为自动对象；</li>
<li>函数最外层作用域中的局部变量不能与形参重名；</li>
<li>最佳实践：定义函数的源文件应包含声明函数的头文件；尽量使用常量引用作为形参；</li>
<li>C++允许用字面值初始化常量引用；</li>
<li>【11】实参数量未知但类型都相同，C++11支持<code>initializer_list</code>类型，内存常量值，用法类似<code>vector</code>：<code>initializer_list&lt;T&gt; lst&#123;a, b, c&#125;;</code>
如：<code>void msg(initializer_list&lt;string&gt; il)&#123; … &#125;</code>，调用：<code>msg(&#123;"a", "b"&#125;</code>；</li>
<li>省略符形参<code>...</code>只能用于形参列表的最后一个，且仅用于C和C++通用的类型；</li>
<li>不使用<code>typedef</code>让函数返回数组指针：<code>Type (*function(parameter_list))[dimension]</code>
，或使用<code>decltype(arr) *arrPtr(int i)</code>，<code>*</code>表示返回数组指针（这点函数指针同理）。</li>
<li>【11】尾置返回类型： <code>auto func(int i) -&gt; int(*)[10];</code></li>
<li>默认实参必须是全局定义，其值取决于调用时对应实参的值；</li>
<li><code>constexpr</code>函数不一定返回常量表达式，只要编译期能得到值即可；</li>
<li><code>assert</code>预处理宏依赖于<code>NDEBUG</code>预处理变量，编译参数加入NDEBUG等价于<code>#define NDEBUG</code></li>
<li>预处理器定义的5个程序调试用的名字：<code>__func__</code>、<code>__FILE__</code>、<code>__LINE__</code>、<code>__TIME__</code>、<code>__DATE__</code></li>
<li>函数指针：用指针替换函数名即可，如<code>bool (*pf)(const int &amp;);</code>，函数指针可以作为形参；</li>
<li>当把函数名作为值使用时，自动转换成函数指针（即<code>pf = func</code>等价于<code>pf = &amp;func</code>），调用时也会自动解引用（即<code>bool b = pf(1);</code>等价于<code>bool b = (*pf)(1);</code>）</li>
<li>函数类型的形参会被自动转换为指针：<code>void func(bool pf());</code>等价于<code>void func(bool (*pf)());</code>
；使用<code>decltype(func) *</code>定义函数指针；</li>
<li>相反，函数返回值不会做自动转换，必须指明返回一个函数指针；</li>
<li>局部静态变量一般拥有和全局变量同等地位和处理方式；</li>
<li>内联函数、函数重载部分略；</li>
</ul>
<h3 id="第七章-类">第七章 类</h3>
<ul>
<li><code>constexpr</code>函数和定义在类内的函数都是隐式<code>inline</code>函数；</li>
<li><code>this</code>指针是一个<code>Type * const</code>，若需要对常量对象执行成员函数，可以在函数参数列表的最后加上<code>const Type * const this</code>；仅在使用整体而非访问部分成员的时候使用<code>this</code>；</li>
<li>类内函数定义顺序不影响，编译期先处理成员声明，再处理函数体（类外有影响）；但是类内声明之间有顺序，如当一个函数使用类型<code>Type</code>时，必须之前已经定义此<code>Type</code>类型。</li>
<li>只有当类没有声明任何构造函数时才会自动生成默认构造函数（且若有其它成员类且该类没有默认构造函数或其它特殊情况，则无法自动生成）；</li>
<li>【11】可以<code>= default</code>使用默认构造函数，若此定义在内部则为内联，否则不是；</li>
<li><code>struct</code>和<code>class</code>的唯一区别是默认访问控制，前者是<code>private</code>后者是<code>public</code>；</li>
<li>一个可变数据成员<code>mutable</code>即使是<code>const</code>对象成员也不是<code>const</code>；</li>
<li>友元声明：<code>friend</code>后接声明即可（并非真正的声明）；外类的友元函数要写对应类<code>classtype::</code>；若有函数重载则每种均应分别声明；</li>
<li>若类中已使用外层作用域定义的类型，则类内不可再定义此类型覆盖外层定义；</li>
<li>构造函数初始化列表为初始化，但函数体内为赋值；若一个成员变量同时在定义时被初始化和在初始化列表中，则以初始化列表为准（不推荐）；<code>const</code>或引用类型必须初始化；</li>
<li>委托构造函数，即直接在初始化列表调用其它构造函数：<code>Type():Type(...)&#123;...&#125;</code>，此处<code>Type()</code>委托了<code>Type(...)</code>；</li>
<li>函数传参遵循最佳匹配原则，不匹配时会做一次（且仅一次）类类型转换；</li>
<li>用初始化列表初始化类时需要所有成员均为<code>public</code>；</li>
<li>字面值常量类必须定义至少一个<code>constexpr</code>的构造函数，而普通类不能定义<code>const</code>的构造函数；</li>
<li>应该在类外部定义静态成员，但需要在类内声明<code>static</code>；类外定义可以访问类的私有成员；</li>
<li><code>static constexpr int period = 30;</code>
进行了声明和初始化，但没有进行定义，最好在类外再定义一下；</li>
<li>前向声明暂时不进行定义，可以用来定义指针或引用，或声明以它为参数或返回类型的函数；声明之后定义之前的类型叫作不完全类型；</li>
<li>静态成员类型可以是不完全类型，也可以就是它所属的类类型，而非静态成员只能声明成它所属类的指针或引用；</li>
</ul>
<h2 id="第二部分-c标准库">第二部分 C++标准库</h2>
<h3 id="第八章-io库">第八章 IO库</h3>
<ul>
<li><code>ifstream</code>（头文件<code>fstream</code>）和<code>istringstream</code>（头文件<code>sstream</code>）继承自<code>istream</code>（头文件<code>iostream</code>），输出同理；故使用<code>cin</code>的地方均可以使用自定义的<code>ifstream</code>和<code>istringstream</code>对象代替；</li>
<li>IO对象无拷贝和赋值；使用<code>&lt;&lt; flush</code>可以刷新缓冲区；当<code>fstream</code>对象被销毁时会自动调用<code>close</code>；</li>
<li>高级IO操作略；</li>
</ul>
<h3 id="第九章-顺序容器">第九章 顺序容器</h3>
<ul>
<li>【11】<code>array&lt;type, size&gt;</code>可以灵活指定大小，支持赋值和复制（因此可以直接作为函数参数或返回值），也支持迭代器、内置方法，提供更好的类型安全检查（<code>std::out_of_range</code>异常）；</li>
<li>顺序容器提供<code>arr.assign(begin, end)</code>
进行赋值，但传入的迭代器不能指向调用者本身；</li>
<li>除<code>array</code>外的<code>swap()</code>函数都是只交换指针；<code>array</code>交换整体，但可以用<code>std::swap()</code>实现交换指针；建议统一使用非成员版本的<code>std::swap()</code>；</li>
<li>【11】C++11中接受元素个数或范围的<code>insert</code>返回指向第一个新加入元素的迭代器（旧版本返回<code>void</code>），<code>erase()</code>返回被删元素之后元素的迭代器；同样<code>insert</code>的参数不能指向调用者容器；<code>insert()</code>不能使用初始化列表；</li>
<li><code>emplace_front()</code>、<code>emplace()</code>和<code>emplace_back()</code>分别是<code>push_front()</code>、<code>insert()</code>和<code>push_back()</code>的构造函数而非拷贝构造函数版本；</li>
<li>访问成员函数<code>front()</code>、<code>back()</code>、下标<code>[]</code>和<code>at()</code>返回的都是引用；下标不做安全检查，超出范围为ub，<code>at(n)</code>越界返回<code>std::out_of_range()</code>；</li>
<li>【11】C++11实现了高效简单的<code>forward_list</code>单向链表，仅支持<code>before_begin()</code>、<code>insert_after()</code>、<code>emplace_after()</code>和<code>erase_after()</code>；</li>
<li>不要保存<code>end()</code>，因为在添加删除元素时原先<code>end()</code>会失效，<code>end()</code>操作很快；</li>
<li><code>resize()</code>和<code>reserve()</code>不会减少容器占用的内存空间，而C++11的<code>shrink_to_fit()</code>可以（但不保证退回内存）；</li>
<li>容器适配器<code>stack</code>和<code>queue</code>默认基于<code>deque</code>实现，可以指明使用除<code>array</code>外任何容器构造<code>stack</code>，以及用<code>list</code>或<code>deque</code>（不能用<code>vector</code>）构造<code>queue</code>
，如<code>stack&lt;string, vector&lt;string&gt;&gt;</code>；</li>
</ul>
<h3 id="第十章-泛型算法">第十章 泛型算法</h3>
<ul>
<li>迭代器令算法不依赖于容器而是依赖于元素类型的操作，泛型算法永远不会执行容器的操作，只会运行与迭代器之上；</li>
<li>【11】lambda表达式：<code>[capture list](parameter list) -&gt; return type &#123;...&#125;</code>
参数列表和返回类型可省略（代表指定空参数列表和自动推断返回类型）；捕获值在lambda创建时而非调用时拷贝，引用捕获需要保证对应变量存在；</li>
<li><code>[]</code>不捕获变量；<code>[names]</code>规定捕获列表，默认为值拷贝，加<code>&amp;</code>表示引用捕获；<code>[&amp;]</code>和<code>[=]</code>表示自动隐式捕获；<code>[&amp;, identifier_list]</code>和<code>[=, identifier_list]</code>，后者变量前必须加&amp;；</li>
<li>若函数体包含<code>return</code>外任何语句，编译器假定此<code>lambda</code>返回<code>void</code>，可使用尾置<code>-&gt;</code>指定返回类型；</li>
<li>【11】参数绑定：<code>auto newCallable = bind(callable, arg_list);</code>
其中使用_n表示<code>newCallable</code>的第n个参数（需要<code>using namespace std::placeholders</code>）；使用<code>ref</code>函数和<code>cref</code>函数（<code>#include &lt;functional&gt;</code>）返回的对象实现引用参数绑定，如：<code>auto g = bind(f, a, ref(b), _2, c, _1);</code>（注：此特性新版本已被弃用，建议直接使用lambda）；</li>
<li>插入迭代器<code>back_inserter it = vec</code>在<code>it = t</code>时会<code>push_back(t)</code>，<code>front_inserter</code>会<code>push_front(t)</code>（插入多个时会倒序插入），<code>inserter</code>在<code>*it = val</code>时等价于<code>it = c.insert(it, val); ++ it;</code></li>
<li>流迭代器：注意<code>istream_iterator</code>允许懒惰求值，知道使用迭代器时才真正读取；</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">istream_iterator&lt;<span class="type">int</span>&gt; <span class="title">in_iter</span><span class="params">(cin)</span>, eof</span>; <span class="comment">// 默认被定义为空对象，故可以用做尾后迭代器</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">vec</span><span class="params">(in_iter, eof)</span></span>;</span><br><span class="line"><span class="comment">// 或者：</span></span><br><span class="line"><span class="keyword">while</span> (in_iter != eof)</span><br><span class="line">	vec.<span class="built_in">push_back</span>(*in_iter++);</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">ostream_iterator&lt;<span class="type">int</span>&gt; <span class="title">out_iter</span><span class="params">(cout, <span class="string">&quot; &quot;</span>)</span></span>; <span class="comment">// 每输出一次后跟一个空格</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> e: vec)</span><br><span class="line">	*out_iter++ = e; <span class="comment">// 事实上*和++不对out_iter做任何事，可以省略</span></span><br></pre></td></tr></table></figure>
<ul>
<li>反向迭代器<code>rptr.base()</code>实际为<code>rptr</code>的后一个，以统一左闭右开区间；</li>
<li>泛型算法可能要求的五类迭代器：输入、输出、前向、双向、随机访问；能力更强的迭代器可以传给能力更弱的形参，反之报错；标准库提供的泛型算法见附录A；</li>
<li>对于<code>list</code>和<code>forward_list</code>，应优先使用成员函数版本算法而非通用泛型算法；一般成员函数版本会改变容器及其迭代器，而通用函数不会；</li>
</ul>
<h3 id="第十一章-关联容器">第十一章 关联容器</h3>
<ul>
<li>【11】可以使用比较函数定义关联容器：<code>multiset&lt;T, decltype(compareT)*&gt;</code>，第二个为函数指针；</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">set&lt;string&gt;::value_type;</span><br><span class="line">set&lt;string&gt; key_type; <span class="comment">// 与value_type相同</span></span><br><span class="line">map&lt;string, <span class="type">int</span>&gt;::key_type;</span><br><span class="line">map&lt;string, <span class="type">int</span>&gt;::mapped_type;</span><br><span class="line">map&lt;string, <span class="type">int</span>&gt;::value_type; <span class="comment">// 即pair&lt;const key_type, mapped_type&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>一般不对关联容器使用泛型算法（键值是const也意味着不能修改）；</li>
<li>面向迭代器的查找遍历：<code>lower_bound(</code>)、<code>upper_bound()</code>和<code>equal_range()</code>；</li>
<li>【11】无序关联容器：<code>unordered_map</code>、<code>unordered_set</code>、<code>unordered_multimap</code>、<code>unordered_multiset</code>；支持一系列桶接口、桶迭代和哈希策略函数；</li>
</ul>
<h3 id="第十二章-动态内存">第十二章 动态内存</h3>
<ul>
<li>【11】C++11新特性支持智能指针<code>shared_ptr</code>、<code>unique_ptr</code>和前者的伴随类<code>weak_ptr</code>；</li>
<li><code>make_shared&lt;T&gt;(args)</code>和<code>shared_ptr&lt;T&gt;p(q)</code>
定义，编译期使用引用计数智能判定是否销毁指针指向的值并返还内存；当前指针设为<code>nullptr</code>将递减原对象引用计数，可以使用<code>reset()</code>销毁对象（注意别的指向此对象的指针）；</li>
<li>空悬指针是<code>delete</code>之后仍然指向原对象地址的指针，相当于野指针；不要混用智能指针和普通指针；</li>
<li>用<code>make_unique&lt;T&gt;(args)</code>
（11不支持）或<code>unique_ptr&lt;T&gt; p(new int(42));</code>
定义<code>unique_ptr</code>，不能拷贝和赋值（但可以作为函数参数和返回值）；用<code>unique_ptr&lt;int&gt; p2(p1.release())</code>或<code>p2 = move(p1)</code>或<code>p2.reset(p1.release())</code>转移对象所有权（p1、p2均交出当前所有权，并将p1所有权交给p2）；</li>
<li><code>weak_ptr&lt;T&gt; p(sp)</code>定义<code>weak_ptr</code>，不增加对象的引用计数，不阻止管理对象的销毁，用<code>p.use_count()</code>返回共享对象数量，<code>p.expired()</code>返回<code>use_count()</code>是否为0，用<code>lock()</code>在<code>expired</code>时返回空<code>shared_ptr</code>，否则返回指向p的对象的<code>shared_ptr</code>；</li>
<li>不应使用旧规范的动态数组，而应使用<code>vector</code>；使用<code>vector&lt;int&gt;().swap(vec);</code>释放<code>vec</code>空间；</li>
<li><code>allocator</code>类分离了内存分配和对象构造：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">allocator&lt;T&gt; a;</span><br><span class="line">p = a.<span class="built_in">allocate</span>(n);</span><br><span class="line">a.<span class="built_in">deallocate</span>(p, n) <span class="comment">// 要求p和n必须都是allocate时的</span></span><br><span class="line">a.<span class="built_in">construct</span>(p, args);</span><br><span class="line">a.<span class="built_in">destroy</span>(p)；</span><br></pre></td></tr></table></figure>
<ul>
<li>【11】<code>construct</code>在旧标准中<code>args</code>必须传入一个元素类型值，C++11中可以使用多个构造函数参数初始化，如<code>a.construct(q++, 3, 'c')</code>令<code>*q</code>为<code>"ccc"</code>；</li>
<li>对为构造部分进行初始化，copy函数返回初始化范围的后一个尾置指针；</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">uninitialized_copy</span>(b, e, b2)</span><br><span class="line"><span class="built_in">uninitialized_copy_n</span>(b, n, b2)</span><br><span class="line"><span class="built_in">uninitialized_fill</span>(b, e, t)</span><br><span class="line"><span class="built_in">uninitialized_fill_n</span>(b, n, t)</span><br></pre></td></tr></table></figure>
<h2 id="第三部分-类设计者的工具">第三部分 类设计者的工具</h2>
<h3 id="第十三章-拷贝控制">第十三章 拷贝控制</h3>
<ul>
<li>三/五法则：五种拷贝控制操作特殊成员函数：拷贝构造、拷贝赋值、析构、移动构造、移动赋值，前三个可以控制类的拷贝操作；常常是否需要自定义拷贝构造和拷贝赋值就看是否需要析构函数；</li>
<li>拷贝构造函数<code>T(const T&amp;)</code>；默认合成拷贝构造函数将参数成员逐个拷贝到当前对象中；</li>
<li>直接初始化选取最符合的构造函数，可能调用拷贝构造函数；拷贝初始化可能进行类型转换；拷贝构造函数可以布置一个参数，但必须带默认参数；</li>
<li>拷贝初始化发生：使用<code>=</code>定义变量时；函数传递值参、返回
值类型时；使用C++11的花括号列表时的部分类类型；<code>emplace</code>都进行直接初始化；</li>
<li>重载拷贝赋值运算符：<code>T&amp; operator =(const T &amp;)</code>；合成析构函数不会<code>delete</code>它的指针成员，重载析构函数：<code>T::~T()</code>；</li>
<li>给函数传递类类型对象时，除了常规作用域查找外还会查找实参类所属的命名空间；当自定义和<code>std::</code>有命名冲突时，默认使用自定义函数；不提倡使用<code>using</code>而应该在每个使用标准库函数时均添加<code>std::</code>；</li>
<li>标准库容器、string和shared_ptr既支持移动又支持拷贝，IO类和unique_ptr类可以移动但不能拷贝；</li>
<li>【11】右值引用可以被绑定到要求转换的表达式、字面常量或返回右值的表达式；头文件<code>utility</code>中<code>move()</code>返回给定对象的右值引用，即承诺除了赋值和销毁外不会再使用原左值，定义移动构造函数：<code>T (T&amp;&amp; other)</code>；定义移动赋值函数：<code>T&amp; operator=(T&amp;&amp; other)</code></li>
<li><code>forward</code>和<code>move</code>不可以<code>using</code>，必须带<code>std::</code>
；</li>
</ul>
<h3 id="第十四章-重载运算与类型转换">第十四章 重载运算与类型转换</h3>
<ul>
<li>使用含有状态的函数对象类：可以被作为参数传入泛型算法，如<code>for_each(vs.begin(), vs.end(), PrintString(cerr,'\n'))</code>
；lambda是函数对象；</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrintString</span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span></span></span><br><span class="line"><span class="function">	<span class="title">PrintString</span><span class="params">(ostream &amp;o = cout, <span class="type">char</span> c = <span class="string">&#x27; &#x27;</span>)</span>:os(o), sep(c)&#123;</span>&#125; <span class="comment">// 定义了构造函数</span></span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> string &amp;s)</span><span class="type">const</span></span>&#123; os &lt;&lt; s &lt;&lt; sep; &#125; <span class="comment">// 定义了函数调用运算符</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	ostream &amp;os;</span><br><span class="line">	<span class="type">char</span> sep;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<ul>
<li>【11】C++11支持标准库<code>function</code>类型；</li>
<li>类型转换运算符：<code>[explicit] operator int() const;</code></li>
<li>表示运算符的模板对象类：<code>greater&lt;int&gt;()</code>等；</li>
</ul>
<h3 id="第十五章-面向对象程序设计">第十五章 面向对象程序设计</h3>
<ul>
<li>【11】C++11允许在参数列表后使用<code>override</code>关键字显式注明覆盖了继承的虚函数；</li>
<li>静态成员即使被继承也只存在唯一实例；</li>
<li>【11】在类名后使用<code>final</code>关键字防止继承；</li>
<li>不存在从基类向派生类的隐式类型转换；派生类向基类的转换只对指针和引用有效；</li>
<li>可以使用作用域运算符指定使用的虚函数；</li>
<li>名字查找先于类型检查；在构造函数和析构函数中使用的虚函数就是此函数所在的类的虚函数，而非动态类型的虚函数；</li>
<li>如果一个类会被派生，应该将其析构函数定义为虚函数；</li>
</ul>
<h3 id="第十六章-模板与泛型编程">第十六章 模板与泛型编程</h3>
<ul>
<li>有关模板、实例化、包扩展、转发、特例化、<code>std::move</code>
等内容；</li>
<li>推荐阅读 <strong><em>Effective Modern C++</em></strong>，<a
href="https://zhuanlan.zhihu.com/p/649667647">缩略版</a>；</li>
<li><a
href="https://zhuanlan.zhihu.com/p/455848360">关于移动语义</a>；</li>
</ul>
<h2 id="第四部分-高级主题">第四部分 高级主题</h2>
<h3 id="第十七章-标准库特殊设施">第十七章 标准库特殊设施</h3>
<ul>
<li>【11】<code>tuple</code>类似<code>pair</code>但成员数量任意（固定），定义为<code>tuple&lt;T1, T2, ..., Tn&gt; t(v1, v2, ..., vn)</code>或<code>make_tuple(v1, v2, ..., vn)</code>
；<code>get&lt;i&gt;(t)</code>返回<code>t</code>的第i个成员的引用（<code>t</code>为左值则返回左值引用，右值则右值引用）；拆包：<code>std::tie(gpa, grade, name) = make_tuple(3.8, 'A', "张三");</code></li>
<li>两个辅助类模板：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">decltype</span><span class="params">(item)</span> T</span>;</span><br><span class="line"><span class="type">size_t</span> sz = tuple_size&lt;T&gt;::value;</span><br><span class="line">tuple_element&lt;<span class="number">1</span>, T&gt;::type cnt = <span class="built_in">get</span>&lt;<span class="number">1</span>&gt;(item);</span><br></pre></td></tr></table></figure>
<ul>
<li><code>bitset&lt;n&gt; b(u)</code> 定义<code>bitset</code>；</li>
<li>【11】<code>regex</code>类定义在<code>regex</code>头文件中，表示一个正则表达式；使用的是ECMAScript正则表达式语言，具体使用略；</li>
<li>【11】随机数引擎类和随机数分布类用法：<code>default_random_engine e; uniform_int_distribution&lt;unsigned&gt; u(0, 9);</code>
<code>e</code>是引擎类，<code>u</code>是分布类，用<code>u(e)</code>
返回一个随机数；具体使用略；</li>
<li>【11】C++风格IO格式控制略；C++11新增了十六进制浮点数等格式操作；</li>
</ul>
<h3 id="第十八章-用于大型程序的工具">第十八章 用于大型程序的工具</h3>
<ul>
<li>异常处理之栈展开：沿函数嵌套调用链查找对应<code>catch</code>子句，若为找到调用标准库函数<code>terminate</code>
，沿着调用链创建的对象将被销毁；</li>
<li>【11】紧跟函数参数列表之后的<code>noexcept</code>标识该函数不会抛出异常，与同样位置写<code>throw()</code>等价；<code>catch(...)</code>捕获所有异常，常常做部分处理后重新抛出throw空语句（会沿调用链向上传递）；</li>
<li>命名空间可以不连续；旧C++使用static表示文件级变量，文件外不可访问，新C++应使用未命名名字空间；</li>
<li>多重继承，使用虚继承解决菱形继承问题；</li>
</ul>
<h3 id="第十九章-特殊工具与技术">第十九章 特殊工具与技术</h3>
<ul>
<li>重载<code>new</code>和<code>delete</code>控制内存分配：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> *<span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="type">size_t</span>)</span></span>;</span><br><span class="line"><span class="type">void</span> *<span class="keyword">operator</span> <span class="keyword">new</span>[](<span class="type">size_t</span>)</span><br><span class="line"><span class="type">void</span> *<span class="keyword">operator</span> <span class="built_in">delete</span>(<span class="type">void</span>*) <span class="keyword">noexcept</span>;</span><br><span class="line"><span class="type">void</span> *<span class="keyword">operator</span> <span class="keyword">delete</span>[](<span class="type">void</span>*) <span class="keyword">noexcept</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>运行时类型识别（Run-Time Type
Identification，RTTI）：使用基类对象指针或引用执行派生类非虚函数时使用；<code>dynamic_cast&lt;type*/type&amp;/type&amp;&amp;&gt;(e)</code>
在转换失败时返回空指针或抛出<code>bad_cast</code>异常；<code>typeid(e)</code>返回运行时类型判断；</li>
<li>析构函数销毁对象但不释放内存；</li>
<li>枚举成员是<code>const</code>，可用<code>enum class</code>或<code>enum struct</code>限定作用域；限定作用域的枚举必须加上作用域限定符访问，且不会进行隐式转换；</li>
<li>【11】C++11中可以指定enum的大小：<code>enum big: unsigned long long</code>，且允许前置声明；</li>
<li>成员指针：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> pdata = &amp;Screen::contents;</span><br><span class="line">Screen myScreen, *pScreen = &amp;myScreen;</span><br><span class="line"><span class="keyword">auto</span> s = myScreen.*pdata;</span><br><span class="line">s = pScreen-&gt;*pdata;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>union</code>：节省空间的类，一次只有一个成员有效；匿名<code>union</code>的成员在<code>union</code>定义所在作用域可以被直接访问；</li>
</ul>
<h3 id="个人注记">个人注记</h3>
<p><a
href="https://changkun.de/modern-cpp/zh-cn/01-intro/">现代C++教程：快速上手C++
11/14/17/20</a></p>
<ul>
<li>现代C++不再允许将字符串字面值常量赋值给<code>char *</code>，应该使用<code>const char *</code>；</li>
<li><code>unexpected_handler</code>、<code>set_unexpected()</code>被弃用，应使用<code>noexcept</code>；</li>
<li><code>auto_ptr</code>被弃用，应使用<code>unique_ptr</code>；</li>
<li><code>register</code>
被弃用，若一个类有析构函数，不再自动生成拷贝构造函数和拷贝赋值运算符；</li>
<li>C++17弃用了<code>&lt;ccomplex&gt;</code>；</li>
<li>使用<code>extern "C"</code>
分离代码中的C代码和C++代码，再用clang++链接.o文件；（<a
href="https://changkun.de/modern-cpp/zh-cn/01-intro/#1-2-%E4%B8%8E-C-%E7%9A%84%E5%85%BC%E5%AE%B9%E6%80%A7">见此</a>）</li>
<li>C++14之后实现了泛型函数版本的<code>begin()</code>、<code>end()</code>等，建议使用；</li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera吴恩达机器学习笔记</title>
    <url>/2023/07/19/Cousera%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>https://www.bilibili.com/video/BV164411S78V</p>
<h2
id="线性回归linear-regression与梯度下降gradient-descent">线性回归(Linear
Regression)与梯度下降(Gradient Descent)</h2>
<p><strong>记号</strong>：</p>
<p><span class="math inline">\(m\)</span> = 训练样本数，<span
class="math inline">\(n\)</span> = 特征数，<span
class="math inline">\(x\)</span> = 输入变量/特征，<span
class="math inline">\(y\)</span> = 输出变量/目标变量</p>
<p><span class="math inline">\((x, y)\)</span> = 训练样本。第i个: <span
class="math inline">\((x^{(i)},y^{(i)})\)</span></p>
<p><span
class="math inline">\(h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+...+\theta_nx_n\)</span></p>
<p>令<span class="math inline">\(x_0\)</span>为<span
class="math inline">\(1\)</span>，则<span
class="math inline">\(h_\theta(x) = \sum_{i=0}^{n}\theta_ix_i=\theta^T
x\)</span></p>
<p><span class="math inline">\(Minimize_{\theta}\ \ J(\theta) =
\frac{1}{2m} \sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2\)</span></p>
<p>（最小二乘线性回归）</p>
<span id="more"></span>
<p>初始 <span class="math inline">\(\theta =
\boldsymbol{0}\)</span>，注意：<span
class="math inline">\(\theta,x,y\)</span> 均为向量</p>
<p><strong>批量梯度下降(Batch Gradient
Regression)</strong>（使用全部样本，循环直到收敛，复杂度<span
class="math inline">\(knm\)</span>）：</p>
<p><span class="math inline">\(\theta_i := \theta_i -
\alpha\frac{\partial}{\partial\theta_i}J(\theta) = \theta_i -
\frac{\alpha}{m}(h_\theta(x)-y)x_i = \theta_i - \frac{\alpha}{m} \sum_{j
= 1}^m (h_\theta(x^{(j)}) - y^{(j)})x_i^{(j)}\)</span></p>
<p><strong>随机梯度下降(Stochastic Gradient
Descent)</strong>（一步只使用一对<span
class="math inline">\((x,y)\)</span> ）：</p>
<p>For j:=1 to m <span class="math inline">\(\theta_i := \theta_i -
\frac{\alpha}{m}(h_\theta(x^{(j)})-y^{(j)})x_i^{(j)}\ (For\ all\
i)\)</span></p>
<p><strong>正则化方法</strong>（复杂度<span
class="math inline">\((nm)^3\)</span>）：<span
class="math inline">\(\theta = (X^TX)^{-1}X^Ty\)</span></p>
<p><strong>向量缩放</strong>：<span class="math inline">\(x_i =
\frac{x_i - \mu_i}{s_i}\)</span> （<span
class="math inline">\(\mu_i\)</span> 为<span
class="math inline">\(x_i\)</span>平均数，<span
class="math inline">\(s_i\)</span> 为极差或标准差）</p>
<h2 id="逻辑回归logistic-regression">逻辑回归(Logistic Regression)</h2>
<p><strong>二分类</strong>：</p>
<p><span class="math inline">\(h_\theta(x) = \frac{1}{1 +
e^{-\theta^TX}}\)</span>，但若仍使用原先代价函数会得到非凸图像，容易收敛至非最值点。</p>
<p>原先代价函数：<span class="math inline">\(Cost(h_\theta(x), y) =
\sum_{i = 1}^m \frac{1}{2} (h_\theta(x^{(i)})-y^{(i)})^2\)</span></p>
<p>重新定义代价函数：</p>
<p><span class="math inline">\(Cost(h_\theta(x), y) = \begin{cases}
-\log(h_\theta(x)) &amp; if\ y = 1 \\ -\log(1 - h_\theta(x)) &amp; if\ y
= 0 \end{cases}\)</span></p>
<p>代入得<span class="math inline">\(J(\theta) = \frac{1}{m} \sum_{i =
1}^m Cost(h_\theta(x),y) = -\frac{1}{m}\sum_{i = 1}^m [y^{(i)} \log
(h_\theta(x^{(i)})) + (1-y^{(i)}) \log (1 -
h_\theta(x^{(i)}))]\)</span></p>
<p><span class="math inline">\(\theta_i := \theta_i - \frac{\alpha}{m}
\sum_{j = 1}^m (h_\theta(x^{(j)}) - y^{(j)})x_i^{(j)}\)</span></p>
<p>（形式与线性回归完全相同）</p>
<p><strong>多拟合分类器</strong>：<span
class="math inline">\(h_\theta^{(i)}(x) = P(y = i|x; \theta)\ \ \ (i =
1, 2, \cdots)\)</span></p>
<p>对每个样本寻找：<span class="math inline">\(\max_i
h_\theta^{(i)}(x)\)</span></p>
<p><strong>正则化(Regularization)</strong>：为避免<strong>过拟合(Overfitting)</strong>，对于某些高次项系数<span
class="math inline">\(\theta_i\)</span>，将<span
class="math inline">\(1000\theta_i^2\)</span>加入<span
class="math inline">\(J(\theta)\)</span>，以使得此系数尽量小，从而消除此系数（显然<span
class="math inline">\(\theta_0\)</span>不需要）。</p>
<p><span class="math inline">\(J(\theta) = \frac{1}{m} [\sum_{i = 1}^m
(h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda \sum_{j = 1}^n
\theta_j^2]\)</span></p>
<p><span class="math inline">\(\theta_0 := \theta_0 - \frac{\alpha}{m}
\sum_{i = 1}^m (h_\theta(x^{(0)}) - y^{(0)})x_0^{(0)}\)</span></p>
<p><span class="math inline">\(\theta_j := \theta_j(1 -
\alpha\frac{\lambda}{m}) - \frac{\alpha}{m} \sum_{i = 1}^m
(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\)</span></p>
<p><span class="math inline">\(\theta = \Big{(}X^TX + \lambda
\begin{bmatrix} 0 &amp; &amp; &amp; &amp; \\ &amp; 1 &amp; &amp; &amp;
\\ &amp; &amp;  1 &amp; &amp; \\ &amp; &amp; &amp; \ddots &amp; \\ &amp;
&amp; &amp; &amp; 1 \end{bmatrix}\Big{)}^{-1}X^Ty\)</span> <span
class="math inline">\((n+1)\times(n+1)\)</span></p>
<p>若<span class="math inline">\(m \leqslant n\)</span>且<span
class="math inline">\(\lambda &gt; 0\)</span>，那么此矩阵可逆。</p>
<h2 id="神经网络neural-networks">神经网络(Neural Networks)</h2>
<p><span class="math inline">\(L\)</span>：网络层数，<span
class="math inline">\(s_l\)</span>：神经元数量（不包括偏差单元bias
unit）</p>
<p><strong>二分类(Binary Classification)</strong>：<span
class="math inline">\(y = 0\ \text{or}\ 1\)</span>，<span
class="math inline">\(s_L = K = 1\)</span></p>
<p><strong>多分类（Multi-class Classification）</strong>：<span
class="math inline">\(y \in \mathbb{R}^K\)</span>，<span
class="math inline">\(S_L = K\)</span></p>
<p><span class="math inline">\(J(\theta) = -\frac{1}{m}[\sum_{i = 1}^m
\sum_{k = 1}^K  y_k^{(i)} \log(h_\theta(x^{(i)}))_k + (1 - y_k^{(i)})
\log(1 - (h_\theta(x^{(i)}))_k)] \\ + \frac{\lambda}{2m}\sum_{l = 1}^{L
- 1}\sum_{i = 1}^{s_l}\sum_{j = 1}^{s_l +
1}(\theta_{ji}^{(l)})^2\)</span></p>
<p><span class="math inline">\(a_j^{(l)}\)</span>：第<span
class="math inline">\(l\)</span>层第<span
class="math inline">\(j\)</span>个节点的<strong>激活值(Activation)</strong>，<span
class="math inline">\(z^{(l+1)} = \theta^{(l)} \cdot
a^{(l)}\)</span>，<span class="math inline">\(a^{(l+1)} =
g(z^{(l+1)})\)</span>，此例中<span class="math inline">\(g(z) =
\frac{1}{1 - e^{-z}}\)</span></p>
<p><span class="math inline">\(cost(i) = y^{(i)}\log h_\theta(x^{(i)}) +
(1 - y^{(i)}) \log h_\theta(x^{(i)})\)</span></p>
<p><span class="math inline">\(\delta_j^{(l)}\)</span>是<span
class="math inline">\(a_j^{(l)}\)</span>的误差代价，<span
class="math inline">\(\delta_j^{(l)} = \frac{\partial}{\partial
z_j^{(l)}}cost(i)\ (j \geqslant 0)\)</span></p>
<p>复杂推导得：<span class="math inline">\(\delta^{(l)} =
(\theta^{(l)})^T \delta^{(l+1)} \cdot g&#39;(z^{(l)})\)</span>，<span
class="math inline">\(g&#39;(z^{(l)}) = a^{(l)} \cdot (1 -
a^{(l)})\)</span>，<span class="math inline">\(\Delta_{ij}^{(l)} :=
\Delta_{ij}^{(l)} + a_j^{(l)}\delta_i^{(l+1)}\)</span></p>
<p>对于每个样本<span class="math inline">\((x^{(i)},
y^{(i)})\)</span>，<strong>正向传播(Forward
Propagation)</strong>得到<span
class="math inline">\(a\)</span>，再计算输出层的<span
class="math inline">\(\delta^{(L)}\)</span>，再<strong>反向传播(Back
Propagation)</strong>得到<span class="math inline">\(\delta^{(2 \sim
L-1)}\)</span>和<span class="math inline">\(\Delta^{(2 \sim
L-1)}\)</span>，最后得到代价函数的偏导数：</p>
<p><span class="math inline">\(D_{ij}^{(l)} :=
\frac{1}{m}\Delta_{ij}^{(l)} + \lambda \theta_{ij}^{(l)}\ \ \ if\ j \neq
0\)</span></p>
<p><span class="math inline">\(D_{ij}^{(l)} := \frac{1}{m}
\Delta_{ij}^{(l)}\ \ \ if\ j = 0\)</span></p>
<p><strong>梯度检测(Gradient Check)</strong>：<span
class="math inline">\(\frac{\partial}{\partial \theta_i} \approx
\frac{J(\theta_1, \cdots, \theta_i+\epsilon, \cdots, \theta_n) -
J(\theta_1, \cdots, \theta_i - \epsilon, \cdots
\theta_n)}{2\epsilon}\)</span></p>
<p>随机初始化：每个<span
class="math inline">\(\theta_{ij}^{(l)}\)</span>都在<span
class="math inline">\([-\epsilon, \epsilon]\)</span>范围内随机。</p>
<h2 id="机器学习诊断法diagnostics">机器学习诊断法(Diagnostics)：</h2>
<p><strong>0/1分类错误(0/1 Misclassfication error)</strong></p>
<p><span class="math inline">\(err(h_\theta(x), y) = \begin{cases} 1
&amp; \text{if } h_\theta(x) \geqslant 0.5 &amp; , y = 0 \\ &amp;
\text{or if } h_\theta(x)&lt;0.5 &amp;, y = 1 \\ 0 &amp;
\text{otherwise} \end{cases}\)</span></p>
<p><span class="math inline">\(Test\ error = \frac{1}{m_{test}} \sum_{i
= 1}^{m_{test}} err(h_\theta(x_{test}^{(i)}),
y_{test}^{(i)})\)</span></p>
<p>训练集(Trainning set) 60%，交叉验证集(Cross validation set)
20%，测试集(Test set) 20%</p>
<p>选择误差小的、泛化能力强的多项式次数<span
class="math inline">\(d\)</span>作为最终拟合结果。</p>
<p>先训练最小化<span
class="math inline">\(J_{train}(\theta)\)</span>，再选取<span
class="math inline">\(J_{cv}(\theta)\)</span>最小的次数<span
class="math inline">\(\theta^{(i)}\)</span>，最后在测试集上测试其泛化能力。</p>
<p>偏差值（Bias）过高：欠拟合。<span
class="math inline">\(J_{train}(\theta)\)</span>和<span
class="math inline">\(J_{cv}(\theta)\)</span>都很高</p>
<p>方差值（Variance）过高：过拟合。<span
class="math inline">\(J_{train}(\theta)\)</span>很低，<span
class="math inline">\(J_{cv}(\theta)\)</span>很高</p>
<p>可以用同样的方法决定正则化系数<span
class="math inline">\(\lambda\)</span></p>
<p>偏斜类问题(skew classes)的评估方法：</p>
<p><strong>查准率(True Positive)</strong>：<span
class="math inline">\(\frac{\text{True positives}}{\text{ predicted
positives}} = \frac{\text{True pos}}{\text{True pos + Fake
pos}}\)</span></p>
<p><strong>召回率(Fake Positive)</strong>：<span
class="math inline">\(\frac{True\ positives}{\# actual\ positives} =
\frac{True\ pos}{True\ pos + False\ neg}\)</span></p>
<p>常用评估值：<span class="math inline">\(F_1\ Score: \frac{2PR}{P +
R}\)</span></p>
<h2 id="支持向量机support-vector-machine">支持向量机(Support Vector
Machine)</h2>
<p>逻辑回归：</p>
<p><span class="math inline">\(J(\theta) = \frac{1}{m}[\sum_{i = 1}^m
(-\log h_\theta(x^{(i)})) + (1 - y^{(i)})(-\log (1 -
h_\theta(x^{(i)})))] + \frac{\lambda}{2m}\sum_{j = 1}^n
\theta_j^2\)</span></p>
<p><span class="math inline">\(SVM\)</span>：</p>
<p><span class="math inline">\(\min_\theta C\sum_{i =
1}^m[y^{(i)}cost_1(\theta^Tx^{(i)}) + (1 -
y^{(i)})cost_0(\theta^Tx^{(i)})] + \frac{1}{2}\sum_{i = 1}^n
\theta_j^2\)</span></p>
<p>若希望预测结果<span class="math inline">\(y = 1\)</span>，则需要<span
class="math inline">\(\theta^Tx^{(i)} \geqslant 1\)</span>，若希望<span
class="math inline">\(y = 0\)</span>，则需要<span
class="math inline">\(\theta^Tx^{(i)} \leqslant -1\)</span></p>
<p><strong>核函数(Kernel)</strong>：<span class="math inline">\(f_i =
similarity(x, l^{(i)}) = exp(-\frac{\parallel x -
l^{(i)}\parallel^2}{2\sigma^2})\)</span></p>
<p>训练：<span class="math inline">\(\min_\theta C\sum_{i = 1}^m
[y^{(i)}cost_1(\theta^T f^{(i)}) + (1 - y^{(i)})cost_0(\theta^Tf^{(i)})]
+ \frac{1}{2}\sum_{j = 1}^n \theta_j^2\)</span> （<span
class="math inline">\(n = m\)</span>）</p>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Andrew Ng - Machine Learning - Stanford</title>
    <url>/2023/07/19/Andrew-Ng-Machine-Learning-Stanford/</url>
    <content><![CDATA[<p>https://open.163.com/newview/movie/free?pid=IEU2H8NIJ&amp;mid=VEU2H8NKA</p>
<h2 id="supervised-learning-gradient-descent">Supervised Learning &amp;
Gradient Descent</h2>
<p>Notation:</p>
<ul>
<li><span class="math inline">\(m\)</span> = #training examples.</li>
<li><span class="math inline">\(n\)</span> = #features</li>
<li><span class="math inline">\(x\)</span> = input variables /
features.</li>
<li><span class="math inline">\(y\)</span> = output variable / target
variable</li>
<li><span class="math inline">\((x, y)\)</span> = training example
<ul>
<li>The i-th: <span
class="math inline">\((x^{(i)},y^{(i)})\)</span></li>
</ul></li>
</ul>
<span id="more"></span>
<p><span
class="math inline">\(h(x)=h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+...+\theta_nx_n\)</span></p>
<p>let <span class="math inline">\(x_0\)</span> be 1,then</p>
<p><span class="math inline">\(h(x) = \sum_{i=0}^{n}\theta_ix_i=\theta^T
x\)</span></p>
<p><span class="math inline">\(Minimize_{\theta}\ \ J(\theta) =
\frac{1}{2} \sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2\)</span></p>
<p>(Least squares linear regression)</p>
<p>Start with <span class="math inline">\(\theta =
\boldsymbol{0}\)</span></p>
<p>Notice:<span class="math inline">\(\theta,x,y\)</span> are all
<em>vectors</em> now.</p>
<p><strong>Batch Gradient Descent</strong>:</p>
<p><span class="math inline">\(\theta_i := \theta_i -
\alpha\frac{\partial}{\partial\theta_i}J(\theta) = \theta_i -
\alpha(h_\theta(x)-y)x_i = \theta_i - \alpha \sum_{j = 1}^n
(h_\theta(x^{(j)}) - y^{(j)})x_i^{(j)}\)</span></p>
<p>(Repeat until convergence)</p>
<p><strong>Stochastic Gradient Descent</strong>:</p>
<p>For j:=1 to m <span class="math inline">\(\theta_i := \theta_i -
\alpha(h_\theta(x^{(j)})-y^{(j)})x_i^{(j)}\ (For\ all\ i)\)</span></p>
<p>(one <span class="math inline">\((x,y)\)</span> for one step)</p>
<p><strong>Def</strong>:<span class="math display">\[\nabla_\theta
J=\left[ \begin{array}\\ \frac{\partial J}{\partial \theta_0} \\ \vdots
\\ \frac{\partial J}{\partial \theta_n} \end{array}\right]\]</span></p>
<p>So:Gradient Descent:<span class="math inline">\(\theta :=\theta -
\alpha \nabla_\theta J\ \ (\theta,\nabla J \in
\mathbb{R^{n+1}})\)</span></p>
<p><span class="math inline">\(f(A):\mathbb{R^{m \times n}} \mapsto
\mathbb{R}\)</span></p>
<p><strong>Def</strong>:<span class="math inline">\(\nabla_A f(A)=\left[
\begin{array}\\ \frac{\partial f}{\partial A_{1,1}} &amp; \cdots &amp;
\frac{\partial f
}{\partial A_{1,n}} \\ \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial f}{\partial A_{m,1}} &amp; \cdots &amp; \frac{\partial
f}{\partial A_{m,n}}\end{array} \right]\)</span></p>
<p><span class="math inline">\(tr\ A = \sum_{i=1}^{n} A_{i,i}\ \ (A \in
\mathbb{R^{n*n}})\)</span></p>
<p><strong>Fact</strong>:</p>
<p><span class="math inline">\(tr\ AB=tr\ BA\)</span></p>
<p><span class="math inline">\(tr\ ABC = tr\ CAB = tr\ BCA\)</span></p>
<p><span class="math inline">\(f(A) = tr\ AB,\nabla_A tr\ AB =
B^T\)</span></p>
<p><span class="math inline">\(\nabla_A tr\ ABA^TC = CAB +
C^TAB^T\)</span></p>
<p><span class="math inline">\(X = \left[\begin{array}\\(x^{(i)})^T \\
\vdots \\ (x^{(m)})^T\end{array}\right]\)</span></p>
<p><span class="math inline">\(\frac{1}{2}(X \theta - y)^T(X\theta - y)
= \frac{1}{2}\sum_{i=1}^{m}(h(x^{(i)})-y^{(i)})^2 =
J(\theta)\)</span></p>
<p><span class="math inline">\(\begin{aligned} &amp;\nabla_\theta
J(\theta)\\ =&amp; \nabla_\theta \frac{1}{2}(X \theta - y)^T(X\theta -
y) \\ =&amp; \frac{1}{2} \nabla_\theta tr (\theta^TX^TX\theta - \theta^T
X^Ty-y^TX\theta +y^Ty) \\ =&amp; \frac{1}{2}(\nabla_\theta tr\
\theta\theta^TX^TX-\nabla_\theta tr\ y^TX\theta - \nabla_\theta
y^TX\theta)\\ =&amp; X^TX\theta - X^Ty \end{aligned}\)</span></p>
<p>Let it be 0,then</p>
<p><span class="math inline">\(\theta = (X^TX)^{-1}X^Ty\)</span></p>
<p>Vector Scaling:<span class="math inline">\(x_i = \frac{x_i -
\mu_i}{s_i}\)</span></p>
<p>Where <span class="math inline">\(\mu_i\)</span> is the average of
all the values for feature (i) and <span
class="math inline">\(s_i\)</span> is the range of values (max - min),
or <span class="math inline">\(s_i\)</span> is the standard
deviation.</p>
<h2 id="underfitting-and-overfitting">Underfitting and Overfitting</h2>
<p><strong>Parametric Learning Algorithm</strong>:The number of
parameters grows with m.</p>
<p>A non-parametric learning Algorithm:<strong>Locally Weighted
Regression</strong> (LOESS)</p>
<p>To evaluate <span class="math inline">\(h\)</span> at a certain <span
class="math inline">\(x\)</span></p>
<p>LR(Linear Regression):Fit <span class="math inline">\(\theta\)</span>
to minimize <span
class="math inline">\(\sum_{i}(y^{(i)}-\theta^Tx^{(i)})^2\)</span>
,return <span class="math inline">\(\theta^TX\)</span></p>
<p>LWR:Fit <span class="math inline">\(\theta\)</span> to minimize <span
class="math inline">\(\sum_i
w^{(i)}(y^{(i)}-\theta^Tx^{(i)})^2\)</span></p>
<p>where <span
class="math inline">\(w^{(i)}=exp(-\frac{(x^{(i)}-x)^2}{2\tau^2})\)</span>
(<span class="math inline">\(\tau\)</span>:bandwidth parameter)</p>
<p>If <span class="math inline">\(|x^{(i)}-x|\)</span> small, then <span
class="math inline">\(w^{(i)}\approx 1\)</span></p>
<p>If <span class="math inline">\(|x^{(i)}-x|\)</span> large, then <span
class="math inline">\(w^{(i)}\approx 0\)</span></p>
<p>One way to proof that the <strong>Least Squares</strong> works
correctly.</p>
<p>Assume <span class="math inline">\(y^{(i)} =
\theta^Tx^{(i)}+\varepsilon^{(i)}\)</span></p>
<p><span class="math inline">\(\varepsilon^{(i)} =
error,\varepsilon^{(i)} \sim \mathscr{N}(O,\sigma^2)\)</span></p>
<p><span class="math inline">\(P(\varepsilon^{(i)}) =
\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}}\sim
\mathscr{N}(\theta^Tx^{(i)},\sigma^2)\)</span></p>
<p>p.s.From Central Limit Theorem,we can know that <span
class="math inline">\(y^{(i)}\)</span> given <span
class="math inline">\(x^{(i)}\)</span> and parameterized by <span
class="math inline">\(\theta\)</span> is distributed Gaussian。</p>
<p><span class="math inline">\(\varepsilon^{(i)}\)</span>s are
<strong>IID</strong> (Independently ,Identically Distributed)</p>
<p><span class="math inline">\(L(\theta) =
P(\overrightarrow{y}|X;\theta) = \prod_{i=1}^{m}
P(y^{(i)}|x^{(i)};\theta) = \prod_{i=1}^m
\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}}\)</span>
(Likelihood)</p>
<p>The priciple of maximun likelihood:</p>
<p><span class="math inline">\(\begin{aligned} l(\theta) =&amp; \log
L(\theta) \\ =&amp; \log \prod_{i=1}^m
\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}}
\\ =&amp; m\log\frac{1}{\sqrt{2\pi}\sigma} +
\sum_{i=1}^m-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\end{aligned}\)</span></p>
<p>So maximize <span class="math inline">\(l(\theta)\)</span> is the
same as minimizing <span
class="math inline">\(\frac{\sum_{i=1}^m(y^{(i)} - \theta^Tx)^2}{2} =
J(\theta)\)</span></p>
<p><strong>Logistic Regression</strong>:<strong>Binary
Classification</strong> (LR can't work well)</p>
<p><span class="math inline">\(y\in\{0,1\},h_\theta
(x)\in[0,1]\)</span></p>
<p>choose:<span class="math inline">\(h_\theta(x) = g(\theta^TX) =
\frac{1}{1+e^{-\theta^TX}}\)</span></p>
<p><span class="math inline">\(g(z) = \frac{1}{1+e^{-z}}\)</span>
(sigmoid function)</p>
<p><span class="math inline">\(P(y = 1 | x; \theta) = h_\theta (x),P(y =
0 | x ; \theta) = 1 - h_\theta(x)\)</span></p>
<p>So <span class="math inline">\(P(y | x; \theta) = h_\theta(x)^y(1 -
h_\theta(x))^{1-y}\)</span></p>
<p><span class="math inline">\(L(\theta) = P(\overrightarrow{y} | x;
\theta) = \prod_{i}P(y^{(i)} | x^{(i)}; \theta) = \prod_i
h(x^{(i)})^{y(i)}(1 - h(x^{(i)}))^{1 - y^{(i)}}\)</span></p>
<p><span class="math inline">\(l(\theta) = \log L(\theta) = \sum_{i=1}^m
y^{(i)}\log h_\theta(x^{(i)}) + (1 - y^{(i)})\log (1 -
h_\theta(x^{(i)}))\)</span></p>
<p><span class="math inline">\(\theta := \theta + \alpha \nabla_\theta
l(\theta)\)</span></p>
<p><strong>Batch Gradient Ascent</strong></p>
<p><span
class="math inline">\(\frac{\partial}{\partial\theta_j}l(\theta) =
\sum_{i=1}^m (y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}\)</span></p>
<p><span class="math inline">\(\theta_j := \theta_j + \alpha\sum_{i=1}^m
(y^{(i)} - h_\theta{(i)})x_j^{(i)}\)</span></p>
<p><strong>Stochastic Gradient Descent</strong></p>
<p><span class="math inline">\(\theta_j := \theta_j + \alpha(y^{(i)} -
h(x^{(i)}))x_j^{(i)}\)</span></p>
<p><span class="math inline">\(g(z) = \begin{cases} 1 &amp; if\
z\geqslant 0 \\ 0 &amp; if\ otherwise\end{cases}\)</span></p>
<p><span class="math inline">\(h_\theta(x) = g(\theta^Tx)\)</span></p>
<p><span class="math inline">\(\theta_j := \theta_j +
\alpha(y^{(i)}-h_\theta(x^{(i)}))x_j^{(i)}\)</span></p>
<h2 id="newtons-methodnot-finished">Newton's Method(Not Finished)</h2>
<p><span class="math inline">\(f(\theta)\)</span>,Find <span
class="math inline">\(\theta\)</span> s.t. <span
class="math inline">\(f(\theta) = 0\)</span></p>
<p><span class="math inline">\(\Delta = \theta^{(t)} - \theta^{(t+1)} =
\frac{f(\theta^{(t)})}{f&#39;(\theta^{(t)})}\)</span></p>
<p><span class="math inline">\(l(\theta)\)</span> Want <span
class="math inline">\(\theta\)</span> s.t. <span
class="math inline">\(l(\theta) = 0\)</span></p>
<p><span class="math inline">\(\theta^{(t+1)} = \theta^{(t)} -
\frac{l&#39;(\theta^{(t)})}{l&#39;&#39;(\theta^{(t)})}\)</span></p>
<p>More generally:</p>
<p><span class="math inline">\(\theta^{(t+1)} = \theta^{(t)} -
H^{-1}\nabla_\theta l\)</span></p>
<p>Where H is the Hessian matrix</p>
<p><span class="math inline">\(H_j = \frac{\partial^2 l}{\partial
\theta_i \partial \theta_j}\)</span></p>
<p><strong>Generalized Linear Methods</strong></p>
<p><strong>Exponential Family Distributions</strong></p>
<p><span class="math inline">\(P(y|x; \theta)\)</span></p>
<p><span class="math inline">\(y \in \mathbb{R}\)</span>: Gaussian -&gt;
Least Square</p>
<p><span class="math inline">\(y \in \{0,1\}\)</span>:Bernoulli -&gt;
Logisitic regression</p>
<p><span class="math inline">\(Bernoulli(\Phi)\)</span> <span
class="math inline">\(P(y = 1; \Phi) = \Phi\)</span> <span
class="math inline">\(\mathscr{N}(\mu,\sigma^2)\)</span></p>
<p><span class="math inline">\(P(y;\eta) = b(y)\exp(\eta^T T(y) -
a(\eta))\)</span></p>
<p><span class="math inline">\(\eta\)</span>-natural parameter</p>
<p><span class="math inline">\(T(y)\)</span>-sufficient
statistic(Usually <span class="math inline">\(T(y) = y\)</span>)</p>
<p><span class="math inline">\(Ber(\Phi)\)</span> :</p>
<p><span class="math inline">\(P(y;\Phi) = \Phi^y(1-\Phi)^{1-y} = \exp(y
\log \Phi + (1 - y) \log (1 - \Phi)) = \exp(\log \frac{\Phi}{1 - \Phi} y
+ \log (1 - \Phi))\)</span></p>
<p><span class="math inline">\(\eta = \log \frac{\Phi}{1 -
\Phi}\)</span>,<span class="math inline">\(y = T(y)\)</span>,<span
class="math inline">\(-a(\eta) = \log(1 - \Phi)\)</span></p>
<p><span class="math inline">\(\Rightarrow \Phi = \frac{1}{1 +
e^{-\eta}} \Rightarrow a(\eta) = -\log (1 - \Phi) = \log(1 +
e^\eta)\)</span></p>
<p><span class="math inline">\(T(y) = y\)</span>, <span
class="math inline">\(b(y) = 1\)</span></p>
<p><span class="math inline">\(\mathscr{N}(\mu, \sigma^2)\)</span> set
<span class="math inline">\(\sigma^2 = 1\)</span></p>
<p><span class="math inline">\(\frac{1}{\sqrt{2\pi}} \exp(-\frac{1}{2}(y
- \mu)^2) =\frac{1}{\sqrt{2\pi}}\exp(-\frac{1}{2}y^2)\exp(\mu
y-\frac{1}{2}\mu^2)\)</span></p>
<p><span class="math inline">\(b(y) =
\frac{1}{\sqrt{2\pi}}\exp(-\frac{1}{2}y^2)\)</span>, <span
class="math inline">\(\mu = \eta\)</span>, <span
class="math inline">\(T(y) = y\)</span>, <span
class="math inline">\(a(\eta) = \frac{1}{2}\mu^2 =
\frac{1}{2}\eta^2\)</span></p>
<p><strong>Generalized Linear Models(GLM)</strong></p>
<p>Assume:</p>
<ol type="1">
<li><p><span class="math inline">\(y|x;\theta \sim \text{Exp Family}
(\eta)\)</span></p></li>
<li><p>Given <span class="math inline">\(x\)</span>,goal is to output
<span class="math inline">\(E[T(y)|x]\)</span>, Want <span
class="math inline">\(h(x) = E[T(y)|x]\)</span></p></li>
<li><p><span class="math inline">\(\eta = \theta^T x\)</span> (<span
class="math inline">\(\eta_i = \theta_i^T x\)</span> if <span
class="math inline">\(y \in \mathbb{R}^l\)</span>)</p></li>
</ol>
<p>Bernoulli: For fixed <span
class="math inline">\(x,\theta\)</span>,algorithm output</p>
<p><span class="math inline">\(h_\theta(x) = E[y|x;\theta] = P(y = 1 |
x;\theta) = \Phi = \frac{1}{1+e^{-\eta}} = \frac{1}{1+e^{-\theta^T
X}}\)</span></p>
<p><span class="math inline">\(g(\eta) = E[y;\eta] =
\frac{1}{1+e^{-\eta}}\)</span> (<strong>Canonical Response
Function</strong>)</p>
<p><span class="math inline">\(g^{-1}\)</span>:<strong>Canonical Link
Function</strong></p>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Makefile和CMake初级使用</title>
    <url>/2023/07/19/Makefile%E5%92%8CCMake%E5%88%9D%E7%BA%A7%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="makefile">Makefile</h2>
<ul>
<li>Makefile三部分：目标、依赖、执行语句；</li>
<li>递归执行：若不存在目标文件或目标文件修改时间早于依赖文件，则先产生对应依赖文件，再执行语句；</li>
<li>所有.o文件均由对应.c文件生成，<code>$&lt;</code>为第一个依赖文件，<code>$@</code>为目标，<code>$^</code>为所有不重复的依赖文件，以空格分开；</li>
<li><code>src = $(wildcard ./*.c)</code>得到空格隔开的所有.c文件名；<code>obj = $(patsubst %.c, %.o, $(src))</code>
代表将src中的所有.c替换成.o；<code>obj = $(src: %.c=%.o)</code>
能得到同样效果；</li>
<li><code>.PHONY</code>代表clean为伪目标</li>
</ul>
<span id="more"></span>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">src = <span class="variable">$(<span class="built_in">wildcard</span> ./*.c)</span>  </span><br><span class="line">obj = <span class="variable">$(<span class="built_in">patsubst</span> %.c, %.o, <span class="variable">$(src)</span>)</span>  </span><br><span class="line"><span class="comment">#obj = $(src:%.c=%.o)  </span></span><br><span class="line">target = app  </span><br><span class="line">CC = gcc  </span><br><span class="line"></span><br><span class="line"><span class="variable">$(target)</span>: <span class="variable">$(obj)</span>  </span><br><span class="line">    <span class="variable">$(CC)</span> <span class="variable">$(obj)</span> -o <span class="variable">$(target)</span>  </span><br><span class="line"></span><br><span class="line"><span class="section">%.o: %.c  </span></span><br><span class="line">    <span class="variable">$(CC)</span> -c <span class="variable">$&lt;</span> -o <span class="variable">$@</span>  </span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: clean  </span></span><br><span class="line"><span class="section">clean:  </span></span><br><span class="line">    rm -rf <span class="variable">$(obj)</span> <span class="variable">$(target)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">CC := clang</span><br><span class="line">CXX := clang++</span><br><span class="line"></span><br><span class="line">.PHONY all</span><br><span class="line"><span class="section">all: answer</span></span><br><span class="line"></span><br><span class="line">objects := main.o answer.o</span><br><span class="line"><span class="section">answer: <span class="variable">$(objects)</span></span></span><br><span class="line">	<span class="variable">$(CXX)</span> -o <span class="variable">$@</span> <span class="variable">$(objects)</span></span><br><span class="line"></span><br><span class="line"><span class="section">main.o: answer.hpp</span></span><br><span class="line"><span class="section">answer.o: answer.hpp</span></span><br><span class="line"></span><br><span class="line">.PHONY clean</span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">	rm -f answer(objects)</span><br></pre></td></tr></table></figure>
<h2 id="cmake">CMake</h2>
<ul>
<li><a
href="https://www.bilibili.com/video/BV14h41187FZ/?vd_source=9282f15e6d326725afd47615733d4bd1">视频教程</a></li>
<li>在my_project目录下存放源文件和CMakeLists.txt，另新建文件夹build，进入后执行<code>cmake ..</code>在build目录下生成Makefile文件，再执行<code>cmake —-build .</code>生成可执行文件；上述命令等价于<code>cmake -B build &amp;&amp; cmake —-build build</code>
；</li>
<li>VSCode配置：<code>brew install cmake</code> 后安装CMake和CMake
Tools，先编写CMakeLists.txt，再<code>Cmd+Shift+P</code> 调出CMake: Quick
Start即可；</li>
<li>常见操作：</li>
</ul>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">cmake_minimum_required(VERSION 3.15.0) <span class="comment"># 指定最小版本</span></span><br><span class="line">project(My_Project) <span class="comment"># 指定项目名称</span></span><br><span class="line"></span><br><span class="line">set(CMAKE_BUILD_TYPE <span class="string">&quot;Release&quot;</span>)</span><br><span class="line">set(CMAKE_CXX_FLAGS_DEBUG <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -g -Werror -Wextra -pedantic -std=c++14&quot;</span>)</span><br><span class="line">set(CMAKE_CXX_FLAGS_RELEASE <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++14 -O2&quot;</span>)</span><br><span class="line"></span><br><span class="line">add_executable(demo demo.cpp) <span class="comment"># 生成可执行文件（Linux: demo, Windows: demo.exe）</span></span><br><span class="line">add_library(common STATIC util1.cpp) <span class="comment"># 生成静态库（Linux: common.a, Windows: common.lib）</span></span><br><span class="line">add_library(common SHARED util2.cpp util3.cpp) <span class="comment"># 生成动态库或共享库（Linux: common.so, Windows: common.dll, MacOS: common.bundle, common.dylib）</span></span><br><span class="line"></span><br><span class="line">file(GLOB SRC_LIST <span class="string">&quot;*.cpp&quot;</span> <span class="string">&quot;protocal/*.cpp&quot;</span>)</span><br><span class="line">add_library(demo $&#123;SRC_LIST&#125;)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">set(SRC_LIST main.cpp test.cpp)</span><br><span class="line">list(APPEND SRC_LIST test2.cpp)</span><br><span class="line">list(REMOVE_ITEM SRC_LIST test2.cpp)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">aux_source_directory(. SRC_LIST) <span class="comment"># 搜索当前目录下所有可编译单元（.cpp文件）</span></span><br><span class="line">aux_source_directory(protocol SRC_PROTOCOL_LIST)</span><br><span class="line">add_library(demo $&#123;SRC_LIST&#125; $&#123;SRC_PROTOCOL_LIST&#125;)</span><br><span class="line"></span><br><span class="line">foreach(source $&#123;srcs&#125;)</span><br><span class="line">get_filename_component(name $&#123;source&#125; NAME/EXT/DIRECTORY/ABSOLUTE) <span class="comment"># 文件名/扩展名/目录路径/绝对路径</span></span><br><span class="line">add_executable($&#123;name&#125; $&#123;source&#125;)</span><br><span class="line">endforeach(source)</span><br><span class="line"></span><br><span class="line">include_directories($&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/<span class="keyword">include</span>) <span class="comment"># 设置头文件包含目录，将路径增加至CPLUS_INCLUDE_PATH变量</span></span><br><span class="line">set(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -I $&#123;CMAKE_CURRENT_SOURCE_DIR&#125;&quot;</span>) <span class="comment"># 等价于</span></span><br><span class="line">link_libraries(<span class="string">&quot;/include/util.so&quot;</span>) <span class="comment"># 写在add_executable之前</span></span><br><span class="line"></span><br><span class="line">link_directories($&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/libs) <span class="comment"># 设置链接库搜索目录，将路径增加至LD_LIBRARY_PATH变量</span></span><br><span class="line">set(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -L $&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/libs&quot;</span>) <span class="comment"># 等价于</span></span><br><span class="line"></span><br><span class="line">find_package(Protobuf REQUIRED) <span class="comment"># 查找外部包</span></span><br><span class="line">target_link_libraries(demo lib.a $&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/libs/lib.so) <span class="comment"># 设置需要链接的库</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动执行子目录下的CMakeLists.txt</span></span><br><span class="line">add_subdirectory($&#123;PROJECT_SOURCE_DIR&#125;/src/proto)</span><br><span class="line">include_directories($&#123;PROJECT_BINARY_DIR&#125;/src/proto)</span><br><span class="line"></span><br><span class="line">message($&#123;PROJECT_SOURCE_DIR&#125;)</span><br><span class="line">message(<span class="string">&quot;build with debug mode&quot;</span>)</span><br><span class="line">message(WARNING <span class="string">&quot;this is warnning message&quot;</span>)</span><br><span class="line">message(FATAL_ERROR <span class="string">&quot;this build has many error&quot;</span>) <span class="comment"># FATAL_ERROR 会导致编译失败</span></span><br></pre></td></tr></table></figure>
<ul>
<li>文件目录形式：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">- my_project/</span><br><span class="line">  - build/</span><br><span class="line">    - Makefile</span><br><span class="line">    - helloworld.exe</span><br><span class="line">  - CmakeLists.txt</span><br><span class="line">  - helloworld.cpp</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac工作环境配置</title>
    <url>/2023/07/13/Mac%E5%B7%A5%E4%BD%9C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>外部文件：</p>
<p><a href="vimrc">.vimrc</a></p>
<h2 id="基础配置">基础配置</h2>
<p>系统偏好正常设置即可。</p>
<p>command+shift+. 显示隐藏文件。</p>
<p>软件：搜狗输入法，Chrome，XCode，Parallel
Desktop/Toolbox，LaTeX，ForkLift，The Unarchiver，Steam，Github
Desktop，Clean One Pro，WPS，MS Office，Typora，<a
href="https://www.qbittorrent.org/download">qBittorrent</a>， <a
href="https://help.ghelper.net/shou-ji-dai-li/clashx">ClashX</a></p>
<span id="more"></span>
<h2 id="shell">Shell</h2>
<p><a
href="https://cloud.tencent.com/developer/article/1639115">一篇教程</a>，<a
href="https://zhuanlan.zhihu.com/p/550022490">另一篇教程</a></p>
<ol type="1">
<li>安装<a
href="https://brew.sh">homebrew</a>：复制主页命令直接执行即可；</li>
<li>安装iTerm2：brew install iterm2；</li>
<li>安装zsh：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> etc/shells</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$SHELL</span></span><br><span class="line"><span class="comment">#若没有zsh：</span></span><br><span class="line">brew install zsh</span><br><span class="line"><span class="comment">#若默认不是zsh：</span></span><br><span class="line">chsh -s /bin/zsh</span><br><span class="line"></span><br><span class="line">vim ~/.zshrc</span><br><span class="line"><span class="built_in">source</span> ~/.bash_profile</span><br></pre></td></tr></table></figure>
<ol type="1">
<li>安装<a href="ohmyz.sh">oh my zsh</a>：复制主页命令直接执行即可</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/.oh-my-zsh/custom/plugins/</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/zsh-users/zsh-syntax-highlighting.git</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/zsh-users/zsh-autosuggestions.git</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/zsh-users/zsh-completions.git</span><br><span class="line"><span class="comment"># brew默认安装至/usr/local/Cellar/故以下命令可能无效：</span></span><br><span class="line">brew install zsh-autosuggestions zsh-syntax-highlighting zsh-completions</span><br><span class="line"></span><br><span class="line">vim ~/.zshrc <span class="comment"># 找到plugins=(git)</span></span><br><span class="line">plugins=(</span><br><span class="line">     git</span><br><span class="line">     zsh-syntax-highlighting</span><br><span class="line">     zsh-autosuggestions</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ol type="1">
<li>安装powerlevel10k主题：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ./oh-my-zsh/themes</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/romkatv/powerlevel10k.git</span><br><span class="line"></span><br><span class="line">vim ~/.zshrc</span><br><span class="line"><span class="comment"># 将 ZSH_THEME 改为：</span></span><br><span class="line">ZSH_THEME=<span class="string">&quot;powerlevel10k/powerlevel10k&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出，重新进入配置powerlevel10k</span></span><br><span class="line"><span class="comment"># 如果powerlevel下载字体失败：</span></span><br><span class="line">brew tap homebrew/cask-fonts</span><br><span class="line">brew install --cask font-sauce-code-pro-nerd-font</span><br></pre></td></tr></table></figure>
<ol type="1">
<li>vim配置：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">复制.vimrc</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim</span><br><span class="line"></span><br><span class="line">将 https://github.com/w0ng/vim-hybrid/blob/master/colors/hybrid.vim 复制到：</span><br><span class="line">~/.vim/colors/hybrid.vim</span><br><span class="line"></span><br><span class="line">:PluginUpdate</span><br></pre></td></tr></table></figure>
<h2 id="语言环境">语言环境</h2>
<h3 id="c">C++</h3>
<p>Mac OS自带Clang+LLVM版G++。</p>
<h3 id="python">Python</h3>
<p>Mac自带非最新版本Python，用brew install python下载最新。</p>
<h3 id="java">Java</h3>
<p><a
href="https://www.oracle.com/java/technologies/downloads/">Oracle官网</a>下载JDK，然后修改环境变量。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/libexec/java_home <span class="comment">#获取安装目录</span></span><br><span class="line">/Library/Java/JavaVirtualMachines/jdk-20.jdk/Contents/Home</span><br><span class="line"></span><br><span class="line">vim ~/.bash_profile</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-20.jdk/Contents/Home</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<h3 id="c-1">C</h3>
<p><a href="https://dotnet.microsoft.com/zh-cn/download">下载</a>或brew
install dotnet</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> csharp &amp;&amp; <span class="built_in">cd</span> csharp</span><br><span class="line">dotnet new console</span><br><span class="line">dotnet restore</span><br><span class="line">dotnet run</span><br><span class="line"></span><br><span class="line"><span class="comment"># 若出错：</span></span><br><span class="line">brew update</span><br><span class="line">brew install openssl</span><br><span class="line"><span class="built_in">ln</span> -s /usr/local/opt/openssl/lib/libcrypto.1.0.0.dylib /usr/local/lib/</span><br><span class="line"><span class="built_in">ln</span> -s /usr/local/opt/openssl/lib/libssl.1.0.0.dylib /usr/local/lib/</span><br><span class="line">brew <span class="built_in">link</span> --force openssl</span><br></pre></td></tr></table></figure>
<h2 id="ide">IDE</h2>
<h2 id="sublime">Sublime</h2>
<p><a
href="https://www.sublimetext.com/download_thanks?target=mac">官网下载</a></p>
<p><a href="https://packagecontrol.io/installation">Package
Control</a>，若失败：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -sf /usr/local/Cellar/openssl@1.1/1.1.1o/lib/libcrypto.dylib /usr/local/lib<span class="comment">##/</span></span><br></pre></td></tr></table></figure>
<h3 id="vscode">VScode</h3>
<p><a href="https://code.visualstudio.com/">官网下载</a></p>
<p>换用国内源：将下载地址中的<strong>az764295.vo.msecnd.net</strong>
更换为  <strong>vscode.cdn.azure.cn</strong> 。</p>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>电脑配置</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo个人网站搭建</title>
    <url>/2023/07/13/Hexo%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h2 id="本机配置">本机配置</h2>
<p><a href="https://nodejs.org/en">官网</a>下载Node.js，换成淘宝源：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 换成淘宝源（可能需要sudo su进入root模式）：</span></span><br><span class="line">npm install -g cnpm --registry==https://registry.npm.taobao.org</span><br><span class="line">cnpm -v</span><br><span class="line">cnpm install -g hexo-cli</span><br><span class="line"><span class="built_in">mkdir</span> Hexo &amp;&amp; <span class="built_in">cd</span> Hexo</span><br><span class="line">hexo init</span><br><span class="line">hexo s</span><br><span class="line"><span class="comment"># 此时可在http://localhost:4000/访问主页</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="服务器与域名配置">服务器与域名配置</h2>
<ul>
<li>阿里云ECS轻量应用服务器2核2G￥108/年；买域名、ICP备案</li>
<li>选择CentOS系统镜像，设置密码；</li>
<li>创建新用户并设置ssh免密登录<a
href="http://www.ruanyifeng.com/blog/2011/12/ssh_remote_login.html">[原理链接]</a>，方便后续hexo部署：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">adduser git</span><br><span class="line"><span class="built_in">chmod</span> 740 /etc/sudoers</span><br><span class="line">vim /etc/sudoers</span><br><span class="line"><span class="comment"># 在root ALL=(ALL) ALL下添加：</span></span><br><span class="line">git ALL=(ALL) ALL</span><br><span class="line"><span class="built_in">chmod</span> 400 /etc/sudoers</span><br><span class="line">sudo passwd git</span><br><span class="line"></span><br><span class="line">su git</span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line"><span class="built_in">mkdir</span> .ssh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查本地~/.ssh下是否已有公钥，若没有：</span></span><br><span class="line">ssh-keygen</span><br><span class="line"><span class="comment"># 在服务器git用户~/.ssh下生成authorized_key</span></span><br><span class="line">ssh-copy-id user@host</span><br></pre></td></tr></table></figure>
<h2 id="服务器nginx配置">服务器nginx配置</h2>
<ul>
<li>RedHat系（RedHat、CentOS、Fedora等）包管理工具为rpm，依赖管理工具为yum，Debian系（Debian、Ubuntu等）包管理工具为dpkg，依赖管理工具为apt。</li>
<li>安装nginx依赖环境，下载解压nginx安装包：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 确认此时在root用户下：</span></span><br><span class="line">yum install gcc-c++</span><br><span class="line">yum install -y pcre pcre-devel</span><br><span class="line">yum install -y zlib zlib-devel</span><br><span class="line">yum install -y openssl openssl-devel</span><br><span class="line"></span><br><span class="line">wget -c https://nginx.org/download/nginx-1.10.1.tar.gz</span><br><span class="line">tar -xvf nginx-1.10.1.tar.gz -C /usr/local</span><br><span class="line"><span class="built_in">cd</span> /usr/local/nginx-1.10.1</span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line"><span class="comment"># 若Make报错：</span></span><br><span class="line">vim ./objs/Makefile</span><br><span class="line"><span class="comment"># 删除CFLAGS中的-Werror：</span></span><br><span class="line">CFLAGS =  -pipe  -O -W -Wall -Wpointer-arith -Wno-unused -g</span><br><span class="line">vim ./src/os/unix/ngx_user.c</span><br><span class="line"><span class="comment"># 注释掉此行：</span></span><br><span class="line">cd.current_salt[0] = ~salt[0];</span><br></pre></td></tr></table></figure>
<ul>
<li>安装、配置nginx：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 确认此时在root用户下：</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/nginx/sbin</span><br><span class="line">./nginx</span><br><span class="line"><span class="comment"># 此时可用host:80访问nginx欢迎页</span></span><br><span class="line"><span class="comment"># 可用./nginx -s stop停止服务</span></span><br><span class="line"><span class="comment"># 若服务器不开放80端口：</span></span><br><span class="line">/sbin/iptables -I INPUT -p tcp –dport 80 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p /home/www/hexo</span><br><span class="line"><span class="built_in">cd</span> /usr/local/nginx/conf</span><br><span class="line">vim nginx.conf</span><br><span class="line"><span class="comment"># 将其中的部署根目录/的location的root修改为/home/www/hexo</span></span><br><span class="line"><span class="comment"># 将server_name修改为域名，若没有域名则改为公网ip</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">curl -sL https://rpm.nodesource.com/setup_10.x | bash -</span><br><span class="line">yum install -y nodejs</span><br><span class="line">node -v</span><br><span class="line">npm -v</span><br><span class="line">yum install git</span><br><span class="line">git --version</span><br></pre></td></tr></table></figure>
<h2 id="服务器hexo配置">服务器Hexo配置</h2>
<p>配置git仓库</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 确认此时在git用户下：</span></span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">git init --bare hexo.git</span><br><span class="line">vim ~/hexo.git/hooks/post-receive</span><br><span class="line"><span class="comment"># 写入：git --work-tree=/home/www/hexo --git-dir=/home/git/hexo.git checkout -f</span></span><br><span class="line"><span class="built_in">chmod</span> +x ~/hexo.git/hooks/post-receive</span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">sudo <span class="built_in">chmod</span> -R 777 /home/www/hexo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 回到本地对应Hexo目录：</span></span><br><span class="line"><span class="built_in">cd</span> ~/Documents/Hexo</span><br><span class="line">sudo vim _config.yml</span><br><span class="line"><span class="comment"># 将url改成https://&#123;服务器IP&#125;/</span></span><br><span class="line"><span class="comment"># 修改末尾deploy部分：</span></span><br><span class="line">deploy:</span><br><span class="line">	<span class="built_in">type</span>: git</span><br><span class="line">	repo: git@ip:/home/git/hexo.git</span><br><span class="line">	branch: master</span><br><span class="line"></span><br><span class="line">npm install hexo-deployer-git --save</span><br><span class="line">npm install hexo-server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 若首次使用git：</span></span><br><span class="line">git config --global user.name <span class="string">&quot;your-username&quot;</span></span><br><span class="line">git config --global user.email <span class="string">&quot;your-email-address&quot;</span></span><br><span class="line"></span><br><span class="line">hexo clean &amp;&amp; hexo g -d</span><br></pre></td></tr></table></figure>
<h2 id="next主题配置">NeXT主题配置</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 更换主题：https://hexo.io/themes/</span></span><br><span class="line">git <span class="built_in">clone</span> --depth=1 https://github.com/theme-next/hexo-theme-next.git themes/next</span><br><span class="line"><span class="comment"># 将_config.yml中themes改为next</span></span><br><span class="line"></span><br><span class="line">hexo n <span class="string">&quot;name.md&quot;</span></span><br><span class="line">hexo clean &amp;&amp; hexo g -d</span><br><span class="line"><span class="comment"># 在Hexo和themes下各有一个_config.yml，在此自定义</span></span><br><span class="line"><span class="comment"># markdown中插入图片：</span></span><br><span class="line"><span class="comment"># 将Hexo根目录下_config.yml文件中post_asset_folder设为true，即可使用相对路径引用图片：</span></span><br><span class="line"><span class="comment"># 注意：.开头的隐藏文件不会被保留</span></span><br><span class="line">![](image.jpg)</span><br></pre></td></tr></table></figure>
<p><a href="https://zhuanlan.zhihu.com/p/618864711">配置教程</a>，<a
href="https://zhuanlan.zhihu.com/p/30836436">另一篇</a>，<a
href="https://siriusq.top/Next%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96?tdsourcetag=s_pctim_aiomsg">另一篇</a></p>
<ul>
<li><p>删除文章：删除对应.md和文件夹，以及Hexo根目录下.deploy_git即可。</p></li>
<li><p><span class="math inline">\(\LaTeX\)</span>支持：<a
href="https://zhuanlan.zhihu.com/p/381508379">知乎</a></p></li>
<li><p>添加置顶：</p></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-generator-index --save</span><br><span class="line">npm instal hexo-generator-index-pin-top --save</span><br></pre></td></tr></table></figure>
<p>在置顶文章的Front-matter中加上top: true即可。</p>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>电脑配置</tag>
      </tags>
  </entry>
</search>
